# =============================================================================
# 2ë‹¨ê³„ ë‰´ìŠ¤ ì ìˆ˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
# 1ë‹¨ê³„: ê°œë³„ ë‰´ìŠ¤ ì ìˆ˜í™” (0~100)
# 2ë‹¨ê³„: ì¢…ëª©ë³„ ë‰´ìŠ¤ ì§‘ê³„ â†’ ì¢…ëª© ìµœì¢… ì ìˆ˜
# =============================================================================
import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.decomposition import PCA
import joblib
import warnings
from datetime import datetime, timedelta

warnings.filterwarnings('ignore')

class IndividualNewsScorer:
    """
    ğŸ¯ 1ë‹¨ê³„: ê°œë³„ ë‰´ìŠ¤ í˜¸ì¬/ì•…ì¬ ì ìˆ˜ ì˜ˆì¸¡ê¸°
    
    ëª©í‘œ: ë‰´ìŠ¤ í•˜ë‚˜ë§Œ ë³´ê³  ê·¸ ë‰´ìŠ¤ ìì²´ì˜ í˜¸ì¬ë„ ì ìˆ˜í™”
    í”¼ì²˜: FinBERT + ê°ì„±ì ìˆ˜ë§Œ (ê³¼ì í•© ë°©ì§€)
    """
    
    def __init__(self):
        self.model = None
        self.pca = None
        self.feature_names = None
        print("âœ… ê°œë³„ ë‰´ìŠ¤ ì ìˆ˜ê¸° ì´ˆê¸°í™”!")
    
    def create_individual_features(self, df, max_bert_dim=50, verbose=True):
        """
        ê°œë³„ ë‰´ìŠ¤ ì ìˆ˜í™”ë¥¼ ìœ„í•œ ìµœì†Œ í”¼ì²˜ ìƒì„±
        """
        if verbose:
            print("ğŸ› ï¸ ê°œë³„ ë‰´ìŠ¤ìš© í”¼ì²˜ ìƒì„± (ê³¼ì í•© ë°©ì§€)")
        
        feature_parts = []
        
        # === 1. BERT ì„ë² ë”©  ===
        bert_cols = [f'finbert_{i}' for i in range(768) if f'finbert_{i}' in df.columns]
        if bert_cols:
            X_bert = df[bert_cols].fillna(0)
            
            if self.pca is None:
                self.pca = PCA(n_components=max_bert_dim, random_state=42)
                X_bert_pca = self.pca.fit_transform(X_bert)
            else:
                X_bert_pca = self.pca.transform(X_bert)
            
            bert_df = pd.DataFrame(
                X_bert_pca,
                index=df.index, 
                columns=[f'bert_pca_{i}' for i in range(max_bert_dim)]
            )
            feature_parts.append(bert_df)
            
            if verbose:
                explained_var = self.pca.explained_variance_ratio_.sum()
                print(f"  BERT: 768 â†’ {max_bert_dim}ì°¨ì› (ì •ë³´ë³´ì¡´: {explained_var:.2%})")
        
        # === 2. í•µì‹¬ ê°ì„± í”¼ì²˜ë§Œ ===
        sentiment_cols = ['positive', 'negative', 'sentiment_score']
        available_sentiment = [col for col in sentiment_cols if col in df.columns]
        
        if available_sentiment:
            sentiment_df = df[available_sentiment].fillna(0).copy()
            
            # ê°„ë‹¨í•œ íŒŒìƒ í”¼ì²˜ 1ê°œë§Œ
            if 'positive' in sentiment_df.columns and 'negative' in sentiment_df.columns:
                sentiment_df['sentiment_balance'] = (
                    sentiment_df['positive'] - sentiment_df['negative']
                ) / (sentiment_df['positive'] + sentiment_df['negative'] + 1e-8)
            
            feature_parts.append(sentiment_df)
            if verbose:
                print(f"  ê°ì„±: {len(sentiment_df.columns)}ê°œ í”¼ì²˜")
        
        # === 3. ì˜ë¯¸ìˆëŠ” ë©”íƒ€ í”¼ì²˜ ===
        meta_features = []
        
        # ê°ì„± ê°•ë„ (positive + negative)
        if 'positive' in df.columns and 'negative' in df.columns:
            sentiment_intensity = df['positive'].fillna(0) + df['negative'].fillna(0)
            meta_features.append(('sentiment_intensity', sentiment_intensity))
        
        # ê°ì„± í™•ì‹ ë„ (max - min)
        sentiment_cols_available = [col for col in ['positive', 'negative', 'neutral'] if col in df.columns]
        if len(sentiment_cols_available) >= 2:
            sentiment_values = df[sentiment_cols_available].fillna(0)
            sentiment_confidence = sentiment_values.max(axis=1) - sentiment_values.min(axis=1)
            meta_features.append(('sentiment_confidence', sentiment_confidence))
        
        if meta_features:
            meta_df = pd.DataFrame({name: values for name, values in meta_features}, index=df.index)
            feature_parts.append(meta_df)
            if verbose:
                print(f"  ì˜ë¯¸ìˆëŠ” ë©”íƒ€: {len(meta_df.columns)}ê°œ í”¼ì²˜")
        
        # í”¼ì²˜ ê²°í•©
        X = pd.concat(feature_parts, axis=1)
        X = X.replace([np.inf, -np.inf], np.nan).fillna(0)
        
        self.feature_names = X.columns.tolist()
        if verbose:
            print(f"  ìµœì¢…: {len(X.columns)}ê°œ í”¼ì²˜ (ê³¼ì í•© ë°©ì§€)")
        
        return X
    
    def create_comprehensive_individual_targets(self, df, verbose=True):
        """
        Comprehensive ë°©ì‹ìœ¼ë¡œ ê°œë³„ ë‰´ìŠ¤ ì ìˆ˜ ìƒì„± (ë¹ˆë„ ì œì™¸)
        ê°ì„±(50%) + ê¸°ìˆ ì ì§€í‘œ(30%) + BERTê°•ë„(20%)
        """
        if verbose:
            print("ğŸ¯ Comprehensive ë°©ì‹ ê°œë³„ ë‰´ìŠ¤ ì ìˆ˜ ìƒì„±")
        
        individual_scores = []
        
        for idx, row in df.iterrows():
            # === 1. ê°ì„± ì»´í¬ë„ŒíŠ¸ (50%) ===
            sentiment_score = row.get('sentiment_score', 0)  # -1 ~ +1
            positive = row.get('positive', 0)
            negative = row.get('negative', 0)
            neutral = row.get('neutral', 0)
            
            # ê°ì„± ê· í˜• ì ìˆ˜ (-1 ~ +1)
            total_emotion = positive + negative + neutral + 1e-8
            emotion_balance = (positive - negative) / total_emotion
            
            # ê°ì„± ê°•ë„ (0 ~ 1)
            emotion_intensity = (positive + negative) / total_emotion
            
            # ê°ì„± ì»´í¬ë„ŒíŠ¸ ì ìˆ˜ (0~100)
            sentiment_component = (
                (sentiment_score + 1) / 2 * 40 +      # sentiment_score: 40ì 
                (emotion_balance + 1) / 2 * 30 +      # emotion_balance: 30ì   
                emotion_intensity * 30                 # emotion_intensity: 30ì 
            ) / 2  # 50% ë¹„ì¤‘
            
            # === 2. ê¸°ìˆ ì  ì§€í‘œ ì»´í¬ë„ŒíŠ¸ (30%) ===
            momentum_score = row.get('momentum_score', 50)  # 0~100
            volume_score = row.get('volume_score', 50)      # 0~100
            
            technical_component = (momentum_score * 0.7 + volume_score * 0.3) * 0.3
            
            # === 3. BERT ê°•ë„ ì»´í¬ë„ŒíŠ¸ (20%) ===
            # BERT ì„ë² ë”©ì˜ ì ˆëŒ“ê°’ í‰ê· ìœ¼ë¡œ ê°ì„± ê°•ë„ ì¸¡ì •
            bert_cols = [f'finbert_{i}' for i in range(768) if f'finbert_{i}' in df.columns and not pd.isna(row.get(f'finbert_{i}', np.nan))]
            
            if bert_cols:
                bert_values = np.array([row.get(col, 0) for col in bert_cols])
                bert_intensity = np.mean(np.abs(bert_values))  # ì ˆëŒ“ê°’ í‰ê· 
                bert_component = min(bert_intensity * 100, 100) * 0.2  # ìµœëŒ€ 20ì 
            else:
                bert_component = 10  # ê¸°ë³¸ê°’
            
            # === ìµœì¢… ì ìˆ˜ í•©ì‚° ===
            final_score = sentiment_component + technical_component + bert_component
            final_score = np.clip(final_score, 0, 100)
            
            individual_scores.append(final_score)
        
        individual_scores = np.array(individual_scores)
        
        if verbose:
            print(f"  ê°œë³„ ì ìˆ˜ ë¶„í¬: {individual_scores.min():.1f} ~ {individual_scores.max():.1f}")
            print(f"  í‰ê· : {individual_scores.mean():.1f} Â± {individual_scores.std():.1f}")
            print(f"  ì ìˆ˜ êµ¬ì„±: ê°ì„±(50%) + ê¸°ìˆ ì ì§€í‘œ(30%) + BERTê°•ë„(20%)")
        
        return individual_scores
    
    def create_targets_from_existing_comprehensive(self, df, stock_scores_dict, verbose=True):
        """
        ê¸°ì¡´ comprehensive ì ìˆ˜ë¥¼ ê°œë³„ ë‰´ìŠ¤ì— ì ìš© (ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€)
        """
        if verbose:
            print("ğŸ¯ ê¸°ì¡´ comprehensive ì ìˆ˜ ê¸°ë°˜ ê°œë³„ ë‰´ìŠ¤ íƒ€ê²Ÿ ìƒì„±")
        
        individual_scores = []
        matched_count = 0
        
        for idx, row in df.iterrows():
            stock_name = row.get('original_stock', '')
            
            if stock_name in stock_scores_dict:
                base_score = stock_scores_dict[stock_name]
                matched_count += 1
                
                # ì‘ì€ ëœë¤ ë…¸ì´ì¦ˆ ì¶”ê°€ (Â±3ì )
                noise = np.random.normal(0, 3)
                individual_score = base_score + noise
                individual_score = np.clip(individual_score, 0, 100)
            else:
                individual_score = 50  # ì¤‘ë¦½
            
            individual_scores.append(individual_score)
        
        individual_scores = np.array(individual_scores)
        
        if verbose:
            print(f"  ë§¤ì¹­ë¥ : {matched_count}/{len(df)} ({matched_count/len(df)*100:.1f}%)")
            print(f"  ì ìˆ˜ ë¶„í¬: {individual_scores.min():.1f} ~ {individual_scores.max():.1f}")
            print(f"  í‰ê· : {individual_scores.mean():.1f} Â± {individual_scores.std():.1f}")
        
        return individual_scores
    
    def train_individual(self, df, stock_scores_dict, verbose=True):
        """
        ê°œë³„ ë‰´ìŠ¤ ì ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨ (ê¸°ì¡´ comprehensive ì ìˆ˜ ê¸°ë°˜)
        """
        if verbose:
            print("\nğŸ¯ 1ë‹¨ê³„: ê°œë³„ ë‰´ìŠ¤ ì ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨ (ê¸°ì¡´ comprehensive ê¸°ì¤€)")
            print("="*60)
        
        # í”¼ì²˜ ë° íƒ€ê²Ÿ ìƒì„± (ê¸°ì¡´ comprehensive ì ìˆ˜ ì‚¬ìš©)
        X = self.create_individual_features(df, max_bert_dim=50, verbose=verbose)
        y = self.create_targets_from_existing_comprehensive(df, stock_scores_dict, verbose=verbose)
        
        # ì „ì²´ ë°ì´í„°ë¡œ í›ˆë ¨
        X_train = X
        y_train = y
        
        # ì„±ëŠ¥ ê²€ì¦ìš© ìƒ˜í”Œë§
        test_sample = X.sample(frac=0.2, random_state=42)
        X_test = test_sample
        y_test = y[test_sample.index]
        
        if verbose:
            print(f"\nğŸ“Š ë°ì´í„° ì‚¬ìš©:")
            print(f"  ì „ì²´ í›ˆë ¨: {len(X_train):,}ê°œ")
            print(f"  ì„±ëŠ¥ ê²€ì¦ìš© ìƒ˜í”Œ: {len(X_test):,}ê°œ")
        
        # ê³¼ì í•© ë°©ì§€ ìµœì í™” íŒŒë¼ë¯¸í„°
        params = {
            'objective': 'regression',
            'metric': 'mae',
            'n_estimators': 100,
            'max_depth': 4,
            'num_leaves': 15,
            'learning_rate': 0.1,
            'feature_fraction': 0.8,
            'bagging_fraction': 0.8,
            'min_data_in_leaf': 30,
            'reg_alpha': 0.3,
            'reg_lambda': 0.3,
            'random_state': 42,
            'verbosity': -1
        }
        
        # ëª¨ë¸ í›ˆë ¨
        self.model = lgb.LGBMRegressor(**params)
        self.model.fit(
            X_train, y_train,
            eval_set=[(X_test, y_test)],
            callbacks=[lgb.early_stopping(20, verbose=False)]
        )
        
        # ì„±ëŠ¥ í‰ê°€
        y_pred_train = self.model.predict(X_train)
        y_pred_test = self.model.predict(X_test)
        
        train_mae = mean_absolute_error(y_train, y_pred_train)
        test_mae = mean_absolute_error(y_test, y_pred_test)
        test_r2 = r2_score(y_test, y_pred_test)
        gap = test_mae - train_mae
        
        if verbose:
            print(f"\nğŸ† ê°œë³„ ë‰´ìŠ¤ ëª¨ë¸ ì„±ëŠ¥:")
            print(f"  í›ˆë ¨ MAE: {train_mae:.2f}")
            print(f"  í…ŒìŠ¤íŠ¸ MAE: {test_mae:.2f}")
            print(f"  í…ŒìŠ¤íŠ¸ RÂ²: {test_r2:.4f}")
            print(f"  ê³¼ì í•© GAP: {gap:.2f}")
            
            if gap < 2.0:
                print(f"  âœ… ê³¼ì í•© ì˜ ì–µì œë¨!")
            else:
                print(f"  ğŸŸ¡ ì¶”ê°€ ì •ê·œí™” ê³ ë ¤")
        
        return {
            'train_mae': train_mae,
            'test_mae': test_mae,
            'test_r2': test_r2,
            'gap': gap
        }
    
    def predict_individual(self, news_data):
        """ê°œë³„ ë‰´ìŠ¤ ì ìˆ˜ ì˜ˆì¸¡"""
        if self.model is None:
            raise ValueError("ê°œë³„ ë‰´ìŠ¤ ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        
        df_input = pd.DataFrame([news_data])
        X = self.create_individual_features(df_input, max_bert_dim=50, verbose=False)  # ë™ì¼í•œ ì°¨ì›
        score = self.model.predict(X)[0]
        return np.clip(score, 0, 100)

class StockAggregateScorer:
    """
    ğŸ¯ 2ë‹¨ê³„: ì¢…ëª©ë³„ ë‰´ìŠ¤ ì§‘ê³„ + ê¸°ìˆ ì  ì§€í‘œ â†’ ì¢…ëª© ìµœì¢… ì ìˆ˜
    """
    
    def __init__(self):
        self.individual_scorer = None
        self.aggregation_model = None
        print("âœ… ì¢…ëª© ì§‘ê³„ ì ìˆ˜ê¸° ì´ˆê¸°í™” (ë‰´ìŠ¤+ê¸°ìˆ ì ì§€í‘œ)!")
    
    def aggregate_stock_news(self, df, individual_scorer, days_window=30, verbose=True):
        """
        ì¢…ëª©ë³„ ë‰´ìŠ¤ë¥¼ ì§‘ê³„í•´ì„œ ì¢…ëª© ì ìˆ˜ ìƒì„± (ì‹œê°„ ê°€ì¤‘ì¹˜ ì ìš©)
        """
        if verbose:
            print(f"\nğŸ”„ 2ë‹¨ê³„: ì¢…ëª©ë³„ ë‰´ìŠ¤ ì§‘ê³„ (ìµœê·¼ {days_window}ì¼, ì‹œê°„ ê°€ì¤‘)")
            print("="*60)
        
        self.individual_scorer = individual_scorer
        
        # ëª¨ë“  ë‰´ìŠ¤ì— ê°œë³„ ì ìˆ˜ í• ë‹¹
        if verbose:
            print("ğŸ“Š ëª¨ë“  ë‰´ìŠ¤ì— ê°œë³„ ì ìˆ˜ ë¶€ì—¬ ì¤‘...")
        
        individual_scores = []
        for idx, row in df.iterrows():
            score = individual_scorer.predict_individual(row)
            individual_scores.append(score)
        
        df = df.copy()
        df['individual_score'] = individual_scores
        
        # ë‚ ì§œ ì²˜ë¦¬
        if 'news_date' in df.columns:
            df['news_date'] = pd.to_datetime(df['news_date'])
        else:
            # ì„ì‹œ ë‚ ì§œ ìƒì„±
            df['news_date'] = pd.date_range(end='2024-01-01', periods=len(df), freq='H')
        
        # ì¢…ëª©ë³„ ì§‘ê³„ (ì‹œê°„ ë¶ˆì¼ì¹˜ í•´ê²°)
        stock_scores = []
        current_date = df['news_date'].max()
        
        if verbose:
            print(f"  ê¸°ì¤€ ë‚ ì§œ: {current_date}")
        
        for stock in df['original_stock'].unique():
            stock_news = df[df['original_stock'] == stock].copy()
            
            if len(stock_news) == 0:
                continue
            
            # ğŸ¯ ì‹œê°„ ë¶ˆì¼ì¹˜ í•´ê²°: ìµœê·¼ ë‰´ìŠ¤ ìš°ì„ ìˆœìœ„
            stock_news = stock_news.sort_values('news_date', ascending=False)
            
            # comprehensive ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ëª¨ë“  ë‰´ìŠ¤ ì‚¬ìš©
            recent_news = stock_news  # ëª¨ë“  ë‰´ìŠ¤ ì‚¬ìš©
            
            if len(recent_news) == 0:
                continue
            
            # comprehensive ë°©ì‹ê³¼ ë™ì¼í•œ ì‹ ì„ ë„ ê°€ì¤‘ì¹˜
            # ê° ì¢…ëª© ë‚´ì—ì„œ ìƒëŒ€ì  ì‹ ì„ ë„ ê³„ì‚° (0~1)
            days_from_latest = (current_date - recent_news['news_date']).dt.days
            max_days = days_from_latest.max()
            
            if max_days == 0:  # ëª¨ë“  ë‰´ìŠ¤ê°€ ê°™ì€ ë‚ 
                freshness_weights = np.ones(len(recent_news))
            else:
                freshness_weights = 1 - (days_from_latest / max_days)  # 1~0
            
            # ì •ê·œí™”
            if freshness_weights.sum() > 0:
                time_weights = freshness_weights / freshness_weights.sum()
            else:
                time_weights = np.ones(len(recent_news)) / len(recent_news)
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            aggregated_score = np.average(recent_news['individual_score'], weights=time_weights)
            
            # ë°ì´í„° í’ˆì§ˆ ì§€í‘œ
            avg_days_ago = np.average(days_from_latest, weights=time_weights)
            freshness_score = np.average(freshness_weights, weights=time_weights)  # í‰ê·  ì‹ ì„ ë„
            
            stock_scores.append({
                'stock_name': stock,
                'final_score': aggregated_score,
                'news_count': len(recent_news),
                'score_std': recent_news['individual_score'].std(),
                'latest_news_date': recent_news['news_date'].max(),
                'avg_days_ago': avg_days_ago,
                'freshness_score': freshness_score
            })
        
        result_df = pd.DataFrame(stock_scores)
        
        if verbose:
            print(f"  ì§‘ê³„ ì™„ë£Œ: {len(result_df)}ê°œ ì¢…ëª©")
            print(f"  ì ìˆ˜ ë¶„í¬: {result_df['final_score'].min():.1f} ~ {result_df['final_score'].max():.1f}")
            print(f"  í‰ê·  ë‰´ìŠ¤ ìˆ˜: {result_df['news_count'].mean():.1f}ê°œ/ì¢…ëª©")
            print(f"  í‰ê·  ì‹ ì„ ë„: {result_df['freshness_score'].mean():.3f} (1.0=ìµœì‹ )")
            print(f"  í‰ê·  ê²½ê³¼ì¼: {result_df['avg_days_ago'].mean():.1f}ì¼")
        
        return result_df
    
    def create_stock_level_features(self, aggregated_news_df, df_original, verbose=True):
        """
        ë‰´ìŠ¤ ì§‘ê³„ ì ìˆ˜ + ê¸°ìˆ ì  ì§€í‘œ ê²°í•©í•˜ì—¬ ì¢…ëª© ë ˆë²¨ í”¼ì²˜ ìƒì„±
        """
        if verbose:
            print("\nğŸ”§ 2ë‹¨ê³„: ë‰´ìŠ¤ ì§‘ê³„ + ê¸°ìˆ ì  ì§€í‘œ ê²°í•©")
            print("="*50)
        
        # ğŸš¨ Data Leakage ë°©ì§€: ê¸°ìˆ ì  ì§€í‘œ ì œì™¸
        # comprehensiveì—ì„œ momentum_score, volume_scoreë¥¼ 30% ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ ì œì™¸
        if verbose:
            print(f"  ê¸°ìˆ ì  ì§€í‘œ: Data Leakage ë°©ì§€ë¥¼ ìœ„í•´ ì œì™¸")
        
        technical_cols = []  # ê¸°ìˆ ì  ì§€í‘œ ì™„ì „ ì œì™¸
        
        # ì¢…ëª©ë³„ ê¸°ìˆ ì  ì§€í‘œ ì§‘ê³„ (ìµœì‹ ê°’ ì‚¬ìš©)
        stock_technical_features = []
        
        for stock in aggregated_news_df['stock_name'].unique():
            stock_data = df_original[df_original['original_stock'] == stock]
            
            if len(stock_data) == 0:
                continue
            
            # ìµœì‹  ê¸°ìˆ ì  ì§€í‘œê°’ ì‚¬ìš©
            latest_tech_data = stock_data.iloc[-1] if len(stock_data) > 0 else None
            
            # ë‰´ìŠ¤ ì§‘ê³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            stock_news_info = aggregated_news_df[aggregated_news_df['stock_name'] == stock].iloc[0]
            
            stock_feature = {
                'stock_name': stock,
                'news_aggregated_score': stock_news_info['final_score'],
                'news_count': stock_news_info['news_count'],
                'news_score_std': stock_news_info['score_std']
            }
            
            # ğŸš¨ ê¸°ìˆ ì  ì§€í‘œ ë° ìƒí˜¸ì‘ìš© í”¼ì²˜ ì œê±° (Data Leakage ë°©ì§€)
            # ë‰´ìŠ¤ ê´€ë ¨ í”¼ì²˜ë§Œ ì‚¬ìš©
            
            stock_technical_features.append(stock_feature)
        
        result_df = pd.DataFrame(stock_technical_features)
        
        if verbose:
            print(f"  ìµœì¢… í”¼ì²˜ ìˆ˜: {len(result_df.columns)}ê°œ (ë‰´ìŠ¤ í”¼ì²˜ë§Œ)")
            print(f"  ì²˜ë¦¬ëœ ì¢…ëª© ìˆ˜: {len(result_df)}ê°œ")
            print(f"  í”¼ì²˜ ëª©ë¡: {list(result_df.columns)}")
            print(f"  ğŸ“ Data Leakage ë°©ì§€: ê¸°ìˆ ì  ì§€í‘œ í”¼ì²˜ ì œì™¸ë¨")
        
        return result_df
    
    def train_final_aggregation_model(self, stock_features_df, target_scores_df, verbose=True):
        """
        ë‰´ìŠ¤+ê¸°ìˆ ì ì§€í‘œ ê²°í•© â†’ ìµœì¢… ì¢…ëª© ì ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨
        """
        if verbose:
            print("\nğŸ¯ 2ë‹¨ê³„ ëª¨ë¸ í›ˆë ¨: ë‰´ìŠ¤ì§‘ê³„+ê¸°ìˆ ì ì§€í‘œ â†’ ìµœì¢…ì ìˆ˜")
            print("="*60)
        
        # íƒ€ê²Ÿ ì ìˆ˜ì™€ ë§¤ì¹­
        merged_df = stock_features_df.merge(
            target_scores_df[['stock_name', 'final_score']], 
            on='stock_name', 
            how='inner'
        )
        
        if len(merged_df) == 0:
            raise ValueError("íƒ€ê²Ÿ ì ìˆ˜ì™€ ë§¤ì¹­ë˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤!")
        
        # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
        feature_cols = [col for col in merged_df.columns 
                       if col not in ['stock_name', 'final_score']]
        
        X = merged_df[feature_cols].fillna(0)
        y = merged_df['final_score'].values
        
        if verbose:
            print(f"  í›ˆë ¨ ë°ì´í„°: {len(X)}ê°œ ì¢…ëª©")
            print(f"  í”¼ì²˜ ìˆ˜: {len(feature_cols)}ê°œ")
            print(f"  íƒ€ê²Ÿ ë¶„í¬: {y.min():.1f} ~ {y.max():.1f}")
        
        # ë°ì´í„° ë¶„í• 
        if len(X) > 10:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.3, random_state=42
            )
        else:
            X_train, X_test = X, X
            y_train, y_test = y, y
        
        # 2ë‹¨ê³„ ëª¨ë¸ íŒŒë¼ë¯¸í„° (ì ë‹¹í•œ ë³µì¡ë„)
        params = {
            'objective': 'regression',
            'metric': 'mae',
            'n_estimators': 100,        # ì ë‹¹í•œ ë³µì¡ë„
            'max_depth': 4,             # ì ë‹¹í•œ ê¹Šì´
            'num_leaves': 15,           # ì ë‹¹í•œ ë¦¬í”„ ìˆ˜
            'learning_rate': 0.1,       # ì¼ë°˜ì ì¸ í•™ìŠµë¥ 
            'min_data_in_leaf': 5,      # ì ë‹¹í•œ ìµœì†Œê°’
            'reg_alpha': 0.3,           # ì ë‹¹í•œ L1 ì •ê·œí™”
            'reg_lambda': 0.3,          # ì ë‹¹í•œ L2 ì •ê·œí™”
            'feature_fraction': 0.8,    # í”¼ì²˜ ìƒ˜í”Œë§
            'random_state': 42,
            'verbosity': -1
        }
        
        # ëª¨ë¸ í›ˆë ¨
        self.aggregation_model = lgb.LGBMRegressor(**params)
        self.aggregation_model.fit(X_train, y_train)
        
        # ì„±ëŠ¥ í‰ê°€
        y_pred_train = self.aggregation_model.predict(X_train)
        y_pred_test = self.aggregation_model.predict(X_test)
        
        train_mae = mean_absolute_error(y_train, y_pred_train)
        test_mae = mean_absolute_error(y_test, y_pred_test)
        test_r2 = r2_score(y_test, y_pred_test)
        
        if verbose:
            print(f"\nğŸ† 2ë‹¨ê³„ ëª¨ë¸ ì„±ëŠ¥:")
            print(f"  í›ˆë ¨ MAE: {train_mae:.2f}")
            print(f"  í…ŒìŠ¤íŠ¸ MAE: {test_mae:.2f}")
            print(f"  í…ŒìŠ¤íŠ¸ RÂ²: {test_r2:.4f}")
            
            # í”¼ì²˜ ì¤‘ìš”ë„
            if hasattr(self.aggregation_model, 'feature_importances_'):
                importance_df = pd.DataFrame({
                    'feature': feature_cols,
                    'importance': self.aggregation_model.feature_importances_
                }).sort_values('importance', ascending=False)
                
                print(f"\nğŸ“Š í”¼ì²˜ ì¤‘ìš”ë„:")
                for _, row in importance_df.iterrows():
                    print(f"  {row['feature']:25s}: {row['importance']:6.0f}")
        
        return {
            'train_mae': train_mae,
            'test_mae': test_mae,
            'test_r2': test_r2,
            'feature_importance': importance_df if 'importance_df' in locals() else None
        }
    
    def predict_final_stock_score(self, stock_name, recent_news_list, technical_indicators, verbose=True):
        """
        ì¢…ëª©ì˜ ë‰´ìŠ¤ë“¤ + ê¸°ìˆ ì  ì§€í‘œ â†’ ìµœì¢… ì¢…ëª© ì ìˆ˜ ì˜ˆì¸¡
        """
        if self.individual_scorer is None or self.aggregation_model is None:
            raise ValueError("ëª¨ë¸ë“¤ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        
        if verbose:
            print(f"ğŸ¯ ì¢…ëª© '{stock_name}' ìµœì¢… ì ìˆ˜ ì˜ˆì¸¡")
        
        # 1ë‹¨ê³„: ê°œë³„ ë‰´ìŠ¤ ì ìˆ˜ë“¤
        individual_scores = []
        for i, news in enumerate(recent_news_list):
            score = self.individual_scorer.predict_individual(news)
            individual_scores.append(score)
            if verbose:
                print(f"  ë‰´ìŠ¤ {i+1} ì ìˆ˜: {score:.1f}")
        
        # ë‰´ìŠ¤ ì§‘ê³„ ì ìˆ˜
        if individual_scores:
            news_aggregated_score = np.mean(individual_scores)
            news_score_std = np.std(individual_scores) if len(individual_scores) > 1 else 0
        else:
            news_aggregated_score = 50  # ì¤‘ë¦½
            news_score_std = 0
        
        if verbose:
            print(f"  ë‰´ìŠ¤ ì§‘ê³„ ì ìˆ˜: {news_aggregated_score:.1f} Â± {news_score_std:.1f}")
        
        # 2ë‹¨ê³„ í”¼ì²˜ ìƒì„±
        stock_features = {
            'news_aggregated_score': news_aggregated_score,
            'news_count': len(recent_news_list),
            'news_score_std': news_score_std
        }
        
        # ğŸš¨ ê¸°ìˆ ì  ì§€í‘œ í”¼ì²˜ ì œê±° (Data Leakage ë°©ì§€)
        # ë‰´ìŠ¤ í”¼ì²˜ë§Œ ì‚¬ìš©
        
        # 2ë‹¨ê³„ ëª¨ë¸ë¡œ ìµœì¢… ì˜ˆì¸¡
        feature_df = pd.DataFrame([stock_features])
        
        # í›ˆë ¨ ì‹œ ì‚¬ìš©ëœ í”¼ì²˜ì™€ ë§ì¶”ê¸°
        expected_features = self.aggregation_model.feature_names_in_
        for col in expected_features:
            if col not in feature_df.columns:
                feature_df[col] = 0  # ëˆ„ë½ëœ í”¼ì²˜ëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬
        
        feature_df = feature_df[expected_features]  # ìˆœì„œ ë§ì¶”ê¸°
        
        final_score = self.aggregation_model.predict(feature_df)[0]
        final_score = np.clip(final_score, 0, 100)
        
        if verbose:
            print(f"  ê¸°ìˆ ì  ì§€í‘œ: ì œì™¸ë¨ (Data Leakage ë°©ì§€)")
            print(f"ğŸ† ìµœì¢… ì¢…ëª© ì ìˆ˜: {final_score:.1f}/100")
        
        return {
            'stock_name': stock_name,
            'individual_news_scores': individual_scores,
            'news_aggregated_score': news_aggregated_score,
            'technical_indicators': technical_indicators,
            'final_score': final_score,
            'news_count': len(recent_news_list)
        }
        
    def save_models(self, individual_path, aggregate_path=None):
        """ëª¨ë¸ ì €ì¥"""
        if self.individual_scorer:
            joblib.dump(self.individual_scorer, individual_path)
            print(f"ğŸ’¾ ê°œë³„ ë‰´ìŠ¤ ëª¨ë¸ ì €ì¥: {individual_path}")

class TwoStageNewsSystem:
    """
    ğŸš€ 2ë‹¨ê³„ ë‰´ìŠ¤ ì ìˆ˜ ì˜ˆì¸¡ í†µí•© ì‹œìŠ¤í…œ
    """
    
    def __init__(self):
        self.stage1 = IndividualNewsScorer()
        self.stage2 = StockAggregateScorer()
        print("ğŸš€ 2ë‹¨ê³„ ë‰´ìŠ¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def train_full_system(self, df, target_scores_df, verbose=True):
        """ì „ì²´ 2ë‹¨ê³„ ì‹œìŠ¤í…œ í›ˆë ¨ (ë‰´ìŠ¤+ê¸°ìˆ ì ì§€í‘œ)"""
        if verbose:
            print("\nğŸš€ 2ë‹¨ê³„ ë‰´ìŠ¤+ê¸°ìˆ ì ì§€í‘œ ì‹œìŠ¤í…œ í›ˆë ¨")
            print("="*70)
        
        # ì¢…ëª© ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        stock_scores_dict = dict(zip(target_scores_df['stock_name'], target_scores_df['final_score']))
        
        # 1ë‹¨ê³„: ê°œë³„ ë‰´ìŠ¤ ì ìˆ˜ ì˜ˆì¸¡ í›ˆë ¨ (ê¸°ì¡´ comprehensive ê¸°ì¤€)
        stage1_results = self.stage1.train_individual(df, stock_scores_dict, verbose=verbose)
        
        # 2-1ë‹¨ê³„: ì¢…ëª©ë³„ ë‰´ìŠ¤ ì§‘ê³„
        aggregated_news_results = self.stage2.aggregate_stock_news(
            df, self.stage1, days_window=30, verbose=verbose
        )
        
        # 2-2ë‹¨ê³„: ë‰´ìŠ¤ ì§‘ê³„ + ê¸°ìˆ ì  ì§€í‘œ ê²°í•©
        stock_features_df = self.stage2.create_stock_level_features(
            aggregated_news_results, df, verbose=verbose
        )
        
        # 2-3ë‹¨ê³„: ìµœì¢… ì§‘ê³„ ëª¨ë¸ í›ˆë ¨
        stage2_results = self.stage2.train_final_aggregation_model(
            stock_features_df, target_scores_df, verbose=verbose
        )
        
        return {
            'stage1_results': stage1_results,
            'stage2_results': stage2_results,
            'aggregated_stocks': aggregated_news_results,  # í‚¤ ì´ë¦„ í†µì¼
            'stock_features': stock_features_df
        }
    
    def predict_stock_score(self, stock_name, recent_news_list, verbose=True):
        """ì¢…ëª©ì˜ ìµœê·¼ ë‰´ìŠ¤ë“¤ë¡œë¶€í„° ì¢…ëª© ì ìˆ˜ ì˜ˆì¸¡"""
        if verbose:
            print(f"ğŸ¯ ì¢…ëª© '{stock_name}' ì ìˆ˜ ì˜ˆì¸¡")
        
        # ê° ë‰´ìŠ¤ë³„ ê°œë³„ ì ìˆ˜
        individual_scores = []
        for news in recent_news_list:
            score = self.stage1.predict_individual(news)
            individual_scores.append(score)
            if verbose:
                print(f"  ë‰´ìŠ¤ ì ìˆ˜: {score:.1f}")
        
        # ì§‘ê³„ ì ìˆ˜ (ë‹¨ìˆœ í‰ê· , ì‹¤ì œë¡œëŠ” ì‹œê°„ê°€ì¤‘ ë“± ì ìš© ê°€ëŠ¥)
        final_score = np.mean(individual_scores)
        
        if verbose:
            print(f"ğŸ† ìµœì¢… ì¢…ëª© ì ìˆ˜: {final_score:.1f}/100")
        
        return {
            'stock_name': stock_name,
            'individual_scores': individual_scores,
            'final_score': final_score,
            'news_count': len(recent_news_list)
        }

# =============================================================================
# ì‹¤í–‰ë¶€
# =============================================================================
if __name__ == "__main__":
    try:
        print("ğŸš€ 2ë‹¨ê³„ ë‰´ìŠ¤ ì ìˆ˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
        print("="*70)
        
        # ë°ì´í„° ë¡œë“œ
        news_csv_path = "/Users/inter4259/Desktop/news_full_features_robust.csv"
        scores_csv_path = "/Users/inter4259/Desktop/Programming/hek_credit/sentiment/model/time/stock_comprehensive_scores.csv"
        
        df_news = pd.read_csv(news_csv_path)
        df_scores = pd.read_csv(scores_csv_path)
        
        print(f"ğŸ“Š ë‰´ìŠ¤ ë°ì´í„°: {len(df_news):,}ê°œ")
        print(f"ğŸ“Š íƒ€ê²Ÿ ì ìˆ˜: {len(df_scores):,}ê°œ ì¢…ëª©")
        
        # 2ë‹¨ê³„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° í›ˆë ¨
        system = TwoStageNewsSystem()
        results = system.train_full_system(
            df_news,                 # ì „ì²´ ë°ì´í„° ì‚¬ìš©
            df_scores, 
            verbose=True
        )
        
        # ê²°ê³¼ ì €ì¥
        model_path = "/Users/inter4259/Desktop/Programming/hek_credit/sentiment/model/time/two_stage_system.pkl"
        system.stage2.save_models(model_path)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ì§‘ê³„ëœ ì¢…ëª© ì ìˆ˜:")
        stock_results = results['aggregated_stocks']
        print(stock_results.head(10))
        
        print(f"\nâœ… 2ë‹¨ê³„ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()