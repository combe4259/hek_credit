# =============================================================================
# ìµœì¢… ë‰´ìŠ¤ ì ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ (ì„±ëŠ¥ ì¢‹ì§€ë§Œ ì‹œê³„ì—´ ì•ˆ ì”€. ìƒìš©í™” ë¶ˆê°€)
# KR-FinBERT + ë°ì´í„° ëˆ„ìˆ˜ ì—†ëŠ” ë£°ì…‹ + LightGBM + Optuna íŠœë‹ (ì˜¤ë¥˜ ìˆ˜ì •)
# =============================================================================
# !pip install sentence-transformers optuna lightgbm scikit-learn pandas joblib -q

import pandas as pd
import numpy as np
import optuna
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import lightgbm as lgb
from sentence_transformers import SentenceTransformer
import joblib
import warnings
warnings.filterwarnings('ignore')

class BetterNewsScorePredictor:
    def __init__(self, bert_model_name='snunlp/KR-FinBERT'):
        self.model = None
        self.feature_names = None
        print(f"ğŸ“š KR-FinBERT ëª¨ë¸ ë¡œë”© ì¤‘: {bert_model_name}")
        self.bert_model = SentenceTransformer(bert_model_name)
        print("âœ… KR-FinBERT ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

    def _composite_signal_to_score(self, composite_signal):
        score = 5 * (composite_signal + 1)
        return np.clip(score, 0, 10)

    def _score_to_category(self, score):
        if score >= 8.5: return "ê°•ë ¥í˜¸ì¬"
        elif score >= 7.0: return "í˜¸ì¬"
        elif score >= 6.0: return "ì•½ê°„í˜¸ì¬"
        elif score >= 4.0: return "ì¤‘ë¦½"
        elif score >= 3.0: return "ì•½ê°„ì•…ì¬"
        elif score >= 1.5: return "ì•…ì¬"
        else: return "ê°•ë ¥ì•…ì¬"

    def _create_features(self, df):
        print("ğŸ› ï¸ ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ í”¼ì²˜ ìƒì„± ì‹œì‘...")
        final_feature_parts = []

        # --- 1. KR-FinBERT ì„ë² ë”© í”¼ì²˜ (ë°°ì¹˜ ì²˜ë¦¬) ---
        text_column = 'content' if 'content' in df.columns else 'title'
        texts = df[text_column].astype(str).tolist()
        print(f"ğŸ§  '{text_column}' ì»¬ëŸ¼ ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = self.bert_model.encode(
            texts,
            batch_size=32,
            show_progress_bar=True,
            convert_to_numpy=True
        )
        X_bert = pd.DataFrame(embeddings, index=df.index)
        X_bert.columns = [f'finbert_{i}' for i in range(X_bert.shape[1])]
        final_feature_parts.append(X_bert)

        # --- 2. ê°ì„± ë¶„ì„ í”¼ì²˜ ---
        sentiment_cols = ['positive', 'negative', 'neutral', 'sentence_count']
        sentiment_features = df[sentiment_cols].copy()
        total_emotion = (sentiment_features['positive'] + sentiment_features['negative']).replace(0, 1e-8)
        sentiment_features['emotion_balance'] = (sentiment_features['positive'] - sentiment_features['negative']) / total_emotion
        final_feature_parts.append(sentiment_features)

        # --- 3. ë£°ì…‹ í”¼ì²˜ ---
        ruleset_cols = ['momentum_score', 'volume_score', 'rule_score']
        ruleset_features = df[ruleset_cols].fillna(50).copy()
        final_feature_parts.append(ruleset_features)

        # --- 4. ë§¥ë½ í”¼ì²˜ ---
        context_features = df[['sector', 'market_cap']].copy()
        cap_q1, cap_q3 = context_features['market_cap'].quantile([0.25, 0.75])
        context_features['market_cap_group'] = pd.cut(
            context_features['market_cap'],
            bins=[0, cap_q1, cap_q3, np.inf],
            labels=['Small', 'Mid', 'Large'],
            right=False
        )
        context_features_encoded = pd.get_dummies(context_features[['sector', 'market_cap_group']], dummy_na=True)
        final_feature_parts.append(context_features_encoded)

        # --- 5. ê²°í•© ---
        final_features = pd.concat(final_feature_parts, axis=1)
        print("ğŸ”— ëª¨ë“  í”¼ì²˜ ê²°í•© ì™„ë£Œ!")
        return final_features

    def train(self, df, model_save_path='final_model.pkl'):
        print("\nğŸ¤– ìµœì¢… ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        required_cols = ['composite_signal', 'content'] if 'content' in df.columns else ['composite_signal', 'title']
        train_df = df.dropna(subset=required_cols).copy()

        X = self._create_features(train_df)
        y = self._composite_signal_to_score(train_df['composite_signal'])
        self.feature_names = X.columns.tolist()

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        print(f"ğŸ“ˆ í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")

        def objective(trial):
            params = {
                'objective': 'regression_l1', 'metric': 'mae', 'verbosity': -1,
                'n_estimators': trial.suggest_int('n_estimators', 200, 1000, step=100),
                'max_depth': trial.suggest_int('max_depth', 5, 11),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, log=True),
                'num_leaves': trial.suggest_int('num_leaves', 31, 71),
                'subsample': trial.suggest_float('subsample', 0.7, 0.9),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 0.9),
                'random_state': 42,
                'n_jobs': -1
            }
            model = lgb.LGBMRegressor(**params)
            model.fit(
                X_train, y_train,
                eval_set=[(X_test, y_test)],
                callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]
            )
            y_pred = model.predict(X_test)
            return mean_absolute_error(y_test, y_pred)

        print("\nâ³ Optuna íŠœë‹ ì‹œì‘...")
        study = optuna.create_study(direction='minimize')
        study.optimize(objective, n_trials=30, show_progress_bar=True)

        print("\nâœ… ìµœì  íŒŒë¼ë¯¸í„°:", study.best_params)
        self.model = lgb.LGBMRegressor(**study.best_params)
        self.model.fit(X_train, y_train)

        y_pred = self.model.predict(X_test)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        direction_accuracy = np.mean((y_test > 5) == (y_pred > 5))
        print(f"\nğŸ“Š ìµœì¢… ì„±ëŠ¥ - MAE: {mae:.3f}, RÂ²: {r2:.3f}, ë°©í–¥ ì •í™•ë„: {direction_accuracy:.1%}")

        joblib.dump(self, model_save_path)
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")

    def predict(self, new_data):
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        X_new = self._create_features(new_data)
        for col in self.feature_names:
            if col not in X_new.columns:
                X_new[col] = 0
        X_new = X_new[self.feature_names]
        predicted_scores = self.model.predict(X_new)
        result_df = new_data.copy()
        result_df['predicted_score'] = np.clip(predicted_scores, 0, 10)
        result_df['predicted_category'] = result_df['predicted_score'].apply(self._score_to_category)
        return result_df

# =============================================================================
# ì‹¤í–‰
# =============================================================================
if __name__ == "__main__":
    from google.colab import drive
    print("ğŸ”— Google Drive ì—°ë™...")
    drive.mount('/content/drive', force_remount=True)

    try:
        DRIVE_DATA_PATH = "/content/drive/MyDrive/news_with_composite_signals.csv"
        print(f"ğŸ“‚ ë°ì´í„° ë¡œë”©: {DRIVE_DATA_PATH}")
        df_news = pd.read_csv(DRIVE_DATA_PATH)

        # --- í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ---
        if 'content' not in df_news.columns:
             raise ValueError("'content' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        if 'sector' not in df_news.columns:
            df_news['sector'] = 'Unknown'
        if 'market_cap' not in df_news.columns:
            df_news['market_cap'] = df_news['market_cap'].median() if not df_news['market_cap'].isnull().all() else 1e10

        predictor = FinalNewsScorePredictor()
        predictor.train(df_news)

        print("\nğŸš€ ìƒ˜í”Œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸")
        sample_news = df_news.dropna(subset=['composite_signal', 'content']).sample(5, random_state=101)
        predictions = predictor.predict(sample_news)

        for idx, row in predictions.iterrows():
            actual_score = predictor._composite_signal_to_score(row['composite_signal'])
            print(f"\nğŸ“° ìƒ˜í”Œ ë‰´ìŠ¤ (ticker: {row['ticker']})")
            print(f"  - ğŸ¤– AI ì˜ˆì¸¡ ì ìˆ˜: {row['predicted_score']:.2f} ({row['predicted_category']})")
            print(f"  - ğŸ“Š ì‹¤ì œ ì ìˆ˜: {actual_score:.2f}")

    except FileNotFoundError:
        print(f"\nâŒ ì˜¤ë¥˜: '{DRIVE_DATA_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
