"""
ë‰´ìŠ¤ ì „ì²˜ë¦¬ + í•œêµ­ì–´ ì¢…ëª©ëª… â†’ ì˜ì–´ í‹°ì»¤ ë§¤í•‘ (ë‹¨ìˆœí™” ë²„ì „)
"""

import json
import pandas as pd
import re
import os
from typing import Dict, List, Optional
from rapidfuzz import fuzz, process
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class NewsPreprocessor:
    """ë‰´ìŠ¤ ì „ì²˜ë¦¬ & ì¢…ëª© ë§¤í•‘ í´ë˜ìŠ¤"""

    def __init__(self, excel_file: str = "data/src/sp500_korean_stocks_with_symbols.xlsx"):
        self.stock_mapping = {}
        self.load_stock_mapping(excel_file)

    def load_stock_mapping(self, excel_file: str):
        """ì—‘ì…€ íŒŒì¼ì—ì„œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
        try:
            df = pd.read_excel(excel_file)
            df.columns = ['korean_name', 'symbol']  # ì²« ì—´: í•œêµ­ì–´, ë‘ ë²ˆì§¸ ì—´: ì˜ì–´

            # NaN ì œê±° í›„ strip
            df = df.dropna()
            for _, row in df.iterrows():
                korean = str(row['korean_name']).strip()
                symbol = str(row['symbol']).strip()
                if korean and symbol:
                    self.stock_mapping[korean] = symbol

            print(f"âœ… ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(self.stock_mapping)}ê°œ")

        except Exception as e:
            print(f"âŒ ì—‘ì…€ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def clean_content(self, text: str) -> str:
        """ë‰´ìŠ¤ ë‚´ìš© ì •ë¦¬ (ë¶ˆí•„ìš”í•œ ê³µë°±/íŠ¹ìˆ˜ë¬¸ì + ê´‘ê³ /ì¡ë‹¤í•œ ë¬¸êµ¬ ì œê±°)"""
        if not text:
            return ""

        # ê¸°ë³¸ ì •ë¦¬
        text = text.replace("\n", " ").replace("\r", " ")
        text = re.sub(r'\s+', ' ', text)

        # ê²Œí‹°ì´ë¯¸ì§€/ê´‘ê³ /ë²„íŠ¼ í…ìŠ¤íŠ¸ ì œê±°
        unwanted_patterns = [
            r"ì‚¬ì§„\s*=\s*ê²Œí‹°ì´ë¯¸ì§€\w*",       # "ì‚¬ì§„=ê²Œí‹°ì´ë¯¸ì§€ë±…í¬"
            r"ê²Œí‹°ì´ë¯¸ì§€ë±…í¬",                # "ê²Œí‹°ì´ë¯¸ì§€ë±…í¬"
            r"êµ¬ë…\s*\d+[ëª…]*",               # "êµ¬ë… 6,565ëª…"
            r"ì‘ì›\s*\d+",                   # "ì‘ì› 76,297"
            r"(ì¢‹ì•„ìš”|ìŠ¬í¼ìš”|í™”ë‚˜ìš”|íŒ¬ì´ì—ìš”|í›„ì†ê¸°ì‚¬ ì›í•´ìš”)\s*\d*",  # ê°ì • ë²„íŠ¼
            r"ë¬´ë£Œë§Œí™”\s*ë³´ëŸ¬ê°€ê¸°",            # "ë¬´ë£Œë§Œí™” ë³´ëŸ¬ê°€ê¸°"
            r"(í”„ë¡œì•¼êµ¬|ë°”ë¡œê°€ê¸°)",           # "í”„ë¡œì•¼êµ¬ ë°”ë¡œê°€ê¸°"
            r"ì–¸ë¡ ì‚¬\s*í™ˆ\s*ë°”ë¡œê°€ê¸°",         # ì–¸ë¡ ì‚¬ í™ˆ ë°”ë¡œê°€ê¸°
            r"ê¸°ì\s*êµ¬ë…",                   # "ë°°ìš°ê·¼ ê¸°ì êµ¬ë…"
        ]

        for pattern in unwanted_patterns:
            text = re.sub(pattern, "", text)

        return text.strip()

    def map_stock(self, stock_name: str) -> Optional[str]:
        """í•œêµ­ì–´ ì¢…ëª©ëª… â†’ ì˜ì–´ í‹°ì»¤ (ì •í™• ë§¤ì¹­ â†’ í¼ì§€ ë§¤ì¹­ ìˆœì„œ)"""
        if stock_name in self.stock_mapping:
            return self.stock_mapping[stock_name]

        # í¼ì§€ ë§¤ì¹­ (cutoff 85 ì´ìƒë§Œ)
        match = process.extractOne(stock_name, self.stock_mapping.keys(), scorer=fuzz.partial_ratio)
        if match and match[1] >= 85:
            print(f"ğŸ“ í¼ì§€ ë§¤ì¹­: '{stock_name}' â†’ '{match[0]}' ({self.stock_mapping[match[0]]})")
            return self.stock_mapping[match[0]]

        return None

    def process_news(self, input_file: str = "data/src/newsDB.news.json"):
        """ë‰´ìŠ¤ JSON ì²˜ë¦¬ + ë§¤í•‘"""
        try:
            with open(input_file, "r", encoding="utf-8") as f:
                raw_data = json.load(f)
        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
            return [], {}

        print(f"ğŸ“Š ë‰´ìŠ¤ {len(raw_data)}ê°œ ì²˜ë¦¬ ì‹œì‘")

        processed_data = []
        stats = {"mapped": 0, "failed": 0}

        for i, item in enumerate(raw_data):
            stock_kor = item.get("stock", "").strip()
            content = self.clean_content(item.get("content", ""))

            # ë‚ ì§œ ì²˜ë¦¬
            published_raw = item.get("published_at", {}).get("$date", None)
            if published_raw:
                news_date = datetime.fromisoformat(published_raw.replace("Z", "+00:00")).date()
                
                # 1ë…„ ì´ì „ ë‰´ìŠ¤ í•„í„°ë§ (2024ë…„ 8ì›” 5ì¼ ì´í›„ë§Œ)
                cutoff_date = datetime(2024, 8, 5).date()
                if news_date < cutoff_date:
                    continue
                    
                news_date = news_date.isoformat()
            else:
                news_date = None

            if not stock_kor or not news_date:
                continue

            ticker = self.map_stock(stock_kor)
            if ticker:
                stats["mapped"] += 1
            else:
                stats["failed"] += 1
                ticker = stock_kor  # ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥

            processed_data.append({
                "original_stock": stock_kor,
                "ticker": ticker,
                "news_date": news_date,
                "content": content
            })

            if (i + 1) % 1000 == 0:
                print(f"  ì§„í–‰ìƒí™©: {i+1}/{len(raw_data)} ì²˜ë¦¬ ì™„ë£Œ")

        print(f"\nâœ… ë§¤í•‘ ì™„ë£Œ: ì„±ê³µ {stats['mapped']} / ì‹¤íŒ¨ {stats['failed']}")
        return processed_data, stats

    def save_results(self, processed_data: List[Dict]):
        """ê²°ê³¼ ì €ì¥ (JSON + CSV + í‹°ì»¤ë³„ ì¹´ìš´íŠ¸)"""
        ts = pd.Timestamp.now().strftime("%Y%m%d_%H%M")

        # ì €ì¥í•  í´ë” ê²½ë¡œ
        folder_path = "data"
        os.makedirs(folder_path, exist_ok=True)
        
        # ì „ì²´ JSON ì €ì¥
        json_file = os.path.join(folder_path, f"news_processed_{ts}.json")
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump(processed_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ì „ì²´ JSON ì €ì¥ â†’ {json_file}")

        # ë§¤í•‘ ì„±ê³µ ë°ì´í„°ë§Œ CSV ì €ì¥
        mapped_data = [d for d in processed_data if d['ticker'] in self.stock_mapping.values()]
        df = pd.DataFrame(mapped_data)
        csv_file = os.path.join(folder_path, f"news_mapped_{ts}.csv")
        df.to_csv(csv_file, index=False, encoding="utf-8-sig")
        print(f"ğŸ“Š ë§¤í•‘ ì„±ê³µ CSV ì €ì¥ â†’ {csv_file} (ì´ {len(df)}ê°œ)")

        # í‹°ì»¤ë³„ ë‰´ìŠ¤ ê°œìˆ˜ ì €ì¥
        ticker_counts = df['ticker'].value_counts()
        count_file = os.path.join(folder_path, f"ticker_counts_{ts}.csv")
        ticker_counts.to_csv(count_file, header=['news_count'])
        print(f"ğŸ“ˆ í‹°ì»¤ë³„ ì¹´ìš´íŠ¸ ì €ì¥ â†’ {count_file}")


def main():
    processor = NewsPreprocessor("data/src/sp500_korean_stocks_with_symbols.xlsx")
    processed_data, stats = processor.process_news("data/src/newsDB.news.json")

    if processed_data:
        processor.save_results(processed_data)

if __name__ == "__main__":
    main()
