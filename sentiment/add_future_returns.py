import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta
import numpy as np
from tqdm import tqdm
import time

def add_future_returns(
    input_csv: str = "news_combined_features.csv",
    output_csv: str = "news_with_future_returns.csv",
    return_days: int = 3  # 3ê±°ë˜ì¼ í›„ ìˆ˜ìµë¥ 
):
    """
    ë‰´ìŠ¤ ë°ì´í„°ì— ë¯¸ë˜ ìˆ˜ìµë¥  ì»¬ëŸ¼ ì¶”ê°€í•˜ê³ , í•™ìŠµì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ìµœì¢… ì €ì¥
    """

    # í‹°ì»¤ ë§¤í•‘ (BRK â†’ BRK-B, BF â†’ BF-B)
    ticker_mapping = {
        'BRK': 'BRK-B',  # ë²„í¬ì…” í•´ì„œì›¨ì´ í´ë˜ìŠ¤B
        'BF': 'BF-B'     # ë¸Œë¼ìš´ í¬ë§Œ í´ë˜ìŠ¤B
    }

    def map_ticker(ticker: str) -> str:
        """í‹°ì»¤ ë§¤í•‘ í•¨ìˆ˜"""
        return ticker_mapping.get(ticker, ticker)

    print(f"ğŸ“Š ë‰´ìŠ¤ ë°ì´í„°ì— {return_days}ì¼ í›„ ìˆ˜ìµë¥  ì¶”ê°€ ì¤‘...")

    # 1. ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(input_csv)
    original_columns = df.columns.tolist() # ì›ë³¸ ì»¬ëŸ¼ ì €ì¥
    print(f"âœ… {len(df)}ê°œ ë‰´ìŠ¤ ë¡œë“œ")

    # 2. ë‚ ì§œ ì»¬ëŸ¼ í™•ì¸ ë° ë³€í™˜
    date_col = 'news_date' if 'news_date' in df.columns else 'date'
    df[date_col] = pd.to_datetime(df[date_col])

    # 3. ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
    results = []

    # 4. í‹°ì»¤ë³„ë¡œ ì²˜ë¦¬ (API í˜¸ì¶œ ìµœì í™”)
    unique_tickers = df['ticker'].unique()
    ticker_data_cache = {}

    print(f"ğŸ“ˆ {len(unique_tickers)}ê°œ í‹°ì»¤ì˜ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

    for ticker in tqdm(unique_tickers, desc="í‹°ì»¤ë³„ ë°ì´í„° ìˆ˜ì§‘"):
        try:
            mapped_ticker = map_ticker(ticker)
            ticker_df = df[df['ticker'] == ticker]
            min_date = ticker_df[date_col].min()
            max_date = ticker_df[date_col].max()
            
            start_date = min_date - timedelta(days=5)
            end_date = max_date + timedelta(days=return_days + 15) # ì—¬ìœ  ê¸°ê°„ ì¦ê°€
            
            stock = yf.Ticker(mapped_ticker)
            hist = stock.history(start=start_date, end=end_date)
            
            if len(hist) < 10:
                print(f"âš ï¸ {ticker}: ì£¼ê°€ ë°ì´í„° ë¶€ì¡±")
                continue
                
            ticker_data_cache[ticker] = hist
            time.sleep(0.1)
            
        except Exception as e:
            print(f"âŒ {ticker} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            continue
    
    print(f"âœ… {len(ticker_data_cache)}ê°œ í‹°ì»¤ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")

    # 5. ê° ë‰´ìŠ¤ë³„ë¡œ ìˆ˜ìµë¥  ê³„ì‚°
    print("ğŸ“Š ë‰´ìŠ¤ë³„ ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚° ì¤‘...")
    
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="ìˆ˜ìµë¥  ê³„ì‚°"):
        ticker = row['ticker']
        news_date = row[date_col]
        result = row.to_dict()
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        result['news_day_close'] = np.nan
        result[f'future_{return_days}d_close'] = np.nan
        result[f'future_return_{return_days}d'] = np.nan
        result['return_calculation_status'] = 'no_stock_data'

        if ticker in ticker_data_cache:
            hist = ticker_data_cache[ticker]
            try:
                # í•„í„°ë§ì„ í†µí•´ ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œ
                relevant_hist = hist[hist.index >= news_date.tz_localize(hist.index.tz)]
                if not relevant_hist.empty:
                    # ë‰´ìŠ¤ ë‹¹ì¼ ë˜ëŠ” ê·¸ ì´í›„ì˜ ì²« ê±°ë˜ì¼ ë° ì¢…ê°€
                    news_day_data = relevant_hist.iloc[0]
                    news_day_close = news_day_data['Close']
                    
                    # return_days ê±°ë˜ì¼ í›„ì˜ ë°ì´í„° í™•ì¸
                    if len(relevant_hist) > return_days:
                        future_day_data = relevant_hist.iloc[return_days]
                        future_close = future_day_data['Close']

                        if news_day_close > 0:
                            future_return = (future_close - news_day_close) / news_day_close
                            result.update({
                                'news_day_close': news_day_close,
                                f'future_{return_days}d_close': future_close,
                                f'future_return_{return_days}d': future_return,
                                'return_calculation_status': 'success'
                            })
                        else:
                             result['return_calculation_status'] = 'zero_price_error'
                    else:
                        result['return_calculation_status'] = 'future_day_not_found'
                else:
                    result['return_calculation_status'] = 'news_day_not_found'
            except Exception as e:
                result['return_calculation_status'] = f'error: {str(e)}'

        results.append(result)

    # 6. ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    result_df = pd.DataFrame(results)

    # 7. ìµœì¢… ì €ì¥í•  ì»¬ëŸ¼ ì„ íƒ <--- âœ¨ìˆ˜ì •ëœ í•µì‹¬ ë¶€ë¶„âœ¨
    final_columns = original_columns + [f'future_return_{return_days}d']
    # í˜¹ì‹œ ëª¨ë¥¼ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•œ ë²ˆ ë” í™•ì¸
    final_columns_to_keep = [col for col in final_columns if col in result_df.columns]
    final_save_df = result_df[final_columns_to_keep]

    # 8. ìµœì¢… ê²°ê³¼ ì €ì¥
    final_save_df.to_csv(output_csv, index=False, encoding='utf-8-sig')

    # 9. ê²°ê³¼ ìš”ì•½ (ìš”ì•½ í†µê³„ëŠ” ì „ì²´ ë°ì´í„°ë¡œ ê³„ì‚°)
    print(f"\nâœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ íŒŒì¼: {output_csv}")
    print(f"ğŸ“‹ ìµœì¢… íŒŒì¼ì—ëŠ” í•™ìŠµì— í•„ìš”í•œ {len(final_save_df.columns)}ê°œ ì»¬ëŸ¼ë§Œ í¬í•¨ë©ë‹ˆë‹¤.")
    
    status_counts = result_df['return_calculation_status'].value_counts()
    print(f"\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½:")
    for status, count in status_counts.items():
        print(f" Â {status}: {count}ê°œ")
    
    if 'success' in status_counts:
        success_df = result_df[result_df['return_calculation_status'] == 'success']
        returns = success_df[f'future_return_{return_days}d']
        print(f"\nğŸ“ˆ {return_days}ì¼ í›„ ìˆ˜ìµë¥  í†µê³„ (ì„±ê³µ ê±´ ëŒ€ìƒ):")
        print(f" Â í‰ê· : {returns.mean():.4f} ({returns.mean()*100:.2f}%)")
        print(f" Â í‘œì¤€í¸ì°¨: {returns.std():.4f} ({returns.std()*100:.2f}%)")
        print(f" Â ìµœì†Œê°’: {returns.min():.4f} ({returns.min()*100:.2f}%)")
        print(f" Â ìµœëŒ€ê°’: {returns.max():.4f} ({returns.max()*100:.2f}%)")
        
        positive_count = len(returns[returns > 0])
        negative_count = len(returns[returns < 0])
        print(f" Â ìˆ˜ìµë¥  > 0: {positive_count}ê°œ ({positive_count/len(returns)*100:.1f}%)")
        print(f" Â ìˆ˜ìµë¥  < 0: {negative_count}ê°œ ({negative_count/len(returns)*100:.1f}%)")
    
    return final_save_df

if __name__ == "__main__":
    # 3ì¼ í›„ ìˆ˜ìµë¥ ë¡œ ê³„ì‚°í•˜ì—¬ í•™ìŠµì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì €ì¥
    add_future_returns(
        input_csv="news_combined_features.csv",
        output_csv="news_with_future_returns.csv", 
        return_days=3
    )