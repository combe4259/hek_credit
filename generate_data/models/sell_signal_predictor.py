import pandas as pd
import numpy as np
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import xgboost as xgb
import joblib
import json
from datetime import datetime, timedelta
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class SellSignalPredictor:
    """ë§¤ë„  ì‹ í˜¸ ì˜ˆì¸¡ ëª¨ë¸
    - íƒ€ì´ë° ì ì ˆì„± (40%): ë³´ìœ  ê¸°ê°„ê³¼ ìˆ˜ìµë¥ ì˜ íš¨ìœ¨ì„±
    - ìˆ˜ìµ ì‹¤í˜„ í’ˆì§ˆ (35%): ì†ìµ ê´€ë¦¬ì˜ ì ì ˆì„±  
    - ì‹œì¥ ëŒ€ì‘ (25%): ì‹œì¥ ìƒí™© ë³€í™”ì— ëŒ€í•œ ëŒ€ì‘ë ¥
    """

    def __init__(self, train_months=36, val_months=6, test_months=6, step_months=3):
        self.model = None
        self.sell_signal_scalers = {}
        self.features = None
        self.is_trained = False

        self.train_months = train_months
        self.val_months = val_months  
        self.test_months = test_months
        self.step_months = step_months

        self.fold_results = []
        self.best_params = None
        
    def create_exit_signal_score(self, df, timing_scaler=None, profit_scaler=None, market_scaler=None, verbose=False):
        """ë§¤ë„ ì‹ í˜¸ ì ìˆ˜ ìƒì„±"""
        if verbose:
            print("ë§¤ë„ ì‹ í˜¸ ì ìˆ˜ ìƒì„± ì¤‘")

        df = df.copy()

        required_columns = ['return_pct', 'holding_period_days', 'exit_volatility_20d', 
                          'exit_momentum_20d', 'change_volatility_5d', 'change_vix']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise ValueError(f"ì»¬ëŸ¼ì´ ì—†ìŒ: {missing_columns}")
        
        df['return_pct'] = df['return_pct'].fillna(0)
        df['holding_period_days'] = df['holding_period_days'].fillna(1)
        df['exit_volatility_20d'] = df['exit_volatility_20d'].fillna(20)
        df['exit_momentum_20d'] = df['exit_momentum_20d'].fillna(0)
        df['change_volatility_5d'] = df['change_volatility_5d'].fillna(0)
        df['change_vix'] = df['change_vix'].fillna(0)

        # 1. íƒ€ì´ë° ì ì ˆì„± ì ìˆ˜ (40%)
        # ë³€ë™ì„± ê³ ë ¤í•œ ê¸°ê°„ë³„ ìœ„í—˜ ì¡°ì •
        annual_vol = df['exit_volatility_20d']
        period_vol = annual_vol * np.sqrt(df['holding_period_days'] / 365)
        period_vol_safe = np.maximum(period_vol, 1)
        
        # ë³€ë™ì„± ëŒ€ë¹„ ìˆ˜ìµë¥ 
        df['vol_adjusted_efficiency'] = df['return_pct'] / period_vol_safe
        
        # ë¡œê·¸ ë³€í™˜
        efficiency_scaled = df['vol_adjusted_efficiency'] * 5
        df['timing_score_raw'] = np.sign(efficiency_scaled) * np.log1p(np.abs(efficiency_scaled))

        #2. ìˆ˜ìµ ì‹¤í˜„ í’ˆì§ˆ ì ìˆ˜ (35%)
        # ë°ì´í„° ë¶„í¬ë¥¼ ê¸°ë°˜
        return_std = df['return_pct'].std()
        return_median = df['return_pct'].median()
        
        # ìˆ˜ìµë¥  ì ìˆ˜
        df['return_score'] = np.tanh((df['return_pct'] - return_median) / return_std) * 3
        
        # ë¦¬ìŠ¤í¬ ì¡°ì • ìˆ˜ìµë¥ 
        volatility_safe = np.maximum(df['exit_volatility_20d'], 1)
        risk_ratio = df['return_pct'] / volatility_safe
        risk_std = risk_ratio.std()
        risk_median = risk_ratio.median()
        df['risk_adjusted_score'] = np.tanh((risk_ratio - risk_median) / risk_std) * 2
        
        # ë³´ìœ ê¸°ê°„ íš¨ìœ¨ì„±
        period_efficiency = df['return_pct'] / np.log1p(df['holding_period_days'])
        efficiency_std = period_efficiency.std()
        efficiency_median = period_efficiency.median()
        df['period_efficiency_score'] = np.tanh((period_efficiency - efficiency_median) / efficiency_std) * 1
        
        # ìµœì¢… í’ˆì§ˆ ì ìˆ˜ ì¡°í•©
        df['profit_quality_raw'] = (df['return_score'] * 0.5 + 
                                   df['risk_adjusted_score'] * 0.3 + 
                                   df['period_efficiency_score'] * 0.2)

        # 3. ì‹œì¥ ëŒ€ì‘ ì ìˆ˜ (25%) - ë°ì´í„° ê¸°ë°˜ ìƒí˜¸ì‘ìš©
        # ê° ì‹œì¥ ì§€í‘œë¥¼ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì •ê·œí™”
        momentum_std = df['exit_momentum_20d'].std()
        momentum_median = df['exit_momentum_20d'].median()
        df['momentum_normalized'] = (df['exit_momentum_20d'] - momentum_median) / momentum_std
        
        vix_change_std = df['change_vix'].std()
        vix_change_median = df['change_vix'].median()
        df['vix_change_normalized'] = (df['change_vix'] - vix_change_median) / vix_change_std
        
        vol_change_std = df['change_volatility_5d'].std()
        vol_change_median = df['change_volatility_5d'].median()
        df['vol_change_normalized'] = (df['change_volatility_5d'] - vol_change_median) / vol_change_std
        
        # ìˆ˜ìµë¥ ê³¼ ì‹œì¥ ì§€í‘œì˜ ìƒí˜¸ì‘ìš©ì„ ì—°ì†í•¨ìˆ˜ë¡œ
        df['momentum_interaction'] = np.tanh(df['momentum_normalized'] * np.sign(df['return_pct'])) * 1.5
        df['vix_interaction'] = np.tanh(df['vix_change_normalized'] * np.tanh(df['return_pct'] / 5)) * 1.0
        df['vol_interaction'] = np.tanh(df['vol_change_normalized'] * np.tanh(df['return_pct'] / 8)) * 0.8
        
        # ì‹œì¥ ëŒ€ì‘ ì ìˆ˜ ì¡°í•© (ë°ì´í„°ê°€ ì•Œì•„ì„œ íŒ¨í„´ ì°¾ê²Œ)
        df['market_response_raw'] = (df['momentum_interaction'] * 0.5 + 
                                    df['vix_interaction'] * 0.3 + 
                                    df['vol_interaction'] * 0.2)

        # ìµœì¢… ì ìˆ˜ ê³„ì‚°
        # ê° êµ¬ì„± ìš”ì†Œë³„ ìŠ¤ì¼€ì¼ë§
        if timing_scaler is None or profit_scaler is None or market_scaler is None:
            timing_scaler = RobustScaler()
            profit_scaler = RobustScaler() 
            market_scaler = RobustScaler()
            
            timing_scaled = timing_scaler.fit_transform(df[['timing_score_raw']])
            profit_scaled = profit_scaler.fit_transform(df[['profit_quality_raw']])
            market_scaled = market_scaler.fit_transform(df[['market_response_raw']])
            
            self.sell_signal_scalers['timing_scaler'] = timing_scaler
            self.sell_signal_scalers['profit_scaler'] = profit_scaler
            self.sell_signal_scalers['market_scaler'] = market_scaler
        else:
            timing_scaled = timing_scaler.transform(df[['timing_score_raw']])
            profit_scaled = profit_scaler.transform(df[['profit_quality_raw']])
            market_scaled = market_scaler.transform(df[['market_response_raw']])
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ì ìˆ˜ ê³„ì‚°
        df['sell_signal_score'] = (timing_scaled.flatten() * 0.4 + 
                                  profit_scaled.flatten() * 0.35 + 
                                  market_scaled.flatten() * 0.25)
        
        if verbose:
            print(f"  ë§¤ë„ ì ìˆ˜ ìƒì„± ì™„ë£Œ")
            print(f"  ë²”ìœ„: {df['sell_signal_score'].min():.4f} ~ {df['sell_signal_score'].max():.4f}")
            print(f"  í‰ê· : {df['sell_signal_score'].mean():.4f}")

        
        return df

    def prepare_features(self, df, verbose=False):
        """ í”¼ì²˜ ì¤€ë¹„"""
        if verbose:
            print("ë§¤ë„ í”¼ì²˜ ì¤€ë¹„")
        

        excluded_features = {
            'return_pct', 'holding_period_days', 'exit_volatility_20d', 'exit_momentum_20d',
            'change_volatility_5d', 'change_vix',
            # ì¤‘ê°„ ê³„ì‚° ë³€ìˆ˜ë“¤ (ë°ì´í„° ê¸°ë°˜ ë³€ìˆ˜ëª… ë°˜ì˜)
            'vol_adjusted_efficiency', 'timing_score_raw', 'return_score', 
            'risk_adjusted_score', 'period_efficiency_score', 'profit_quality_raw',
            'momentum_normalized', 'vix_change_normalized', 'vol_change_normalized',
            'momentum_interaction', 'vix_interaction', 'vol_interaction',
            'market_response_raw', 'sell_signal_score'
        }
        

        available_features = []
        
        # 1. ê¸°ë³¸ ê±°ë˜ ì •ë³´
        basic_features = ['position_size_pct']
        available_features.extend([col for col in basic_features if col in df.columns])
        

        entry_features = [
            'entry_momentum_5d', 'entry_momentum_20d', 'entry_momentum_60d',
            'entry_ma_dev_5d', 'entry_ma_dev_20d', 'entry_ma_dev_60d',
            'entry_volatility_5d', 'entry_volatility_60d',
            'entry_vol_change_5d', 'entry_vol_change_20d', 'entry_vol_change_60d',
            'entry_vix', 'entry_tnx_yield', 'entry_ratio_52w_high'
        ]
        available_features.extend([col for col in entry_features if col in df.columns])
        
        # 3.  ì‹œì  ì •ë³´
        exit_features = [
            'exit_momentum_5d', 'exit_momentum_60d',
            'exit_ma_dev_5d', 'exit_ma_dev_20d', 'exit_ma_dev_60d',
            'exit_volatility_5d', 'exit_volatility_60d',
            'exit_vix', 'exit_tnx_yield', 'exit_ratio_52w_high'
        ]
        available_features.extend([col for col in exit_features if col in df.columns])
        
        # 4. ë³´ìœ  ê¸°ê°„ ì¤‘ ë³€í™”
        change_features = [
            'change_momentum_5d', 'change_momentum_20d', 'change_momentum_60d',
            'change_ma_dev_5d', 'change_ma_dev_20d', 'change_ma_dev_60d',
            'change_volatility_20d', 'change_volatility_60d',  # change_volatility_5d ì œì™¸
            'change_tnx_yield', 'change_ratio_52w_high'

        ]
        available_features.extend([col for col in change_features if col in df.columns])
        
        # 5. ì‹œì¥ í™˜ê²½ ì •ë³´
        market_features = [
            'market_return_during_holding',
            'excess_return'
        ]
        available_features.extend([col for col in market_features if col in df.columns])
        

        self.features = [col for col in available_features 
                        if col in df.columns and col not in excluded_features]
        
        if verbose:
            print(f"  ë§¤ë„ ì‚¬ìš© í”¼ì²˜: {len(self.features)}ê°œ")

        feature_data = df[self.features].select_dtypes(include=[np.number])
        
        if verbose and len(feature_data.columns) != len(self.features):
            print(f"  ë¹„ìˆ«ìí˜• ì»¬ëŸ¼ ì œì™¸: {len(self.features) - len(feature_data.columns)}ê°œ")
        
        return feature_data

    def train_model(self, df, hyperparameter_search=False, verbose=False):
        """ë§¤ë„  ì‹ í˜¸ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨"""
        if verbose:
            print("ë§¤ë„ ì‹ í˜¸ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        
        #  ì‹ í˜¸ ì ìˆ˜ ìƒì„±
        df_with_score = self.create_exit_signal_score(df, verbose=verbose)
        
        # í”¼ì²˜ ì¤€ë¹„
        X = self.prepare_features(df_with_score, verbose=verbose)
        y = df_with_score['sell_signal_score']
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
        if hyperparameter_search:
            best_params = self._optimize_hyperparameters(X, y, verbose=verbose)
        else:
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
            best_params = {
                'max_depth': 7,
                'learning_rate': 0.05,
                'n_estimators': 600,
                'subsample': 0.8,
                'colsample_bytree': 0.9,
                'reg_alpha': 1.0,
                'reg_lambda': 5.0,
                'random_state': 42
            }
        
        # ìµœì¢… ëª¨ë¸ í›ˆë ¨
        self.model = xgb.XGBRegressor(**best_params)
        self.model.fit(X, y)
        
        # ì„±ëŠ¥ í‰ê°€
        y_pred = self.model.predict(X)
        r2 = r2_score(y, y_pred)
        rmse = np.sqrt(mean_squared_error(y, y_pred))
        
        self.is_trained = True
        
        if verbose:
            print(f"  ë§¤ë„ ì‹ í˜¸ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
            print(f"  RÂ² Score: {r2:.4f}")
            print(f"  RMSE: {rmse:.4f}")
        
        return {
            'model': self.model,
            'r2_score': r2,
            'rmse': rmse,
            'best_params': best_params,
            'feature_count': len(self.features)
        }

    def predict_exit_signal(self, df, verbose=False):
        """ì‹ í˜¸ ê°•ë„ ì˜ˆì¸¡ """
        if not self.is_trained:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•ŠìŒ.")
        
        if verbose:
            print("ë§¤ë„ ì‹ í˜¸ ì˜ˆì¸¡")
        
        # í”¼ì²˜ ì¤€ë¹„
        X = self.prepare_features(df, verbose=False)
        
        # ì˜ˆì¸¡
        predictions = self.model.predict(X)
        
        if verbose:
            print(f"  {len(predictions)}ê°œ í¬ì§€ì…˜ì˜  ì‹ í˜¸ ì˜ˆì¸¡ ì™„ë£Œ")
            print(f"  ì‹ í˜¸ ê°•ë„ ë²”ìœ„: {predictions.min():.4f} ~ {predictions.max():.4f}")
            print(f"  í‰ê·  ì‹ í˜¸ ê°•ë„: {predictions.mean():.4f}")
        
        return predictions

    def get_signal_interpretation(self, score):
        """ì‹ í˜¸ ì ìˆ˜ í•´ì„"""
        if score > 2:
            return "ì¦‰ì‹œ ë§¤ë„ ê¶Œì¥"
        elif score > 1:
            return "ê°•í•œ ë§¤ë„ ì‹ í˜¸"
        elif score > 0:
            return "ì¤‘ê°„ ë§¤ë„ ì‹ í˜¸"
        elif score > -1:
            return "ì•½í•œ ë§¤ë„ ì‹ í˜¸"
        else:
            return "ë³´ìœ  ìœ ì§€"

    def _optimize_hyperparameters(self, X, y, verbose=False):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”"""
        if verbose:
            print("  í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘...")
        
        param_grid = {
            'max_depth': [5, 6, 7, 8, 9],
            'learning_rate': [0.02, 0.05, 0.07, 0.1],
            'n_estimators': [400, 500, 600, 800],
            'subsample': [0.7, 0.8, 0.9],
            'colsample_bytree': [0.8, 0.9, 0.95],
            'reg_alpha': [0.5, 1.0, 2.0],
            'reg_lambda': [3.0, 5.0, 8.0]
        }
        

        base_model = xgb.XGBRegressor(
            random_state=42,
            tree_method='gpu_hist',
            gpu_id=0
        )
        tscv = TimeSeriesSplit(n_splits=3)

        search = GridSearchCV(
            base_model, param_grid, 
            cv=tscv, scoring='r2',
            verbose=1
        )
        search.fit(X, y)
        
        if verbose:
            print(f"  ìµœì  RÂ² Score: {search.best_score_:.4f}")
        
        return search.best_params_

    def save_model(self, filename=None):
        """ëª¨ë¸ ì €ì¥"""
        if not self.is_trained:
            raise ValueError("í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        if filename is None:
            filename = f"sell_signal_predictor_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
        
        save_data = {
            'model': self.model,
            'scalers': self.sell_signal_scalers,
            'features': self.features,
            'model_type': 'SELL_SIGNAL_PREDICTOR',
            'created_at': datetime.now().isoformat()
        }
        
        joblib.dump(save_data, filename)
        print(f" Sell Signal ëª¨ë¸ ì €ì¥: {filename}")
        return filename

    def load_model(self, filename):
        """ëª¨ë¸ ë¡œë“œ"""
        save_data = joblib.load(filename)
        
        self.model = save_data['model']
        self.sell_signal_scalers = save_data['scalers']
        self.features = save_data['features']
        self.is_trained = True
        
        print(f"ğŸ“‚ Sell Signal ëª¨ë¸ ë¡œë“œ: {filename}")
        return True

    # ================================
    # Walk-Forward í•™ìŠµ íŒŒì´í”„ë¼ì¸ 
    # ================================
    
    def create_time_folds(self, df, verbose=False):
        if verbose:
            print("Sell Signal Walk-Forward ì‹œê°„ í´ë“œ ìƒì„±")
        
        df = df.copy()
        df['date'] = pd.to_datetime(df['exit_date'])
        df = df.sort_values('date').reset_index(drop=True)
        
        start_date = df['date'].min()
        end_date = df['date'].max()
        
        folds = []
        current_start = start_date
        fold_id = 1
        
        while current_start + pd.DateOffset(months=self.train_months + self.val_months + self.test_months) <= end_date:
            train_end = current_start + pd.DateOffset(months=self.train_months)
            val_end = train_end + pd.DateOffset(months=self.val_months)
            test_end = val_end + pd.DateOffset(months=self.test_months)
            
            train_mask = (df['date'] >= current_start) & (df['date'] < train_end)
            val_mask = (df['date'] >= train_end) & (df['date'] < val_end)
            test_mask = (df['date'] >= val_end) & (df['date'] < test_end)
            
            if train_mask.sum() > 1000 and val_mask.sum() > 100 and test_mask.sum() > 100:
                fold_info = {
                    'fold_id': fold_id,
                    'train_start': current_start.strftime('%Y-%m-%d'),
                    'train_end': train_end.strftime('%Y-%m-%d'),
                    'val_start': train_end.strftime('%Y-%m-%d'),
                    'val_end': val_end.strftime('%Y-%m-%d'),
                    'test_start': val_end.strftime('%Y-%m-%d'),
                    'test_end': test_end.strftime('%Y-%m-%d'),
                    'train_indices': df[train_mask].index.tolist(),
                    'val_indices': df[val_mask].index.tolist(),
                    'test_indices': df[test_mask].index.tolist()
                }
                folds.append(fold_info)
                fold_id += 1
            
            current_start += pd.DateOffset(months=self.step_months)
        
        if verbose:
            print(f"  ìƒì„±ëœ í´ë“œ ìˆ˜: {len(folds)}ê°œ")
            for i, fold in enumerate(folds):
                print(f"  í´ë“œ {i+1}: {fold['train_start']} ~ {fold['test_end']}")
                print(f"    Train: {len(fold['train_indices']):,}ê°œ, Val: {len(fold['val_indices']):,}ê°œ, Test: {len(fold['test_indices']):,}ê°œ")
        
        return folds
    
    def run_walk_forward_training(self, data_path, hyperparameter_search=True, verbose=True):

        if verbose:
            print("Sell Signal Walk-Forward í•™ìŠµ ì‹œì‘")
            print("="*60)
        
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(data_path)
        if verbose:
            print(f"ë°ì´í„° ë¡œë“œ: {len(df):,}ê°œ ê±°ë˜")
        
        # Sell Signal ì ìˆ˜ ìƒì„±
        df = self.create_exit_signal_score(df, verbose=verbose)
        
        # ì‹œê°„ í´ë“œ ìƒì„±
        folds = self.create_time_folds(df, verbose=verbose)
        
        fold_results = []
        
        for fold_info in tqdm(folds, desc="í´ë“œë³„ í•™ìŠµ"):
            if verbose:
                print(f"\n í´ë“œ {fold_info['fold_id']} í•™ìŠµ ì¤‘")
            
            # í´ë“œë³„ ë°ì´í„° ë¶„í• 
            train_data = df.loc[fold_info['train_indices']]
            val_data = df.loc[fold_info['val_indices']]
            test_data = df.loc[fold_info['test_indices']]
            
            # í”¼ì²˜ ì¤€ë¹„
            X_train = self.prepare_features(train_data, verbose=False)
            X_val = self.prepare_features(val_data, verbose=False)
            X_test = self.prepare_features(test_data, verbose=False)
            
            y_train = train_data['sell_signal_score']
            y_val = val_data['sell_signal_score']
            y_test = test_data['sell_signal_score']

            if hyperparameter_search:
                search_result = self._optimize_hyperparameters(X_train, y_train, verbose=False)
                best_params = search_result
            else:

                best_params = {
                    'tree_method': 'hist',
                    'subsample': 0.75, 
                    'scale_pos_weight': 10, 
                    'reg_lambda': 20.0, 
                    'reg_alpha': 1.0, 
                    'objective': 'reg:squarederror', 
                    'n_estimators': 800, 
                    'min_child_weight': 2, 
                    'max_leaves': 255, 
                    'max_depth': 9, 
                    'max_delta_step': 0, 
                    'max_bin': 128, 
                    'learning_rate': 0.01, 
                    'grow_policy': 'depthwise', 
                    'gamma': 0.5, 
                    'eval_metric': 'rmse', 
                    'colsample_bytree': 0.9, 
                    'colsample_bynode': 0.8, 
                    'colsample_bylevel': 0.8, 
                    'random_state': 42
                }
            
            # ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµ
            best_model = xgb.XGBRegressor(**best_params)
            best_model.fit(X_train, y_train)
            
            # ê²€ì¦ ë° í…ŒìŠ¤íŠ¸ í‰ê°€
            val_pred = best_model.predict(X_val)
            val_r2 = r2_score(y_val, val_pred)
            
            test_pred = best_model.predict(X_test)
            test_r2 = r2_score(y_test, test_pred)
            
            # ê²°ê³¼ ì €ì¥
            fold_result = {
                'fold_id': fold_info['fold_id'],
                'fold_info': fold_info,
                'best_params': best_params,
                'val_r2': val_r2,
                'test_r2': test_r2,
                'train_samples': len(X_train),
                'val_samples': len(X_val),
                'test_samples': len(X_test),
                'features_used': len(X_train.columns),
                'best_model': best_model
            }
            
            fold_results.append(fold_result)
            
            if verbose:
                print(f"  í´ë“œ {fold_info['fold_id']} ì™„ë£Œ: Val RÂ² = {val_r2:.4f}, Test RÂ² = {test_r2:.4f}")
        
        self.fold_results = fold_results
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ìµœì¢… ëª¨ë¸ë¡œ ì„ íƒ
        best_fold = max(fold_results, key=lambda x: x['test_r2'])
        self.model = best_fold['best_model']
        self.best_params = best_fold['best_params']
        self.is_trained = True
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        if verbose:
            self._print_fold_summary()
        
        return fold_results
    
    def _print_fold_summary(self):
        """í´ë“œë³„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not self.fold_results:
            print("í´ë“œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\n" + "="*70)
        print("Sell Signal Walk-Forward ê²°ê³¼ ìš”ì•½")
        print("="*70)
        
        val_r2_scores = [result['val_r2'] for result in self.fold_results]
        test_r2_scores = [result['test_r2'] for result in self.fold_results]
        
        print(f" í´ë“œë³„ ì„±ëŠ¥:")
        for result in self.fold_results:
            print(f"  í´ë“œ {result['fold_id']}: Val RÂ² = {result['val_r2']:.4f}, Test RÂ² = {result['test_r2']:.4f}")
        
        print(f"\n ì „ì²´ í†µê³„:")
        print(f"  Validation RÂ²: {np.mean(val_r2_scores):.4f} Â± {np.std(val_r2_scores):.4f}")
        print(f"  Test RÂ²:       {np.mean(test_r2_scores):.4f} Â± {np.std(test_r2_scores):.4f}")
        print(f"  ìµœê³  ì„±ëŠ¥:     {np.max(test_r2_scores):.4f} (í´ë“œ {np.argmax(test_r2_scores) + 1})")
        print(f"  í‰ê·  í”¼ì²˜ ìˆ˜:  {np.mean([r['features_used'] for r in self.fold_results]):.0f}ê°œ")
        
        print("="*70)
    
    def save_training_results(self, filename=None):
        """í•™ìŠµ ê²°ê³¼ ì €ì¥ """
        if filename is None:
            filename = f"sell_signal_debug_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        save_data = {
            'model_type': 'SELL_SIGNAL_PREDICTOR',
            'model_name': 'Sell Signal Predictor',
            'created_at': datetime.now().isoformat(),
            'total_folds': len(self.fold_results),
            'best_params': self.best_params,
            'fold_results': []
        }
        
        for result in self.fold_results:
            # ëª¨ë¸ ê°ì²´ ì œì™¸í•˜ê³  ì €ì¥
            fold_data = {key: value for key, value in result.items() 
                        if key != 'best_model'}
            save_data['fold_results'].append(fold_data)
        
        with open(filename, 'w') as f:
            json.dump(save_data, f, indent=2, default=str)
        
        print(f"ğŸ’¾ Sell Signal í•™ìŠµ ê²°ê³¼ ì €ì¥: {filename}")
        return filename

def main():
    """Sell Signal Predictor í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print(" Sell Signal Predictor - ë§¤ë„  ì‹ í˜¸ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ")
    print("="*70)
    print("="*70)
    
    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    import os
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_path = os.path.join(current_dir, '../results/final/trading_episodes_with_rebuilt_market_component.csv')
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(data_path):
        print(f" ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {data_path}")
        return
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    predictor = SellSignalPredictor()
    
    # ëœë¤ ë¶„í•  í•™ìŠµ ì‹¤í–‰
    try:
        # ë°ì´í„° ë¡œë“œ
        import pandas as pd
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
        import numpy as np
        
        df = pd.read_csv(data_path)
        print(f"\nğŸ“Š ë°ì´í„° ë¡œë“œ: {len(df):,}ê°œ ê±°ë˜")
        
        # Train/Val/Test ë¶„í•  (60/20/20)
        train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
        train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2
        
        print(f"\nğŸ“Š ë°ì´í„° ë¶„í• :")
        print(f"  Train: {len(train_df):,}ê°œ ({len(train_df)/len(df)*100:.1f}%)")
        print(f"  Val:   {len(val_df):,}ê°œ ({len(val_df)/len(df)*100:.1f}%)")
        print(f"  Test:  {len(test_df):,}ê°œ ({len(test_df)/len(df)*100:.1f}%)")
        
        # ëª¨ë¸ í•™ìŠµ
        print(f"\n ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        result = predictor.train_model(train_df, hyperparameter_search=False, verbose=True)
        
        # í‰ê°€ í•¨ìˆ˜
        def evaluate_model(predictor, data, name):
            data_with_score = predictor.create_exit_signal_score(data, verbose=False)
            X = predictor.prepare_features(data_with_score, verbose=False)
            y = data_with_score['sell_signal_score']
            y_pred = predictor.model.predict(X)
            
            r2 = r2_score(y, y_pred)
            rmse = np.sqrt(mean_squared_error(y, y_pred))
            mae = mean_absolute_error(y, y_pred)
            
            return {
                'name': name,
                'r2': r2,
                'rmse': rmse,
                'mae': mae,
                'y_mean': y.mean(),
                'y_std': y.std(),
                'pred_mean': y_pred.mean(),
                'pred_std': y_pred.std()
            }
        
        # ê° ì„¸íŠ¸ í‰ê°€
        train_metrics = evaluate_model(predictor, train_df, 'Train')
        val_metrics = evaluate_model(predictor, val_df, 'Val')
        test_metrics = evaluate_model(predictor, test_df, 'Test')
        
        # ì„±ê³¼ ì¶œë ¥
        print(f"\n ì„±ê³¼ ì§€í‘œ:")
        print("="*60)
        print(f"{'Dataset':<10} {'RÂ²':>8} {'RMSE':>8} {'MAE':>8} {'Mean':>8} {'Std':>8}")
        print("-"*60)
        for metrics in [train_metrics, val_metrics, test_metrics]:
            print(f"{metrics['name']:<10} {metrics['r2']:>8.4f} {metrics['rmse']:>8.4f} {metrics['mae']:>8.4f} {metrics['y_mean']:>8.4f} {metrics['y_std']:>8.4f}")
        
        # ì˜¤ë²„í”¼íŒ… ì²´í¬
        overfit_score = train_metrics['r2'] - val_metrics['r2']
        print(f"\nğŸ” ì˜¤ë²„í”¼íŒ… ë¶„ì„:")
        if overfit_score > 0.05:
            print(f"   ì˜¤ë²„í”¼íŒ… ê°€ëŠ¥ì„±: Train-Val RÂ² ì°¨ì´ = {overfit_score:.4f}")
        else:
            print(f"   ì˜¤ë²„í”¼íŒ… ì—†ìŒ: Train-Val RÂ² ì°¨ì´ = {overfit_score:.4f}")
        
        # Val-Test ì„±ëŠ¥ ì•ˆì •ì„±
        stability_score = abs(val_metrics['r2'] - test_metrics['r2'])
        print(f"\nğŸ“ ì„±ëŠ¥ ì•ˆì •ì„±:")
        if stability_score < 0.05:
            print(f"   ì•ˆì •ì : Val-Test RÂ² ì°¨ì´ = {stability_score:.4f}")
        else:
            print(f"  ï¸  ë¶ˆì•ˆì •: Val-Test RÂ² ì°¨ì´ = {stability_score:.4f}")
        
        # ëª¨ë¸ ì €ì¥
        model_filename = predictor.save_model()
        
        print(f"\n Sell Signal ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        print(f" ì €ì¥ëœ ëª¨ë¸: {model_filename}")
        

        return predictor
        
    except Exception as e:
        print(f" í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()