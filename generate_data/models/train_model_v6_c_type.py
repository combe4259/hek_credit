import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV, RandomizedSearchCV
from sklearn.model_selection import ParameterGrid
from scipy.stats import uniform, randint
from tqdm import tqdm
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import xgboost as xgb
import joblib
import json
from datetime import datetime
import warnings
import torch
warnings.filterwarnings('ignore')

class CTypeExitSignalAI:
    """
    C-type ë§¤ë„ ì²­ì‚° ì‹ í˜¸ AI
    
    ëª©í‘œ: ë§¤ë„ ì‹œì ì—ì„œ ì²­ì‚° ì¡°ê±´ì˜ ì ì ˆì„±ì„ í‰ê°€
    - íƒ€ì´ë° ì ì ˆì„±: ì–¼ë§ˆë‚˜ ì ì ˆí•œ ì‹œì ì— íŒ”ì•˜ëŠ”ê°€?
    - ìˆ˜ìµ ì‹¤í˜„ í’ˆì§ˆ: ì†ìµì„ ì–¼ë§ˆë‚˜ ì˜ ê´€ë¦¬í–ˆëŠ”ê°€?
    - ì‹œì¥ ëŒ€ì‘: ì‹œì¥ ìƒí™©ì— ì–¼ë§ˆë‚˜ ì˜ ëŒ€ì‘í–ˆëŠ”ê°€?
    """

    def __init__(self, train_months=36, val_months=6, test_months=6, step_months=3, use_global_split=True):
        self.train_months = train_months
        self.val_months = val_months
        self.test_months = test_months
        self.step_months = step_months
        self.use_global_split = use_global_split
        
        # ===== C-type: ì²­ì‚° ì‹ í˜¸ í‰ê°€ =====
        self.c_type_exit_model = None         
        self.c_type_exit_scalers = {}         
        self.c_type_exit_features = None      
        
        self.fold_results = []
        self.global_results = None
        self.best_params_c = None
    
    # ================================
    # C-type: ë§¤ë„ ì²­ì‚° ì ìˆ˜í™”
    # ================================
    
    def create_c_type_exit_score(self, df, timing_scaler=None, profit_scaler=None, market_scaler=None, verbose=False):
        """
        C-type: ì²­ì‚° ì‹œì ì˜ ì ì ˆì„±ì„ í‰ê°€í•˜ëŠ” ì ìˆ˜ ìƒì„±
        
        3ê°€ì§€ í•µì‹¬ í‰ê°€ ì§€í‘œ:
        1. íƒ€ì´ë° ì ì ˆì„± (40%): ë³´ìœ  ê¸°ê°„ê³¼ ìˆ˜ìµë¥ ì˜ íš¨ìœ¨ì„±
        2. ìˆ˜ìµ ì‹¤í˜„ í’ˆì§ˆ (35%): ì†ìµ ê´€ë¦¬ì˜ ì ì ˆì„±
        3. ì‹œì¥ ëŒ€ì‘ (25%): ì‹œì¥ ìƒí™© ë³€í™”ì— ëŒ€í•œ ëŒ€ì‘ë ¥
        """
        if verbose:
            print("ğŸ›‘ C-type: ì²­ì‚° ì ìˆ˜ ìƒì„± ì¤‘...")

        df = df.copy()
        
        # NaN ì²˜ë¦¬
        df['return_pct'] = df['return_pct'].fillna(0)
        df['holding_period_days'] = df['holding_period_days'].fillna(1)
        df['exit_volatility_20d'] = df['exit_volatility_20d'].fillna(20)
        df['exit_momentum_20d'] = df['exit_momentum_20d'].fillna(0)
        df['change_volatility_5d'] = df['change_volatility_5d'].fillna(0)
        df['change_vix'] = df['change_vix'].fillna(0)

        # ===== 1. íƒ€ì´ë° ì ì ˆì„± ì ìˆ˜ (40%) =====
        # ë³´ìœ  ê¸°ê°„ ëŒ€ë¹„ ìˆ˜ìµë¥  íš¨ìœ¨ì„±
        holding_safe = np.maximum(df['holding_period_days'], 1)
        df['daily_return_efficiency'] = df['return_pct'] / holding_safe
        
        # ë³´ìœ  ê¸°ê°„ë³„ ì ì ˆì„± í‰ê°€
        df['holding_timing_base'] = np.where(
            df['holding_period_days'] < 3, -2,     # ë„ˆë¬´ ë¹ ë¥¸ ì²­ì‚°: ë§¤ìš° ë‚˜ì¨
            np.where(df['holding_period_days'] < 7, 1,      # ë‹¨ê¸° ì²­ì‚°: ë³´í†µ
                    np.where(df['holding_period_days'] < 21, 3,     # ì ì • ë³´ìœ : ì¢‹ìŒ
                            np.where(df['holding_period_days'] < 60, 2,     # ì¤‘ì¥ê¸°: ë³´í†µ
                                    np.where(df['holding_period_days'] < 120, 0, -1)))))  # ì¥ê¸°: ê°ì 
        
        # ìˆ˜ìµë¥ ì— ë”°ë¥¸ íƒ€ì´ë° ë³´ì •
        df['return_timing_adjustment'] = np.where(
            df['return_pct'] > 10, 1.5,    # í° ìˆ˜ìµ: íƒ€ì´ë° ë³´ë„ˆìŠ¤
            np.where(df['return_pct'] > 5, 1.2,     # ì¤‘ê°„ ìˆ˜ìµ: ì•½ê°„ ë³´ë„ˆìŠ¤
                    np.where(df['return_pct'] > 0, 1.0,     # ì†Œìˆ˜ìµ: ê·¸ëŒ€ë¡œ
                            np.where(df['return_pct'] > -5, 0.8,    # ì†Œì†ì‹¤: ì•½ê°„ ê°ì 
                                    np.where(df['return_pct'] > -15, 0.6, 0.3)))))  # í° ì†ì‹¤: í° ê°ì 
        
        df['timing_score_raw'] = df['holding_timing_base'] * df['return_timing_adjustment']

        # ===== 2. ìˆ˜ìµ ì‹¤í˜„ í’ˆì§ˆ ì ìˆ˜ (35%) =====
        # ì ˆëŒ€ ìˆ˜ìµë¥  í‰ê°€
        df['absolute_return_score'] = np.where(
            df['return_pct'] > 15, 5,      # í° ìˆ˜ìµ: ë§¤ìš° ì¢‹ìŒ
            np.where(df['return_pct'] > 8, 4,       # ì¢‹ì€ ìˆ˜ìµ: ì¢‹ìŒ
                    np.where(df['return_pct'] > 3, 3,       # ì ë‹¹í•œ ìˆ˜ìµ: ë³´í†µ
                            np.where(df['return_pct'] > 0, 1,       # ì†Œìˆ˜ìµ: ì•½ê°„ ì¢‹ìŒ
                                    np.where(df['return_pct'] > -3, -1,     # ì†Œì†ì‹¤: ì•½ê°„ ë‚˜ì¨
                                            np.where(df['return_pct'] > -8, -2,     # ì†ì‹¤: ë‚˜ì¨
                                                    np.where(df['return_pct'] > -15, -3, -4)))))))  # í° ì†ì‹¤: ë§¤ìš° ë‚˜ì¨
        
        # ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ìˆ˜ìµë¥  (ìƒ¤í”„ ë¹„ìœ¨ ê°œë…)
        volatility_safe = np.maximum(df['exit_volatility_20d'], 1)
        df['risk_adjusted_return'] = df['return_pct'] / volatility_safe
        df['risk_adjusted_score'] = np.clip(df['risk_adjusted_return'] * 2, -3, 3)
        
        # ì†ì ˆ/ìµì ˆ ì ì ˆì„±
        df['cutloss_profit_score'] = np.where(
            (df['return_pct'] > 0) & (df['holding_period_days'] < 30), 2,    # ë¹ ë¥¸ ìµì ˆ: ì¢‹ìŒ
            np.where((df['return_pct'] < -5) & (df['holding_period_days'] < 10), 1,  # ë¹ ë¥¸ ì†ì ˆ: ë³´í†µ
                    np.where((df['return_pct'] < -10) & (df['holding_period_days'] > 30), -2, 0))  # ëŠ¦ì€ ì†ì ˆ: ë‚˜ì¨
        )
        
        df['profit_quality_raw'] = (df['absolute_return_score'] * 0.5 + 
                                   df['risk_adjusted_score'] * 0.3 + 
                                   df['cutloss_profit_score'] * 0.2)

        # ===== 3. ì‹œì¥ ëŒ€ì‘ ì ìˆ˜ (25%) =====
        # ì²­ì‚° ì‹œì ì˜ ëª¨ë©˜í…€ ëŒ€ì‘
        df['exit_momentum_response'] = np.where(
            df['return_pct'] > 0,  # ìˆ˜ìµ ì‹¤í˜„ ì‹œ
            np.where(df['exit_momentum_20d'] < -5, 3,    # í•˜ë½ì¥ì—ì„œ ìˆ˜ìµì‹¤í˜„: ë§¤ìš° ì¢‹ìŒ
                    np.where(df['exit_momentum_20d'] > 5, -1, 1)),   # ìƒìŠ¹ì¥ì—ì„œ ìˆ˜ìµì‹¤í˜„: ì•„ì‰¬ì›€
            # ì†ì‹¤ ì²­ì‚° ì‹œ
            np.where(df['exit_momentum_20d'] < -10, 2,   # ê¸‰ë½ì¥ì—ì„œ ì†ì ˆ: ì¢‹ì€ íŒë‹¨
                    np.where(df['exit_momentum_20d'] > 0, -2, 0))    # ìƒìŠ¹ì¥ì—ì„œ ì†ì ˆ: ë‚˜ìœ íŒë‹¨
        )
        
        # VIX ë³€í™” ëŒ€ì‘ (ê³µí¬ì§€ìˆ˜ ë³€í™”ì— ë”°ë¥¸ ëŒ€ì‘)
        df['vix_change_response'] = np.where(
            df['change_vix'] > 5,  # VIX ê¸‰ë“± (ê³µí¬ ì¦ê°€) ì‹œ
            np.where(df['return_pct'] > 0, 2,   # ìˆ˜ìµ ì‹¤í˜„: ì¢‹ì€ ëŒ€ì‘
                    np.where(df['return_pct'] > -5, 1, 0)),  # ì†Œì†ì‹¤ë„ ë‚˜ì˜ì§€ ì•ŠìŒ
            np.where(df['change_vix'] < -3,  # VIX í•˜ë½ (ì•ˆì •) ì‹œ
                    np.where(df['return_pct'] < 0, -1, 0), 0)    # ì•ˆì •ê¸° ì†ì‹¤: ì•„ì‰¬ì›€
        )
        
        # ë³€ë™ì„± ë³€í™” ëŒ€ì‘
        df['volatility_change_response'] = np.where(
            df['change_volatility_5d'] > 15,  # ë³€ë™ì„± ê¸‰ì¦ ì‹œ
            np.where(df['return_pct'] > 0, 2, 1),     # ìˆ˜ìµì‹¤í˜„ ì¢‹ìŒ, ì†ì ˆë„ ë‚˜ì˜ì§€ ì•ŠìŒ
            np.where(df['change_volatility_5d'] < -10,  # ë³€ë™ì„± ê°ì†Œ ì‹œ
                    np.where(df['return_pct'] < -5, -1, 0), 0)  # ì•ˆì •ê¸° ì†ì‹¤: ì•„ì‰¬ì›€
        )
        
        df['market_response_raw'] = (df['exit_momentum_response'] * 0.5 + 
                                    df['vix_change_response'] * 0.3 + 
                                    df['volatility_change_response'] * 0.2)

        # ===== ìµœì¢… ì ìˆ˜ ê³„ì‚° (ìŠ¤ì¼€ì¼ë§ ì ìš©) =====
        # ê° êµ¬ì„± ìš”ì†Œë³„ ìŠ¤ì¼€ì¼ë§
        if timing_scaler is None or profit_scaler is None or market_scaler is None:
            timing_scaler = RobustScaler()
            profit_scaler = RobustScaler() 
            market_scaler = RobustScaler()
            
            timing_scaled = timing_scaler.fit_transform(df[['timing_score_raw']])
            profit_scaled = profit_scaler.fit_transform(df[['profit_quality_raw']])
            market_scaled = market_scaler.fit_transform(df[['market_response_raw']])
            
            self.c_type_exit_scalers['timing_scaler'] = timing_scaler
            self.c_type_exit_scalers['profit_scaler'] = profit_scaler
            self.c_type_exit_scalers['market_scaler'] = market_scaler
        else:
            timing_scaled = timing_scaler.transform(df[['timing_score_raw']])
            profit_scaled = profit_scaler.transform(df[['profit_quality_raw']])
            market_scaled = market_scaler.transform(df[['market_response_raw']])
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ì ìˆ˜ ê³„ì‚°
        df['c_type_exit_score'] = (timing_scaled.flatten() * 0.4 + 
                                  profit_scaled.flatten() * 0.35 + 
                                  market_scaled.flatten() * 0.25)
        
        if verbose:
            print(f"  âœ… C-type Exit Score ìƒì„± ì™„ë£Œ")
            print(f"  ë²”ìœ„: {df['c_type_exit_score'].min():.4f} ~ {df['c_type_exit_score'].max():.4f}")
            print(f"  í‰ê· : {df['c_type_exit_score'].mean():.4f}")
            print(f"  êµ¬ì„±: íƒ€ì´ë° ì ì ˆì„±(40%) + ìˆ˜ìµ ì‹¤í˜„ í’ˆì§ˆ(35%) + ì‹œì¥ ëŒ€ì‘(25%)")
        
        return df

    def prepare_c_type_features(self, df, verbose=False):
        """
        C-type: ì²­ì‚° ì‹œì ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ ì¤€ë¹„
        
        ì²­ì‚° ì‹œì ì—ì„œ ì•Œ ìˆ˜ ìˆëŠ” ì •ë³´:
        - ì§„ì… ì‹œì  ì •ë³´ (entry_*): ì°¸ê³  ì •ë³´
        - í˜„ì¬(ì²­ì‚°) ì‹œì  ì •ë³´ (exit_*): í•µì‹¬ ì •ë³´
        - ë³´ìœ  ê¸°ê°„ ì¤‘ ë³€í™” (change_*): í•µì‹¬ ì •ë³´
        - ì‹œì¥ ì •ë³´ (market_*): í™˜ê²½ ì •ë³´
        """
        if verbose:
            print("ğŸ›‘ C-type: ì²­ì‚° íŒë‹¨ìš© í”¼ì²˜ ì¤€ë¹„")
        
        # ë¼ë²¨ë§ì— ì‚¬ìš©ëœ í”¼ì²˜ë“¤ ì œì™¸
        excluded_features = {
            'return_pct', 'holding_period_days', 'exit_volatility_20d', 'exit_momentum_20d',
            'change_volatility_5d', 'change_vix',
            # ì¤‘ê°„ ê³„ì‚° ë³€ìˆ˜ë“¤
            'daily_return_efficiency', 'holding_timing_base', 'return_timing_adjustment',
            'timing_score_raw', 'absolute_return_score', 'risk_adjusted_return', 'risk_adjusted_score',
            'cutloss_profit_score', 'profit_quality_raw', 'exit_momentum_response',
            'vix_change_response', 'volatility_change_response', 'market_response_raw',
            'c_type_exit_score'
        }
        
        # Cìœ í˜•ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ë“¤
        c_type_features = []
        
        # ===== 1. ê¸°ë³¸ ê±°ë˜ ì •ë³´ =====
        basic_features = ['position_size_pct']
        c_type_features.extend([col for col in basic_features if col in df.columns])
        
        # ===== 2. ì§„ì… ì‹œì  ì •ë³´ (ì°¸ê³ ìš©) =====
        entry_features = [
            'entry_momentum_5d', 'entry_momentum_20d', 'entry_momentum_60d',
            'entry_ma_dev_5d', 'entry_ma_dev_20d', 'entry_ma_dev_60d',
            'entry_volatility_5d', 'entry_volatility_60d',  # entry_volatility_20d ì œì™¸
            'entry_vol_change_5d', 'entry_vol_change_20d', 'entry_vol_change_60d',
            'entry_vix', 'entry_tnx_yield', 'entry_ratio_52w_high'
        ]
        c_type_features.extend([col for col in entry_features if col in df.columns])
        
        # ===== 3. ì²­ì‚° ì‹œì  ì •ë³´ (í•µì‹¬) =====
        exit_features = [
            'exit_momentum_5d', 'exit_momentum_60d',  # exit_momentum_20d ì œì™¸ (ë¼ë²¨ë§ ì‚¬ìš©)
            'exit_ma_dev_5d', 'exit_ma_dev_20d', 'exit_ma_dev_60d',
            'exit_volatility_5d', 'exit_volatility_60d',  # exit_volatility_20d ì œì™¸
            'exit_vix', 'exit_tnx_yield', 'exit_ratio_52w_high'
        ]
        c_type_features.extend([col for col in exit_features if col in df.columns])
        
        # ===== 4. ë³´ìœ  ê¸°ê°„ ì¤‘ ë³€í™” (ë§¤ìš° ì¤‘ìš”) =====
        change_features = [
            'change_momentum_5d', 'change_momentum_20d', 'change_momentum_60d',
            'change_ma_dev_5d', 'change_ma_dev_20d', 'change_ma_dev_60d',
            'change_volatility_20d', 'change_volatility_60d',  # change_volatility_5d ì œì™¸
            'change_tnx_yield', 'change_ratio_52w_high'
            # change_vixëŠ” ë¼ë²¨ë§ì— ì‚¬ìš©ë˜ë¯€ë¡œ ì œì™¸
        ]
        c_type_features.extend([col for col in change_features if col in df.columns])
        
        # ===== 5. ì‹œì¥ í™˜ê²½ ì •ë³´ =====
        market_features = [
            'market_return_during_holding',
            'excess_return'
        ]
        c_type_features.extend([col for col in market_features if col in df.columns])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ê³  ì œì™¸ë˜ì§€ ì•Šì€ í”¼ì²˜ë§Œ ì„ íƒ
        self.c_type_exit_features = [col for col in c_type_features 
                                    if col in df.columns and col not in excluded_features]
        
        if verbose:
            print(f"  Cìœ í˜• ì‚¬ìš© í”¼ì²˜: {len(self.c_type_exit_features)}ê°œ")
            print(f"  êµ¬ì„±: ì§„ì… ì •ë³´(ì°¸ê³ ) + ì²­ì‚° ì •ë³´(í•µì‹¬) + ë³€í™” ì •ë³´(ì¤‘ìš”) + ì‹œì¥ ì •ë³´")
            print(f"  ì œì™¸ëœ í”¼ì²˜: ë¼ë²¨ë§ì— ì‚¬ìš©ëœ ë³€ìˆ˜ë“¤ ë° ì¤‘ê°„ ê³„ì‚° ë³€ìˆ˜ë“¤")
        
        # ìˆ«ìí˜• ë°ì´í„°ë§Œ ì„ íƒ
        feature_data = df[self.c_type_exit_features].select_dtypes(include=[np.number])
        
        if verbose and len(feature_data.columns) != len(self.c_type_exit_features):
            print(f"  ë¹„ìˆ«ìí˜• ì»¬ëŸ¼ ì œì™¸: {len(self.c_type_exit_features) - len(feature_data.columns)}ê°œ")
        
        return feature_data

    # ================================
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
    # ================================
    
    def get_c_type_hyperparameter_grid(self):
        """
        C-type ëª¨ë¸ì— íŠ¹í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
        ì²­ì‚° ì‹ í˜¸ ì˜ˆì¸¡ì— ìµœì í™”ëœ íŒŒë¼ë¯¸í„° ë²”ìœ„
        """
        
        # C-type íŠ¹í™” íŒŒë¼ë¯¸í„° (ì²­ì‚° ì‹ í˜¸ ì˜ˆì¸¡)
        c_param_grid = {
            'objective': ['reg:squarederror'],
            'eval_metric': ['rmse'],
            
            # ì²­ì‚° ì‹ í˜¸ ì˜ˆì¸¡ì— íŠ¹í™”ëœ íŠ¸ë¦¬ êµ¬ì¡°
            'max_depth': [4, 5, 6, 7, 8, 9],  # ì¤‘ê°„ ê¹Šì´ (ê³¼ì í•© ë°©ì§€)
            'min_child_weight': [1, 2, 3, 4, 5, 8],
            'subsample': [0.7, 0.75, 0.8, 0.85, 0.9],
            'colsample_bytree': [0.7, 0.8, 0.85, 0.9, 0.95],
            'colsample_bylevel': [0.7, 0.8, 0.9, 1.0],
            
            # ì²­ì‚° ì‹ í˜¸ì— ì í•©í•œ í•™ìŠµë¥  (ì‹ í˜¸ ì˜ˆì¸¡ì´ë¯€ë¡œ ì¤‘ê°„ê°’)
            'learning_rate': [0.02, 0.03, 0.05, 0.07, 0.1, 0.15],
            'n_estimators': [200, 300, 400, 500, 600, 800],
            
            # ì²­ì‚° ì‹ í˜¸ íŠ¹í™” ì •ê·œí™” (ë…¸ì´ì¦ˆ ì œê±° ì¤‘ì‹œ)
            'reg_alpha': [0.05, 0.1, 0.2, 0.5, 1.0, 2.0],
            'reg_lambda': [1.0, 2.0, 3.0, 5.0, 8.0, 10.0],
            
            # ì²­ì‚° ì‹œì  ì˜ˆì¸¡ íŠ¹í™”
            'gamma': [0, 0.01, 0.05, 0.1, 0.2, 0.5],
            'max_delta_step': [0, 1, 2, 3],
            'scale_pos_weight': [1, 2, 3],
            
            # íŠ¸ë¦¬ ìƒì„±
            'tree_method': ['hist'],
            'grow_policy': ['depthwise', 'lossguide'],
            'max_leaves': [0, 31, 63, 127],
            'max_bin': [128, 256]
        }
        
        return c_param_grid

    def smart_c_type_hyperparameter_search(self, X_train, y_train, X_val, y_val, n_iter=150):
        """
        C-type ëª¨ë¸ì„ ìœ„í•œ ìŠ¤ë§ˆíŠ¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰
        1ë‹¨ê³„: RandomizedSearchCVë¡œ ë„“ì€ ë²”ìœ„ íƒìƒ‰
        2ë‹¨ê³„: ìµœì  íŒŒë¼ë¯¸í„° ì£¼ë³€ ì„¸ë°€ íƒìƒ‰
        """
        print("ğŸ›‘ C-type ìŠ¤ë§ˆíŠ¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ì‹œì‘")
        
        param_grid = self.get_c_type_hyperparameter_grid()
        base_model = xgb.XGBRegressor(random_state=42, n_jobs=1)
        
        # TimeSeriesSplit ì‚¬ìš© (ì‹œê³„ì—´ ë°ì´í„°)
        tscv = TimeSeriesSplit(n_splits=3)
        
        # 1ë‹¨ê³„: RandomizedSearchCV
        print("  1ë‹¨ê³„: ê´‘ë²”ìœ„ íŒŒë¼ë¯¸í„° íƒìƒ‰...")
        random_search = RandomizedSearchCV(
            base_model, param_grid, 
            n_iter=n_iter, cv=tscv, scoring='r2',
            random_state=42, n_jobs=1
        )
        random_search.fit(X_train, y_train)
        
        best_params_stage1 = random_search.best_params_
        stage1_score = random_search.best_score_
        
        print(f"  1ë‹¨ê³„ ì™„ë£Œ: CV RÂ² = {stage1_score:.4f}")
        
        # 2ë‹¨ê³„: ìµœì  íŒŒë¼ë¯¸í„° ì£¼ë³€ ì„¸ë°€ íƒìƒ‰
        print("  2ë‹¨ê³„: ì„¸ë°€ íŒŒë¼ë¯¸í„° íƒìƒ‰...")
        refined_grid = self._create_c_type_refined_grid(best_params_stage1)
        
        grid_search = GridSearchCV(
            base_model, refined_grid, 
            cv=tscv, scoring='r2', n_jobs=1
        )
        grid_search.fit(X_train, y_train)
        
        final_best_params = grid_search.best_params_
        stage2_score = grid_search.best_score_
        
        print(f"  2ë‹¨ê³„ ì™„ë£Œ: CV RÂ² = {stage2_score:.4f}")
        
        # ìµœì¢… ëª¨ë¸ë¡œ ê²€ì¦ ì„¸íŠ¸ í‰ê°€
        final_model = xgb.XGBRegressor(**final_best_params, random_state=42)
        final_model.fit(X_train, y_train)
        val_pred = final_model.predict(X_val)
        val_r2 = r2_score(y_val, val_pred)
        
        print(f"  ê²€ì¦ ì„¸íŠ¸ RÂ²: {val_r2:.4f}")
        
        return {
            'best_params': final_best_params,
            'best_model': final_model,
            'cv_score_stage1': stage1_score,
            'cv_score_stage2': stage2_score,
            'val_score': val_r2,
            'search_iterations': n_iter
        }

    def _create_c_type_refined_grid(self, best_params):
        """ìµœì  íŒŒë¼ë¯¸í„° ì£¼ë³€ì˜ ì„¸ë°€í•œ ê·¸ë¦¬ë“œ ìƒì„±"""
        
        refined_grid = {}
        
        # ê° íŒŒë¼ë¯¸í„°ë³„ ì„¸ë°€ ì¡°ì •
        if 'max_depth' in best_params:
            depth = best_params['max_depth']
            refined_grid['max_depth'] = [max(3, depth-1), depth, min(10, depth+1)]
        
        if 'learning_rate' in best_params:
            lr = best_params['learning_rate']
            refined_grid['learning_rate'] = [max(0.01, lr-0.02), lr, min(0.3, lr+0.02)]
            
        if 'n_estimators' in best_params:
            n_est = best_params['n_estimators']
            refined_grid['n_estimators'] = [max(100, n_est-100), n_est, min(1000, n_est+100)]
            
        if 'reg_alpha' in best_params:
            alpha = best_params['reg_alpha']
            refined_grid['reg_alpha'] = [max(0, alpha-0.1), alpha, alpha+0.1]
            
        if 'reg_lambda' in best_params:
            lambda_val = best_params['reg_lambda']
            refined_grid['reg_lambda'] = [max(0.5, lambda_val-1), lambda_val, lambda_val+1]
        
        # ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë“¤ì€ ìµœì ê°’ ê³ ì •
        for key, value in best_params.items():
            if key not in refined_grid:
                refined_grid[key] = [value]
        
        return refined_grid

    # ================================
    # Walk-Forward Validation
    # ================================
    
    def create_time_folds(self, df, verbose=False):
        """ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ìœ„í•œ Walk-Forward í´ë“œ ìƒì„±"""
        if verbose:
            print("ğŸ›‘ C-type Walk-Forward ì‹œê°„ í´ë“œ ìƒì„±")
        
        df = df.copy()
        df['date'] = pd.to_datetime(df['exit_date'])
        df = df.sort_values('date').reset_index(drop=True)
        
        start_date = df['date'].min()
        end_date = df['date'].max()
        
        folds = []
        current_start = start_date
        fold_id = 1
        
        while current_start + pd.DateOffset(months=self.train_months + self.val_months + self.test_months) <= end_date:
            train_end = current_start + pd.DateOffset(months=self.train_months)
            val_end = train_end + pd.DateOffset(months=self.val_months)
            test_end = val_end + pd.DateOffset(months=self.test_months)
            
            train_mask = (df['date'] >= current_start) & (df['date'] < train_end)
            val_mask = (df['date'] >= train_end) & (df['date'] < val_end)
            test_mask = (df['date'] >= val_end) & (df['date'] < test_end)
            
            if train_mask.sum() > 1000 and val_mask.sum() > 100 and test_mask.sum() > 100:
                fold_info = {
                    'fold_id': fold_id,
                    'train_start': current_start.strftime('%Y-%m-%d'),
                    'train_end': train_end.strftime('%Y-%m-%d'),
                    'val_start': train_end.strftime('%Y-%m-%d'),
                    'val_end': val_end.strftime('%Y-%m-%d'),
                    'test_start': val_end.strftime('%Y-%m-%d'),
                    'test_end': test_end.strftime('%Y-%m-%d'),
                    'train_indices': df[train_mask].index.tolist(),
                    'val_indices': df[val_mask].index.tolist(),
                    'test_indices': df[test_mask].index.tolist()
                }
                folds.append(fold_info)
                fold_id += 1
            
            current_start += pd.DateOffset(months=self.step_months)
        
        if verbose:
            print(f"  ìƒì„±ëœ í´ë“œ ìˆ˜: {len(folds)}ê°œ")
            for i, fold in enumerate(folds):
                print(f"  í´ë“œ {i+1}: {fold['train_start']} ~ {fold['test_end']}")
                print(f"    Train: {len(fold['train_indices']):,}ê°œ, Val: {len(fold['val_indices']):,}ê°œ, Test: {len(fold['test_indices']):,}ê°œ")
        
        return folds

    def run_c_type_walk_forward_training(self, data_path, verbose=True):
        """C-type ëª¨ë¸ì˜ Walk-Forward í•™ìŠµ ë° í‰ê°€"""
        if verbose:
            print("ğŸ›‘ C-type Walk-Forward í•™ìŠµ ì‹œì‘")
            print("="*60)
        
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(data_path)
        if verbose:
            print(f"ğŸ“Š ë°ì´í„° ë¡œë“œ: {len(df):,}ê°œ ê±°ë˜")
        
        # C-type ì ìˆ˜ ìƒì„±
        df = self.create_c_type_exit_score(df, verbose=verbose)
        
        # ì‹œê°„ í´ë“œ ìƒì„±
        folds = self.create_time_folds(df, verbose=verbose)
        
        fold_results = []
        
        for fold_info in tqdm(folds, desc="í´ë“œë³„ í•™ìŠµ"):
            if verbose:
                print(f"\nğŸ›‘ í´ë“œ {fold_info['fold_id']} í•™ìŠµ ì¤‘...")
            
            # í´ë“œë³„ ë°ì´í„° ë¶„í• 
            train_data = df.loc[fold_info['train_indices']]
            val_data = df.loc[fold_info['val_indices']]
            test_data = df.loc[fold_info['test_indices']]
            
            # í”¼ì²˜ ì¤€ë¹„
            X_train = self.prepare_c_type_features(train_data, verbose=False)
            X_val = self.prepare_c_type_features(val_data, verbose=False)
            X_test = self.prepare_c_type_features(test_data, verbose=False)
            
            y_train = train_data['c_type_exit_score']
            y_val = val_data['c_type_exit_score']
            y_test = test_data['c_type_exit_score']
            
            # TODO: í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (í˜„ì¬ ì£¼ì„ì²˜ë¦¬ - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)
            # search_result = self.smart_c_type_hyperparameter_search(
            #     X_train, y_train, X_val, y_val, n_iter=100
            # )
            
            # ë¯¸ë¦¬ ìµœì í™”ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©
            best_params = {
                'tree_method': 'approx', 'subsample': 0.75, 'scale_pos_weight': 10, 
                'reg_lambda': 20.0, 'reg_alpha': 1.0, 'objective': 'reg:squarederror', 
                'n_estimators': 800, 'min_child_weight': 2, 'max_leaves': 255, 
                'max_depth': 9, 'max_delta_step': 0, 'max_bin': 128, 
                'learning_rate': 0.01, 'grow_policy': 'depthwise', 'gamma': 0.5, 
                'eval_metric': 'rmse', 'colsample_bytree': 0.9, 'colsample_bynode': 0.8, 
                'colsample_bylevel': 0.8, 'random_state': 42
            }
            
            # ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµ
            best_model = xgb.XGBRegressor(**best_params)
            best_model.fit(X_train, y_train)
            val_pred = best_model.predict(X_val)
            val_r2 = r2_score(y_val, val_pred)
            
            search_result = {
                'best_params': best_params,
                'best_model': best_model,
                'val_score': val_r2
            }
            
            # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€
            test_pred = search_result['best_model'].predict(X_test)
            test_r2 = r2_score(y_test, test_pred)
            
            # ê²°ê³¼ ì €ì¥
            fold_result = {
                'fold_id': fold_info['fold_id'],
                'fold_info': fold_info,
                'best_params': search_result['best_params'],
                'val_r2': search_result['val_score'],
                'test_r2': test_r2,
                'train_samples': len(X_train),
                'val_samples': len(X_val),
                'test_samples': len(X_test),
                'features_used': len(X_train.columns)
            }
            
            fold_results.append(fold_result)
            
            if verbose:
                print(f"  í´ë“œ {fold_info['fold_id']} ì™„ë£Œ: Val RÂ² = {search_result['val_score']:.4f}, Test RÂ² = {test_r2:.4f}")
        
        self.fold_results = fold_results
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        if verbose:
            self.print_c_type_fold_summary()
        
        return fold_results

    def print_c_type_fold_summary(self):
        """í´ë“œë³„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not self.fold_results:
            print("âŒ í´ë“œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\n" + "="*70)
        print("ğŸ† C-type Walk-Forward ê²°ê³¼ ìš”ì•½")
        print("="*70)
        
        val_r2_scores = [result['val_r2'] for result in self.fold_results]
        test_r2_scores = [result['test_r2'] for result in self.fold_results]
        
        print(f"ğŸ“Š í´ë“œë³„ ì„±ëŠ¥:")
        for result in self.fold_results:
            print(f"  í´ë“œ {result['fold_id']}: Val RÂ² = {result['val_r2']:.4f}, Test RÂ² = {result['test_r2']:.4f}")
        
        print(f"\nğŸ“ˆ ì „ì²´ í†µê³„:")
        print(f"  Validation RÂ²: {np.mean(val_r2_scores):.4f} Â± {np.std(val_r2_scores):.4f}")
        print(f"  Test RÂ²:       {np.mean(test_r2_scores):.4f} Â± {np.std(test_r2_scores):.4f}")
        print(f"  ìµœê³  ì„±ëŠ¥:     {np.max(test_r2_scores):.4f} (í´ë“œ {np.argmax(test_r2_scores) + 1})")
        print(f"  í‰ê·  í”¼ì²˜ ìˆ˜:  {np.mean([r['features_used'] for r in self.fold_results]):.0f}ê°œ")
        
        print("="*70)

    def save_c_type_results(self, filename=None):
        """C-type ê²°ê³¼ ì €ì¥"""
        if filename is None:
            filename = f"c_type_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        save_data = {
            'model_version': 'c_type_v6',
            'model_name': 'C-type Exit Signal AI',
            'created_at': datetime.now().isoformat(),
            'total_folds': len(self.fold_results),
            'fold_results': []
        }
        
        for result in self.fold_results:
            # ëª¨ë¸ ê°ì²´ ì œì™¸í•˜ê³  ì €ì¥
            fold_data = {key: value for key, value in result.items() 
                        if key != 'best_model'}
            save_data['fold_results'].append(fold_data)
        
        with open(filename, 'w') as f:
            json.dump(save_data, f, indent=2, default=str)
        
        print(f"ğŸ’¾ C-type ê²°ê³¼ ì €ì¥: {filename}")
        return filename

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ›‘ C-type Exit Signal AI - ë§¤ë„ ì²­ì‚° ì‹ í˜¸ ì˜ˆì¸¡")
    print("="*60)
    print("ğŸ“‹ ëª¨ë¸ ëª©í‘œ:")
    print("  - ë§¤ë„ ì‹œì ì—ì„œ ì²­ì‚° ì¡°ê±´ì˜ ì ì ˆì„± í‰ê°€")
    print("  - íƒ€ì´ë° ì ì ˆì„± + ìˆ˜ìµ ì‹¤í˜„ í’ˆì§ˆ + ì‹œì¥ ëŒ€ì‘ ì¢…í•© ì ìˆ˜")
    print("  - Walk-Forward Validationìœ¼ë¡œ ì‹œê³„ì—´ ì•ˆì •ì„± ê²€ì¦")
    print("="*60)
    
    # ë°ì´í„° ê²½ë¡œ
    import os
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_path = os.path.join(current_dir, '../results/final/trading_episodes_with_rebuilt_market_component.csv')
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(data_path):
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        return
    
    # ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ
    model = CTypeExitSignalAI()
    
    # Walk-Forward í•™ìŠµ ì‹¤í–‰
    fold_results = model.run_c_type_walk_forward_training(data_path, verbose=True)
    
    # ê²°ê³¼ ì €ì¥
    model.save_c_type_results()
    
    print("\nâœ… C-type Exit Signal AI í•™ìŠµ ì™„ë£Œ!")
    return model

if __name__ == "__main__":
    main()