import pandas as pd
import numpy as np
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from scipy.stats import spearmanr
import xgboost as xgb
import joblib
import json
from datetime import datetime, timedelta
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class TradeQualityEvaluator:
    """ê±°ë˜ í’ˆì§ˆ í‰ê°€ ëª¨ë¸ì™„ë£Œëœ ë§¤ìˆ˜-ë§¤ë„ ê±°ë˜ì˜ í’ˆì§ˆì„ í‰ê°€"""

    def __init__(self, train_months=36, val_months=6, test_months=6, step_months=3):

        self.model = None
        self.trade_quality_scalers = {}
        self.features = None
        self.is_trained = False
        

        self.train_months = train_months
        self.val_months = val_months  
        self.test_months = test_months
        self.step_months = step_months
        

        self.fold_results = []
        self.best_params = None
        
    def create_quality_score(self, df, risk_scaler=None, eff_scaler=None, verbose=False):
        """ ê±°ë˜ í’ˆì§ˆ ì ìˆ˜ ìƒì„± """
        if verbose:
            print("ê±°ë˜ í’ˆì§ˆ ì ìˆ˜ ìƒì„± ì¤‘")
        
        df = df.copy()
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° NaN ì²˜ë¦¬
        required_columns = ['return_pct', 'entry_volatility_20d', 'entry_ratio_52w_high', 'holding_period_days']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
        
        df['return_pct'] = df['return_pct'].fillna(0)
        df['entry_volatility_20d'] = df['entry_volatility_20d'].fillna(0)
        df['entry_ratio_52w_high'] = df['entry_ratio_52w_high'].fillna(0)
        df['holding_period_days'] = df['holding_period_days'].fillna(0)

        # 1. ì§„ì… í’ˆì§ˆ (30%) - Buy Signal ê¸°ë°˜
        from buy_signal_predictor import BuySignalPredictor
        buy_predictor = BuySignalPredictor()
        
        # Buy Signal ì ìˆ˜ ìƒì„±
        df_with_buy = buy_predictor.create_entry_signal_score(df, verbose=False)
        df['entry_quality'] = df_with_buy['buy_signal_score']
        
        # 2. ì²­ì‚° íƒ€ì´ë° í’ˆì§ˆ (30%)
        df['exit_timing_quality'] = self._calculate_exit_timing_without_return(df)
        
        # 3. ìµœì¢… ì„±ê³¼ (40%) - ìˆ˜ìµë¥  ê¸°ë°˜
        df['result_quality'] = self._score_return(df['return_pct'])
        
        # 4. ìµœì¢… ê±°ë˜ í’ˆì§ˆ ì ìˆ˜ (0-100ì  ìŠ¤ì¼€ì¼ ìœ ì§€)
        df['trade_quality_score'] = (
            df['entry_quality'] * 0.3 + 
            df['exit_timing_quality'] * 0.3 +
            df['result_quality'] * 0.4
        )
        
        # 0-100 ë²”ìœ„ ë³´ì¥
        df['trade_quality_score'] = np.clip(df['trade_quality_score'], 0, 100)
        
        # ìŠ¤ì¼€ì¼ëŸ¬ëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
        if risk_scaler is None or eff_scaler is None:
            self.trade_quality_scalers['risk_scaler'] = None
            self.trade_quality_scalers['efficiency_scaler'] = None
        
        if verbose:
            print(f"   Trade Quality ì ìˆ˜ ìƒì„± ì™„ë£Œ")
            print(f"  ë²”ìœ„: {df['trade_quality_score'].min():.4f} ~ {df['trade_quality_score'].max():.4f}")
            print(f"  í‰ê· : {df['trade_quality_score'].mean():.4f}")

        
        return df
    
    def _calculate_exit_timing_without_return(self, df):
        """ì²­ì‚° íƒ€ì´ë° í’ˆì§ˆ ê³„ì‚° (ë°ì´í„° ê¸°ë°˜)"""
        
        # 1. ë³´ìœ  ê¸°ê°„ ì ì ˆì„± (ë¶„ìœ„ìˆ˜ ê¸°ë°˜)
        holding_percentiles = np.percentile(df['holding_period_days'], [25, 50, 75])
        p25, p50, p75 = holding_percentiles
        
        # 25%-75% êµ¬ê°„ì´ ì ì ˆí•œ ë³´ìœ ê¸°ê°„ìœ¼ë¡œ í‰ê°€
        holding_score = np.where(
            (df['holding_period_days'] >= p25) & (df['holding_period_days'] <= p75), 80,  # ì ì ˆí•œ êµ¬ê°„
            np.where(df['holding_period_days'] < p25, 60,  # ë„ˆë¬´ ì§§ìŒ
                np.where(df['holding_period_days'] <= p50 * 2, 70, 50))  # ì ë‹¹íˆ ê¹€ vs ë„ˆë¬´ ê¹€
        )
        
        # 2. VIX ë³€í™” ëŒ€ì‘ (ë¶„ìœ„ìˆ˜ ê¸°ë°˜)
        if 'change_vix' in df.columns:
            vix_percentiles = np.percentile(df['change_vix'], [25, 75])
            vix_p25, vix_p75 = vix_percentiles
            
            # VIX ìƒìœ„ 25% ìƒìŠ¹ ì‹œ ì²­ì‚° = ì¢‹ì€ íŒë‹¨
            vix_response = np.where(
                df['change_vix'] >= vix_p75, 80,  # ìƒìœ„ 25% VIX ê¸‰ë“±
                np.where(df['change_vix'] >= 0, 60,  # ì¼ë°˜ì  VIX ìƒìŠ¹
                    np.where(df['change_vix'] >= vix_p25, 50, 40))  # VIX í•˜ë½
            )
        else:
            vix_response = 50
        
        # 3. ëª¨ë©˜í…€ ëŒ€ì‘ (ë¶„ìœ„ìˆ˜ ê¸°ë°˜)
        if 'exit_momentum_20d' in df.columns:
            momentum_percentiles = np.percentile(df['exit_momentum_20d'], [25, 75])
            momentum_p25, momentum_p75 = momentum_percentiles
            
            # í•˜ìœ„ 25% ëª¨ë©˜í…€ì—ì„œ ì²­ì‚° = ì¢‹ì€ íƒ€ì´ë°
            momentum_response = np.where(
                df['exit_momentum_20d'] <= momentum_p25, 80,  # í•˜ìœ„ 25% ì•½í•œ ëª¨ë©˜í…€
                np.where(df['exit_momentum_20d'] <= 0, 70,  # ìŒìˆ˜ ëª¨ë©˜í…€
                    np.where(df['exit_momentum_20d'] <= momentum_p75, 60, 40))  # ê°•í•œ ëª¨ë©˜í…€
            )
        else:
            momentum_response = 50
        
        # ì¢…í•© ì²­ì‚° íƒ€ì´ë° ì ìˆ˜ (ìˆ˜ìµë¥ ê³¼ ë¬´ê´€)
        exit_timing_score = (
            holding_score * 0.4 +
            vix_response * 0.3 +
            momentum_response * 0.3
        )
        
        return exit_timing_score
    
    def _score_return(self, return_pct):
        """
        ìˆ˜ìµë¥ ì„ 0-100 ì ìˆ˜ë¡œ ë³€í™˜ (ë°ì´í„° ë¶„í¬ ê¸°ë°˜)
        """
        # ë°ì´í„° ê¸°ë°˜ ë¶„ìœ„ìˆ˜ ê³„ì‚°
        percentiles = np.percentile(return_pct, [10, 25, 50, 75, 90])
        p10, p25, p50, p75, p90 = percentiles
        
        # ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ì ìˆ˜ í• ë‹¹
        return np.where(
            return_pct >= p90, 100,     # ìƒìœ„ 10% 
            np.where(return_pct >= p75, 85,      # ìƒìœ„ 25%
            np.where(return_pct >= p50, 70,      # ìƒìœ„ 50% (ì¤‘ì•™ê°’ ì´ìƒ)
            np.where(return_pct >= p25, 55,      # ìƒìœ„ 75%
            np.where(return_pct >= p10, 40,      # ìƒìœ„ 90%
            np.where(return_pct >= 0, 25,        # ìˆ˜ìµì€ ë‚´ì§€ë§Œ í•˜ìœ„ 10%
            10))))))  # ì†ì‹¤

    def prepare_features(self, df, verbose=False):
        """ê±°ë˜ í’ˆì§ˆ ì˜ˆì¸¡ìš© í”¼ì²˜ ì¤€ë¹„"""
        if verbose:
            print("í’ˆì§ˆ í‰ê°€ìš© í”¼ì²˜ ì¤€ë¹„")

        excluded_features = {
            'return_pct', 'entry_volatility_20d', 'entry_ratio_52w_high', 'holding_period_days',
            'risk_adj_return', 'price_safety', 'risk_management_score',
            'time_efficiency', 'efficiency_score', 'quality_score', 'trade_quality_score'
        }
        

        available_features = []
        
        # 1. ê¸°ë³¸ ê±°ë˜ ì •ë³´
        basic_features = ['position_size_pct']
        available_features.extend([col for col in basic_features if col in df.columns])
        
        # 2. ì§„ì… ì‹œì  ê¸°ìˆ ì  ì§€í‘œ
        entry_features = [
            'entry_momentum_5d', 'entry_momentum_20d', 'entry_momentum_60d',
            'entry_ma_dev_5d', 'entry_ma_dev_20d', 'entry_ma_dev_60d',
            'entry_volatility_5d', 'entry_volatility_60d',
            'entry_vol_change_5d', 'entry_vol_change_20d', 'entry_vol_change_60d',
            'entry_vix', 'entry_tnx_yield'
        ]
        available_features.extend([col for col in entry_features if col in df.columns])
        
        #  3. ì¢…ë£Œ ì‹œì  ì§€í‘œ
        exit_features = [
            'exit_momentum_5d', 'exit_momentum_20d', 'exit_momentum_60d',
            'exit_ma_dev_5d', 'exit_ma_dev_20d', 'exit_ma_dev_60d',
            'exit_volatility_5d', 'exit_volatility_20d', 'exit_volatility_60d',
            'exit_vix', 'exit_tnx_yield', 'exit_ratio_52w_high'
        ]
        available_features.extend([col for col in exit_features if col in df.columns])
        
        # 4. ë³€í™”ëŸ‰ ì§€í‘œ
        change_features = [
            'change_momentum_5d', 'change_momentum_20d', 'change_momentum_60d',
            'change_ma_dev_5d', 'change_ma_dev_20d', 'change_ma_dev_60d',
            'change_volatility_5d', 'change_volatility_20d', 'change_volatility_60d',
            'change_vix', 'change_tnx_yield', 'change_ratio_52w_high'
        ]
        available_features.extend([col for col in change_features if col in df.columns])
        
        # 5. ë³´ìœ  ê¸°ê°„ ì¤‘ ì‹œì¥ ì •ë³´
        market_features = [
            'market_return_during_holding',
            'excess_return'
        ]
        available_features.extend([col for col in market_features if col in df.columns])
        

        self.features = [col for col in available_features 
                        if col in df.columns and col not in excluded_features]
        
        if verbose:
            print(f"  ì‚¬ìš© í”¼ì²˜: {len(self.features)}ê°œ")

        feature_data = df[self.features].select_dtypes(include=[np.number])
        
        if verbose and len(feature_data.columns) != len(self.features):
            print(f"  ë¹„ìˆ«ìí˜• ì»¬ëŸ¼ ì œì™¸: {len(self.features) - len(feature_data.columns)}ê°œ")
        
        return feature_data

    def train_model(self, df, hyperparameter_search=False, verbose=False):
        """ê±°ë˜ í’ˆì§ˆ ëª¨ë¸ í›ˆë ¨"""
        if verbose:
            print("ê±°ë˜ í’ˆì§ˆ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        
        # í’ˆì§ˆ ì ìˆ˜ ìƒì„±
        df_with_score = self.create_quality_score(df, verbose=verbose)
        
        # í”¼ì²˜ ì¤€ë¹„
        X = self.prepare_features(df_with_score, verbose=verbose)
        y = df_with_score['trade_quality_score']
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
        if hyperparameter_search:
            best_params = self._optimize_hyperparameters(X, y, verbose=verbose)
        else:
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
            best_params = {
                'max_depth': 6,
                'learning_rate': 0.1,
                'n_estimators': 300,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'reg_alpha': 0.1,
                'reg_lambda': 1.0,
                'random_state': 42
            }
        
        # ìµœì¢… ëª¨ë¸ í›ˆë ¨
        self.model = xgb.XGBRegressor(**best_params)
        self.model.fit(X, y)
        
        # ì„±ëŠ¥ í‰ê°€
        y_pred = self.model.predict(X)
        r2 = r2_score(y, y_pred)
        rmse = np.sqrt(mean_squared_error(y, y_pred))
        
        self.is_trained = True
        
        if verbose:
            print(f"  ê±°ë˜ í’ˆì§ˆ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
            print(f"  RÂ² Score: {r2:.4f}")
            print(f"  RMSE: {rmse:.4f}")
        
        return {
            'model': self.model,
            'r2_score': r2,
            'rmse': rmse,
            'best_params': best_params,
            'feature_count': len(self.features)
        }

    def predict_quality(self, df, verbose=False):
        """
        ê±°ë˜ í’ˆì§ˆ ì˜ˆì¸¡
        """
        if not self.is_trained:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•ŠìŒ.")
        
        if verbose:
            print("ê±°ë˜ í’ˆì§ˆ ì˜ˆì¸¡")
        
        # í”¼ì²˜ ì¤€ë¹„
        X = self.prepare_features(df, verbose=False)
        
        # ì˜ˆì¸¡
        predictions = self.model.predict(X)
        
        if verbose:
            print(f"  {len(predictions)}ê°œ ê±°ë˜ì˜ í’ˆì§ˆ ì˜ˆì¸¡ ì™„ë£Œ")
            print(f"  ì˜ˆì¸¡ ë²”ìœ„: {predictions.min():.4f} ~ {predictions.max():.4f}")
        
        return predictions

    def _optimize_hyperparameters(self, X, y, verbose=False):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”"""
        if verbose:
            print("  í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘")
        
        param_grid = {
            'max_depth': [4, 5, 6, 7, 8],
            'learning_rate': [0.05, 0.1, 0.15, 0.2],
            'n_estimators': [200, 300, 400, 500],
            'subsample': [0.7, 0.8, 0.9],
            'colsample_bytree': [0.7, 0.8, 0.9],
            'reg_alpha': [0, 0.1, 0.5, 1.0],
            'reg_lambda': [0.5, 1.0, 2.0]
        }
        

        base_model = xgb.XGBRegressor(
            random_state=42,
            tree_method='gpu_hist',
            gpu_id=0
        )
        tscv = TimeSeriesSplit(n_splits=3)
        

        search = GridSearchCV(
            base_model, param_grid, 
            cv=tscv, scoring='r2',
            verbose=1
        )
        search.fit(X, y)
        
        if verbose:
            print(f"  ìµœì  RÂ² Score: {search.best_score_:.4f}")
        
        return search.best_params_

    def save_model(self, filename=None):
        """ëª¨ë¸ ì €ì¥"""
        if not self.is_trained:
            raise ValueError("í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŒ")
        
        if filename is None:
            filename = f"trade_quality_evaluator_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
        
        save_data = {
            'model': self.model,
            'scalers': self.trade_quality_scalers,
            'features': self.features,
            'model_type': 'TRADE_QUALITY_EVALUATOR',
            'created_at': datetime.now().isoformat()
        }
        
        joblib.dump(save_data, filename)
        print(f" Trade Quality ëª¨ë¸ ì €ì¥: {filename}")
        return filename

    def load_model(self, filename):
        """ëª¨ë¸ ë¡œë“œ"""
        save_data = joblib.load(filename)
        
        self.model = save_data['model']
        self.trade_quality_scalers = save_data['scalers'] 
        self.features = save_data['features']
        self.is_trained = True
        
        print(f" Trade Quality ëª¨ë¸ ë¡œë“œ: {filename}")
        return True

    # ================================
    # Walk-Forward í•™ìŠµ íŒŒì´í”„ë¼ì¸ 
    # ================================
    
    def create_time_folds(self, df, verbose=False):
        if verbose:
            print(" Trade Quality Walk-Forward ì‹œê°„ í´ë“œ ìƒì„±")
        
        df = df.copy()
        df['date'] = pd.to_datetime(df['entry_datetime'])
        df = df.sort_values('date').reset_index(drop=True)
        
        start_date = df['date'].min()
        end_date = df['date'].max()
        
        folds = []
        current_start = start_date
        fold_id = 1
        
        while current_start + pd.DateOffset(months=self.train_months + self.val_months + self.test_months) <= end_date:
            train_end = current_start + pd.DateOffset(months=self.train_months)
            val_end = train_end + pd.DateOffset(months=self.val_months)
            test_end = val_end + pd.DateOffset(months=self.test_months)
            
            train_mask = (df['date'] >= current_start) & (df['date'] < train_end)
            val_mask = (df['date'] >= train_end) & (df['date'] < val_end)
            test_mask = (df['date'] >= val_end) & (df['date'] < test_end)
            
            if train_mask.sum() > 1000 and val_mask.sum() > 100 and test_mask.sum() > 100:
                fold_info = {
                    'fold_id': fold_id,
                    'train_start': current_start.strftime('%Y-%m-%d'),
                    'train_end': train_end.strftime('%Y-%m-%d'),
                    'val_start': train_end.strftime('%Y-%m-%d'),
                    'val_end': val_end.strftime('%Y-%m-%d'),
                    'test_start': val_end.strftime('%Y-%m-%d'),
                    'test_end': test_end.strftime('%Y-%m-%d'),
                    'train_indices': df[train_mask].index.tolist(),
                    'val_indices': df[val_mask].index.tolist(),
                    'test_indices': df[test_mask].index.tolist()
                }
                folds.append(fold_info)
                fold_id += 1
            
            current_start += pd.DateOffset(months=self.step_months)
        
        if verbose:
            print(f"  ìƒì„±ëœ í´ë“œ ìˆ˜: {len(folds)}ê°œ")
            for i, fold in enumerate(folds):
                print(f"  í´ë“œ {i+1}: {fold['train_start']} ~ {fold['test_end']}")
                print(f"    Train: {len(fold['train_indices']):,}ê°œ, Val: {len(fold['val_indices']):,}ê°œ, Test: {len(fold['test_indices']):,}ê°œ")
        
        return folds
    
    def run_walk_forward_training(self, data_path, hyperparameter_search=True, verbose=True):
        """Trade Quality Walk-Forward í•™ìŠµ ë° í‰ê°€"""
        if verbose:
            print(" Trade Quality Walk-Forward í•™ìŠµ ì‹œì‘")
            print("="*60)
        
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(data_path)
        if verbose:
            print(f" ë°ì´í„° ë¡œë“œ: {len(df):,}ê°œ ê±°ë˜")
        
        # Trade Quality ì ìˆ˜ ìƒì„±
        df = self.create_quality_score(df, verbose=verbose)
        
        # ì‹œê°„ í´ë“œ ìƒì„±
        folds = self.create_time_folds(df, verbose=verbose)
        
        fold_results = []
        
        for fold_info in tqdm(folds, desc="í´ë“œë³„ í•™ìŠµ"):
            if verbose:
                print(f"\n í´ë“œ {fold_info['fold_id']} í•™ìŠµ ì¤‘...")
            
            # í´ë“œë³„ ë°ì´í„° ë¶„í• 
            train_data = df.loc[fold_info['train_indices']]
            val_data = df.loc[fold_info['val_indices']]
            test_data = df.loc[fold_info['test_indices']]
            
            # í”¼ì²˜ ì¤€ë¹„
            X_train = self.prepare_features(train_data, verbose=False)
            X_val = self.prepare_features(val_data, verbose=False)
            X_test = self.prepare_features(test_data, verbose=False)
            
            y_train = train_data['trade_quality_score']
            y_val = val_data['trade_quality_score']
            y_test = test_data['trade_quality_score']
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
            if hyperparameter_search:
                search_result = self._optimize_hyperparameters(X_train, y_train, verbose=False)
                best_params = search_result
            else:
                # ê¸°ë³¸ íŒŒë¼ë¯¸í„° (Trade Quality íŠ¹í™”)
                best_params = {
                    'max_depth': 6,
                    'learning_rate': 0.1,
                    'n_estimators': 300,
                    'subsample': 0.8,
                    'colsample_bytree': 0.8,
                    'reg_alpha': 0.1,
                    'reg_lambda': 1.0,
                    'random_state': 42
                }
            
            # ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµ
            best_model = xgb.XGBRegressor(**best_params)
            best_model.fit(X_train, y_train)
            
            # ê²€ì¦ ë° í…ŒìŠ¤íŠ¸ í‰ê°€
            val_pred = best_model.predict(X_val)
            val_r2 = r2_score(y_val, val_pred)
            
            test_pred = best_model.predict(X_test)
            test_r2 = r2_score(y_test, test_pred)

            # í…ŒìŠ¤íŠ¸ì…‹ ì ìˆ˜-ìˆ˜ìµë¥  ìƒê´€ê´€ê³„ ë¶„ì„
            if verbose:
                self.calculate_ranking_performance(test_pred, y_test, verbose=True)

            # ê²°ê³¼ ì €ì¥
            fold_result = {
                'fold_id': fold_info['fold_id'],
                'fold_info': fold_info,
                'best_params': best_params,
                'val_r2': val_r2,
                'test_r2': test_r2,
                'train_samples': len(X_train),
                'val_samples': len(X_val),
                'test_samples': len(X_test),
                'features_used': len(X_train.columns),
                'best_model': best_model
            }
            
            fold_results.append(fold_result)
            
            if verbose:
                print(f"  í´ë“œ {fold_info['fold_id']} ì™„ë£Œ: Val RÂ² = {val_r2:.4f}, Test RÂ² = {test_r2:.4f}")
        
        self.fold_results = fold_results
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ìµœì¢… ëª¨ë¸ë¡œ ì„ íƒ
        best_fold = max(fold_results, key=lambda x: x['test_r2'])
        self.model = best_fold['best_model']
        self.best_params = best_fold['best_params']
        self.is_trained = True
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        if verbose:
            self._print_fold_summary()
        
        return fold_results
    
    def _print_fold_summary(self):
        """í´ë“œë³„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not self.fold_results:
            print(" í´ë“œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\n" + "="*70)
        print(" Trade Quality Walk-Forward ê²°ê³¼ ìš”ì•½")
        print("="*70)
        
        val_r2_scores = [result['val_r2'] for result in self.fold_results]
        test_r2_scores = [result['test_r2'] for result in self.fold_results]
        
        print(f" í´ë“œë³„ ì„±ëŠ¥:")
        for result in self.fold_results:
            print(f"  í´ë“œ {result['fold_id']}: Val RÂ² = {result['val_r2']:.4f}, Test RÂ² = {result['test_r2']:.4f}")
        
        print(f"\n ì „ì²´ í†µê³„:")
        print(f"  Validation RÂ²: {np.mean(val_r2_scores):.4f} Â± {np.std(val_r2_scores):.4f}")
        print(f"  Test RÂ²:       {np.mean(test_r2_scores):.4f} Â± {np.std(test_r2_scores):.4f}")
        print(f"  ìµœê³  ì„±ëŠ¥:     {np.max(test_r2_scores):.4f} (í´ë“œ {np.argmax(test_r2_scores) + 1})")
        print(f"  í‰ê·  í”¼ì²˜ ìˆ˜:  {np.mean([r['features_used'] for r in self.fold_results]):.0f}ê°œ")
        
        print("="*70)
    
    def calculate_ranking_performance(self, predictions, actuals, verbose=True):
        if len(predictions) != len(actuals):
            raise ValueError("ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ê¸¸ì´ê°€ ë‹¤ë¦„")
        
        # 1. ìƒê´€ê´€ê³„ ë¶„ì„
        spearman_corr, spearman_p = spearmanr(predictions, actuals)
        pearson_corr = np.corrcoef(predictions, actuals)[0, 1]
        
        # 2. êµ¬ê°„ë³„ ë¶„ì„
        quintiles = np.quantile(predictions, [0.2, 0.4, 0.6, 0.8])
        
        results = {
            'correlations': {
                'spearman': spearman_corr,
                'spearman_pvalue': spearman_p,
                'pearson': pearson_corr
            },
            'quintile_analysis': []
        }
        
        if verbose:
            print("\n" + "="*60)
            print(" ì ìˆ˜-ìˆ˜ìµë¥  ìƒê´€ê´€ê³„ ë¶„ì„")
            print("="*60)
            print(f" Spearman ìƒê´€ê³„ìˆ˜: {spearman_corr:.4f} (p={spearman_p:.4f})")
            print(f" Pearson ìƒê´€ê³„ìˆ˜:  {pearson_corr:.4f}")
            
            print(f"\n ì ìˆ˜ êµ¬ê°„ë³„ ë¶„ì„ (ì´ {len(predictions):,}ê°œ ìƒ˜í”Œ):")
            print("-" * 60)
        
        # ê° ë¶„ìœ„ë³„ ë¶„ì„
        quintile_names = ['í•˜ìœ„ 20%', 'í•˜ìœ„ì¤‘ 20%', 'ì¤‘ìœ„ 20%', 'ìƒìœ„ì¤‘ 20%', 'ìƒìœ„ 20%']
        
        for i in range(5):
            if i == 0:
                mask = predictions <= quintiles[0]
            elif i == 4:
                mask = predictions > quintiles[3]
            else:
                mask = (predictions > quintiles[i-1]) & (predictions <= quintiles[i])
            
            if np.sum(mask) > 0:
                quintile_actuals = actuals[mask]
                quintile_preds = predictions[mask]
                
                quintile_result = {
                    'quintile': i + 1,
                    'name': quintile_names[i],
                    'count': int(np.sum(mask)),
                    'pred_range': [float(quintile_preds.min()), float(quintile_preds.max())],
                    'actual_mean': float(quintile_actuals.mean()),
                    'actual_std': float(quintile_actuals.std()),
                    'actual_median': float(np.median(quintile_actuals))
                }
                
                results['quintile_analysis'].append(quintile_result)
                
                if verbose:
                    print(f"{quintile_names[i]:>8} | "
                          f"ìƒ˜í”Œ: {np.sum(mask):>5,}ê°œ | "
                          f"ì˜ˆì¸¡ë²”ìœ„: [{quintile_preds.min():>6.2f}, {quintile_preds.max():>6.2f}] | "
                          f"ì‹¤ì œí‰ê· : {quintile_actuals.mean():>7.3f} Â± {quintile_actuals.std():>6.3f}")
        
        # 3. ë‹¨ì¡°ì„± ê²€ì‚¬
        quintile_means = [q['actual_mean'] for q in results['quintile_analysis']]
        is_monotonic = all(quintile_means[i] <= quintile_means[i+1] for i in range(len(quintile_means)-1))
        
        results['monotonicity'] = {
            'is_monotonic': is_monotonic,
            'mean_difference': quintile_means[-1] - quintile_means[0] if len(quintile_means) >= 2 else 0
        }
        
        # 4. Top/Bottom ë¶„ì„
        top20_mask = predictions >= np.percentile(predictions, 80)
        bottom20_mask = predictions <= np.percentile(predictions, 20)
        
        results['top_bottom_analysis'] = {
            'top20_mean': float(actuals[top20_mask].mean()),
            'bottom20_mean': float(actuals[bottom20_mask].mean()),
            'spread': float(actuals[top20_mask].mean() - actuals[bottom20_mask].mean())
        }
        
        if verbose:
            print("-" * 60)
            print(f" ë‹¨ì¡°ì„± ê²€ì‚¬: {' í†µê³¼' if is_monotonic else ' ì‹¤íŒ¨'}")
            print(f" ìƒí•˜ìœ„ ìŠ¤í”„ë ˆë“œ: {results['top_bottom_analysis']['spread']:.3f}")
            print(f"   - ìƒìœ„ 20% í‰ê· : {results['top_bottom_analysis']['top20_mean']:.3f}")
            print(f"   - í•˜ìœ„ 20% í‰ê· : {results['top_bottom_analysis']['bottom20_mean']:.3f}")
            print("="*60)
        
        return results
    
    def save_training_results(self, filename=None):
        """í•™ìŠµ ê²°ê³¼ ì €ì¥ """
        if filename is None:
            filename = f"trade_quality_debug_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        save_data = {
            'model_type': 'TRADE_QUALITY_EVALUATOR',
            'model_name': 'Trade Quality Evaluator',
            'created_at': datetime.now().isoformat(),
            'total_folds': len(self.fold_results),
            'best_params': self.best_params,
            'fold_results': []
        }
        
        for result in self.fold_results:
            fold_data = {key: value for key, value in result.items() 
                        if key != 'best_model'}
            save_data['fold_results'].append(fold_data)
        
        with open(filename, 'w') as f:
            json.dump(save_data, f, indent=2, default=str)
        
        print(f" Trade Quality í•™ìŠµ ê²°ê³¼ ì €ì¥: {filename}")
        return filename

def main():
    """Trade Quality Evaluator í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print(" Trade Quality Evaluator - ê±°ë˜ í’ˆì§ˆ í‰ê°€ ëª¨ë¸ í•™ìŠµ")
    print("="*70)

    
    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    import os
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_path = os.path.join(current_dir, '../results/final/trading_episodes_with_rebuilt_market_component.csv')
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(data_path):
        print(f" ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        return
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    evaluator = TradeQualityEvaluator()
    
    # ë¶„í•  í•™ìŠµ ì‹¤í–‰
    try:
        # ë°ì´í„° ë¡œë“œ
        import pandas as pd
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
        import numpy as np
        
        df = pd.read_csv(data_path)
        print(f"\në°ì´í„° ë¡œë“œ: {len(df):,}ê°œ ê±°ë˜")
        

        df_filtered = df[
            df['entry_pe_ratio'].notna() & 
            df['entry_roe'].notna() & 
            df['entry_earnings_growth'].notna() &
            df['return_pct'].notna() &
            df['holding_period_days'].notna() &
            df['entry_volatility_20d'].notna() &
            df['entry_ratio_52w_high'].notna()
        ].copy()
        
        print(f"ğŸ“Š í€ë”ë©˜í„¸ ë°ì´í„° í•„í„°ë§: {len(df_filtered):,}ê°œ ({len(df_filtered)/len(df)*100:.1f}%)")
        
        # Train/Val/Test ë¶„í•  (60/20/20)
        train_val_df, test_df = train_test_split(df_filtered, test_size=0.2, random_state=42)
        train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2
        
        print(f"\nğŸ“Š ë°ì´í„° ë¶„í• :")
        print(f"  Train: {len(train_df):,}ê°œ ({len(train_df)/len(df_filtered)*100:.1f}%)")
        print(f"  Val:   {len(val_df):,}ê°œ ({len(val_df)/len(df_filtered)*100:.1f}%)")
        print(f"  Test:  {len(test_df):,}ê°œ ({len(test_df)/len(df_filtered)*100:.1f}%)")
        
        # ëª¨ë¸ í•™ìŠµ
        print(f"\n ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        result = evaluator.train_model(train_df, hyperparameter_search=False, verbose=True)
        
        # í‰ê°€ í•¨ìˆ˜
        def evaluate_model(evaluator, data, name):
            data_with_score = evaluator.create_quality_score(data, verbose=False)
            X = evaluator.prepare_features(data_with_score, verbose=False)
            y = data_with_score['trade_quality_score']
            y_pred = evaluator.model.predict(X)
            
            r2 = r2_score(y, y_pred)
            rmse = np.sqrt(mean_squared_error(y, y_pred))
            mae = mean_absolute_error(y, y_pred)
            
            return {
                'name': name,
                'r2': r2,
                'rmse': rmse,
                'mae': mae,
                'y_mean': y.mean(),
                'y_std': y.std(),
                'pred_mean': y_pred.mean(),
                'pred_std': y_pred.std()
            }
        
        # ê° ì„¸íŠ¸ í‰ê°€
        train_metrics = evaluate_model(evaluator, train_df, 'Train')
        val_metrics = evaluate_model(evaluator, val_df, 'Val')
        test_metrics = evaluate_model(evaluator, test_df, 'Test')
        
        # ì„±ê³¼ ì¶œë ¥
        print(f"\n ì„±ê³¼ ì§€í‘œ:")
        print("="*60)
        print(f"{'Dataset':<10} {'RÂ²':>8} {'RMSE':>8} {'MAE':>8} {'Mean':>8} {'Std':>8}")
        print("-"*60)
        for metrics in [train_metrics, val_metrics, test_metrics]:
            print(f"{metrics['name']:<10} {metrics['r2']:>8.4f} {metrics['rmse']:>8.4f} {metrics['mae']:>8.4f} {metrics['y_mean']:>8.4f} {metrics['y_std']:>8.4f}")
        
        # ì˜¤ë²„í”¼íŒ… ì²´í¬
        overfit_score = train_metrics['r2'] - val_metrics['r2']
        print(f"\n ì˜¤ë²„í”¼íŒ… ë¶„ì„:")
        if overfit_score > 0.05:
            print(f"  ï¸  ì˜¤ë²„í”¼íŒ… ê°€ëŠ¥ì„±: Train-Val RÂ² ì°¨ì´ = {overfit_score:.4f}")
        else:
            print(f"   ì˜¤ë²„í”¼íŒ… ì—†ìŒ: Train-Val RÂ² ì°¨ì´ = {overfit_score:.4f}")
        
        # Val-Test ì„±ëŠ¥ ì•ˆì •ì„±
        stability_score = abs(val_metrics['r2'] - test_metrics['r2'])
        print(f"\nğŸ“ ì„±ëŠ¥ ì•ˆì •ì„±:")
        if stability_score < 0.05:
            print(f"   ì•ˆì •ì : Val-Test RÂ² ì°¨ì´ = {stability_score:.4f}")
        else:
            print(f"    ë¶ˆì•ˆì •: Val-Test RÂ² ì°¨ì´ = {stability_score:.4f}")
        
        # ëª¨ë¸ ì €ì¥
        model_filename = evaluator.save_model()
        
        print(f"\n Trade Quality ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        print(f" ì €ì¥ëœ ëª¨ë¸: {model_filename}")
        
        # ì‚¬ìš©ë²• ì•ˆë‚´
        print(f"\n ëª¨ë¸ ì‚¬ìš©ë²•:")
        print(f"evaluator = TradeQualityEvaluator()")
        print(f"evaluator.load_model('{model_filename}')")
        print(f"quality_scores = evaluator.predict_quality(completed_trades_df)")
        
        return evaluator
        
    except Exception as e:
        print(f" í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()