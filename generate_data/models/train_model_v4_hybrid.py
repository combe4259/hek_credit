import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV
from tqdm import tqdm
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import xgboost as xgb
import joblib
import json
from datetime import datetime
import warnings
import torch
warnings.filterwarnings('ignore')

class HybridTradingAI:
    """
    í•˜ì´ë¸Œë¦¬ë“œ íŠ¸ë ˆì´ë”© AI v4
    
    êµ¬ì¡°:
    1. Aìœ í˜•: ì™„ë£Œëœ ê±°ë˜ì˜ ì •í™•í•œ í’ˆì§ˆ í‰ê°€ (ì‚¬í›„ ë¶„ì„)
    2. Bìœ í˜•: í˜„ì¬ ìƒí™© ê¸°ë°˜ ì§„ì… ì¡°ê±´ ë¶„ì„ (ì‹¤ì‹œê°„ ì§€ì›, ë¯¸ë˜ ì˜ˆì¸¡ ì—†ìŒ)
    
    íŠ¹ì§•:
    - Data Leakage ì™„ì „ ì œê±°
    - í˜„ì‹¤ì ì¸ ì˜ì‚¬ê²°ì • ì§€ì›
    - ì •í™•í•œ ì‚¬í›„ í’ˆì§ˆ í‰ê°€
    """
    
    def __init__(self, train_months=36, val_months=6, test_months=6, step_months=3):
        self.train_months = train_months
        self.val_months = val_months
        self.test_months = test_months
        self.step_months = step_months
        
        # ===== Aìœ í˜•: ê±°ë˜ í’ˆì§ˆ ë¶„ì„ê¸° (Post-Trade Quality Analyzer) =====
        self.a_type_quality_model = None      # í’ˆì§ˆ í‰ê°€ ì˜ˆì¸¡ ëª¨ë¸
        self.a_type_quality_scalers = {}      # Aìœ í˜• ì „ìš© ìŠ¤ì¼€ì¼ëŸ¬ë“¤
        self.a_type_quality_features = None   # Aìœ í˜•ì´ ì‚¬ìš©í•˜ëŠ” í”¼ì²˜ ëª©ë¡
        
        # ===== Bìœ í˜•: ì§„ì… ì¡°ê±´ í‰ê°€ê¸° (Entry Condition Evaluator) =====  
        self.b_type_entry_model = None        # ì§„ì… ì¡°ê±´ ì˜ˆì¸¡ ëª¨ë¸
        self.b_type_entry_scalers = {}        # Bìœ í˜• ì „ìš© ìŠ¤ì¼€ì¼ëŸ¬ë“¤
        self.b_type_entry_features = None     # Bìœ í˜•ì´ ì‚¬ìš©í•˜ëŠ” í”¼ì²˜ ëª©ë¡
        
        self.fold_results = []
    
    # ================================
    # Aìœ í˜•: ì‚¬í›„ í’ˆì§ˆ í‰ê°€ (ì™„ì „í•œ ê±°ë˜ ë°ì´í„° ì‚¬ìš©)
    # ================================
    
    def create_a_type_quality_score(self, df, risk_scaler=None, eff_scaler=None, verbose=False):
        """Aìœ í˜•: ì™„ë£Œëœ ê±°ë˜ì˜ í’ˆì§ˆ ì ìˆ˜ ìƒì„± (ëª¨ë“  ì •ë³´ í™œìš© ê°€ëŠ¥)"""
        if verbose:
            print("ğŸ¯ Aìœ í˜•: Quality Score ìƒì„± ì¤‘...")
        
        df = df.copy()
        
        # NaN ì²˜ë¦¬ (ì¤‘ë¦½ì  ê°’ 0ìœ¼ë¡œ ì²˜ë¦¬)
        df['return_pct'] = df['return_pct'].fillna(0)
        df['entry_volatility_20d'] = df['entry_volatility_20d'].fillna(0)
        df['entry_ratio_52w_high'] = df['entry_ratio_52w_high'].fillna(0)
        df['holding_period_days'] = df['holding_period_days'].fillna(0)
        
        # Risk Management Quality (40%) - ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ì„±ê³¼
        volatility_safe = np.maximum(df['entry_volatility_20d'], 0.01)
        df['risk_adj_return'] = df['return_pct'] / volatility_safe
        df['risk_adj_return'] = np.where(
            np.isinf(df['risk_adj_return']) | np.isnan(df['risk_adj_return']), 
            0, df['risk_adj_return']
        )
        
        ratio_safe = np.clip(df['entry_ratio_52w_high'], 0, 100)
        df['price_safety'] = (100 - ratio_safe) / 100
        
        df['risk_management_score'] = df['risk_adj_return'] * 0.6 + df['price_safety'] * 0.4
        
        # Efficiency Quality (60%) - ì‹œê°„ ëŒ€ë¹„ íš¨ìœ¨ì„±
        holding_safe = np.maximum(df['holding_period_days'], 1)
        df['time_efficiency'] = df['return_pct'] / holding_safe
        df['time_efficiency'] = np.where(
            np.isinf(df['time_efficiency']) | np.isnan(df['time_efficiency']), 
            0, df['time_efficiency']
        )
        
        df['efficiency_score'] = df['time_efficiency']
        
        # ìŠ¤ì¼€ì¼ë§ ë° ì¢…í•© ì ìˆ˜
        if risk_scaler is None or eff_scaler is None:
            risk_scaler = RobustScaler()
            eff_scaler = RobustScaler()
            
            risk_scaled = risk_scaler.fit_transform(df[['risk_management_score']])
            eff_scaled = eff_scaler.fit_transform(df[['efficiency_score']])
            
            self.a_type_quality_scalers['risk_scaler'] = risk_scaler
            self.a_type_quality_scalers['efficiency_scaler'] = eff_scaler
        else:
            risk_scaled = risk_scaler.transform(df[['risk_management_score']])
            eff_scaled = eff_scaler.transform(df[['efficiency_score']])
        
        df['a_type_quality_score'] = risk_scaled.flatten() * 0.4 + eff_scaled.flatten() * 0.6
        
        if verbose:
            print(f"  âœ… Quality Score ìƒì„± ì™„ë£Œ")
            print(f"  ë²”ìœ„: {df['a_type_quality_score'].min():.4f} ~ {df['a_type_quality_score'].max():.4f}")
            print(f"  í‰ê· : {df['a_type_quality_score'].mean():.4f}")
        
        return df
    
    def prepare_a_type_features(self, df, verbose=False):
        """Aìœ í˜•: í’ˆì§ˆ í‰ê°€ìš© í”¼ì²˜ ì¤€ë¹„ (ì™„ë£Œëœ ê±°ë˜ì˜ ëª¨ë“  ì •ë³´ ì‚¬ìš© ê°€ëŠ¥)"""
        if verbose:
            print("ğŸ”§ Aìœ í˜•: í’ˆì§ˆ í‰ê°€ìš© í”¼ì²˜ ì¤€ë¹„ ì¤‘...")
        
        # Quality Score ê³„ì‚°ìš© í”¼ì²˜ëŠ” ì œì™¸
        excluded_features = {
            'return_pct', 'entry_volatility_20d', 'entry_ratio_52w_high', 'holding_period_days',
            'risk_adj_return', 'price_safety', 'risk_management_score',
            'time_efficiency', 'efficiency_score', 'quality_score', 'a_type_quality_score'
        }
        
        # Aìœ í˜•ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  í”¼ì²˜ ì¹´í…Œê³ ë¦¬
        available_a_type_features = []
        
        # ===== 1. ê¸°ë³¸ ê±°ë˜ ì •ë³´ =====
        basic_trade_info = ['position_size_pct']  # ê±°ë˜ ê·œëª¨
        available_a_type_features.extend([col for col in basic_trade_info if col in df.columns])
        
        # ===== 2. ì§„ì… ì‹œì  ê¸°ìˆ ì  ì§€í‘œ =====
        entry_technical_indicators = [
            # ëª¨ë©˜í…€ ì§€í‘œ
            'entry_momentum_5d', 'entry_momentum_60d', 
            # ì´ë™í‰ê·  ê´´ë¦¬ë„
            'entry_ma_dev_5d', 'entry_ma_dev_20d', 'entry_ma_dev_60d',
            # ë³€ë™ì„± (entry_volatility_20d ì œì™¸ - quality_scoreì— ì‚¬ìš©ë¨)
            'entry_volatility_5d', 'entry_volatility_60d',
            # ë³€ë™ì„± ë³€í™”ìœ¨
            'entry_vol_change_5d', 'entry_vol_change_20d', 'entry_vol_change_60d',
            # ì‹œì¥ í™˜ê²½
            'entry_vix', 'entry_tnx_yield'
        ]
        available_a_type_features.extend([col for col in entry_technical_indicators if col in df.columns])
        
        # ===== 3. ì¢…ë£Œ ì‹œì  ì§€í‘œ (Aìœ í˜•ë§Œ ì‚¬ìš© ê°€ëŠ¥!) =====
        exit_technical_indicators = [
            # ì¢…ë£Œ ì‹œì  ëª¨ë©˜í…€
            'exit_momentum_5d', 'exit_momentum_20d', 'exit_momentum_60d',
            # ì¢…ë£Œ ì‹œì  ì´ë™í‰ê·  ê´´ë¦¬ë„
            'exit_ma_dev_5d', 'exit_ma_dev_20d', 'exit_ma_dev_60d',
            # ì¢…ë£Œ ì‹œì  ë³€ë™ì„±
            'exit_volatility_5d', 'exit_volatility_20d', 'exit_volatility_60d',
            # ì¢…ë£Œ ì‹œì  ì‹œì¥ í™˜ê²½
            'exit_vix', 'exit_tnx_yield', 'exit_ratio_52w_high'
        ]
        available_a_type_features.extend([col for col in exit_technical_indicators if col in df.columns])
        
        # ===== 4. ë³€í™”ëŸ‰ ì§€í‘œ (Aìœ í˜•ë§Œ ì‚¬ìš© ê°€ëŠ¥!) =====
        change_indicators = [
            # ëª¨ë©˜í…€ ë³€í™”
            'change_momentum_5d', 'change_momentum_20d', 'change_momentum_60d',
            # ì´ë™í‰ê·  êµŒë¦¬ë„ ë³€í™”
            'change_ma_dev_5d', 'change_ma_dev_20d', 'change_ma_dev_60d',
            # ë³€ë™ì„± ë³€í™”
            'change_volatility_5d', 'change_volatility_60d',
            # ì‹œì¥ í™˜ê²½ ë³€í™”
            'change_vix', 'change_tnx_yield', 'change_ratio_52w_high'
        ]
        available_a_type_features.extend([col for col in change_indicators if col in df.columns])
        
        # ===== 5. ë³´ìœ  ê¸°ê°„ ì¤‘ ì‹œì¥ ì •ë³´ (Aìœ í˜•ë§Œ ì‚¬ìš© ê°€ëŠ¥!) =====
        holding_period_info = [
            'market_return_during_holding',  # ë³´ìœ  ê¸°ê°„ ì¤‘ ì‹œì¥ ìˆ˜ìµë¥ 
            'excess_return'                  # ì‹œì¥ ëŒ€ë¹„ ì´ˆê³¼ ìˆ˜ìµë¥ 
        ]
        available_a_type_features.extend([col for col in holding_period_info if col in df.columns])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í”¼ì²˜ë§Œ ì„ íƒ
        self.a_type_quality_features = [col for col in available_a_type_features 
                                       if col in df.columns and col not in excluded_features]
        
        if verbose:
            print(f"  Aìœ í˜• ì‚¬ìš© í”¼ì²˜: {len(self.a_type_quality_features)}ê°œ")
            print(f"  í¬í•¨ëœ í”¼ì²˜ ìœ í˜•: entry, exit, change, holding (ëª¨ë“  ì •ë³´ í™œìš©)")
        
        return df[self.a_type_quality_features]
    
    # ================================
    # Bìœ í˜•: í˜„ì¬ ìƒí™© ê¸°ë°˜ ì§„ì… ì¡°ê±´ ë¶„ì„ (ë¯¸ë˜ ì˜ˆì¸¡ ì—†ìŒ)
    # ================================
    
    def create_b_type_entry_condition_score(self, df, verbose=False):
        """Bìœ í˜•: í˜„ì¬ ì§„ì… ì¡°ê±´ ë¶„ì„ ì ìˆ˜ (ë¯¸ë˜ ì •ë³´ ì‚¬ìš© ê¸ˆì§€)"""
        if verbose:
            print("ğŸ”® Bìœ í˜• (ì§„ì… ì¡°ê±´ í‰ê°€): Entry Condition Score ìƒì„± ì¤‘...")
            print("   â†’ í˜„ì¬ ì‹œì  ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ë§¤ìˆ˜ ì í•©ë„ í‰ê°€")
        
        df = df.copy()
        
        # NaN ì²˜ë¦¬ (ì¤‘ë¦½ì  ê°’ 0ìœ¼ë¡œ ì²˜ë¦¬)
        df['entry_vix'] = df['entry_vix'].fillna(0)
        df['entry_volatility_20d'] = df['entry_volatility_20d'].fillna(0)
        df['entry_ratio_52w_high'] = df['entry_ratio_52w_high'].fillna(0)
        df['entry_momentum_20d'] = df['entry_momentum_20d'].fillna(0)
        
        # 1. ê¸°ìˆ ì  ì¡°ê±´ ì ìˆ˜ (40%)
        # RSI ê°œë…: ê³¼ë§¤ë„ì¼ìˆ˜ë¡ ì¢‹ìŒ
        rsi_proxy = np.clip((100 - df['entry_ratio_52w_high']) / 100, 0, 1)
        
        # ëª¨ë©˜í…€: ì ë‹¹í•œ í•˜ë½ í›„ ë°˜ë“± ì‹ í˜¸ê°€ ì¢‹ìŒ
        momentum_safe = np.clip(df['entry_momentum_20d'], -50, 50)
        momentum_score = np.where(momentum_safe < -10, 0.8,  # í•˜ë½ í›„
                                np.where(momentum_safe > 10, 0.3, 0.6))  # ìƒìŠ¹ ì¤‘
        
        df['b_type_technical_score'] = rsi_proxy * 0.6 + momentum_score * 0.4
        
        # ===== 2. ì‹œì¥ í™˜ê²½ ì ìˆ˜ (35%): "ì „ë°˜ì ìœ¼ë¡œ ë§¤ìˆ˜í•˜ê¸° ì¢‹ì€ ì‹œê¸°ì¸ê°€?" =====
        
        # 2-1. VIX ê¸°ë°˜ ì‹œì¥ ì•ˆì •ì„± í‰ê°€
        # â†’ VIXê°€ ë‚®ì„ìˆ˜ë¡ ì‹œì¥ì´ ì•ˆì •í•˜ì—¬ ë§¤ìˆ˜ ì ê¸°
        # VIX 10: ë§¤ìš° ì•ˆì • (1.0ì ), VIX 50: ë§¤ìš° ë¶ˆì•ˆ (0ì )
        vix_safe = np.clip(df['entry_vix'], 10, 50)
        market_stability_score = (50 - vix_safe) / 40
        
        # 2-2. ì‹œì¥ í™˜ê²½ ì¢…í•© ì ìˆ˜ (í˜„ì¬ëŠ” VIXë§Œ ì‚¬ìš©)
        df['b_type_market_env_score'] = market_stability_score
        
        # ===== 3. ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ ì ìˆ˜ (25%): "í˜„ì¬ ìœ„í—˜ë„ê°€ ì ì ˆí•œê°€?" =====
        
        # 3-1. ë³€ë™ì„± ì ì •ì„± í‰ê°€
        # â†’ ë„ˆë¬´ ë‚®ìœ¼ë©´ ìœ ë™ì„± ë¶€ì¡±, ë„ˆë¬´ ë†’ìœ¼ë©´ ìœ„í—˜
        # 20-30% ë³€ë™ì„±ì´ ì ì • ìˆ˜ì¤€
        vol_safe = np.clip(df['entry_volatility_20d'], 10, 100)
        volatility_score = np.where(
            vol_safe < 25, 1.0,      # ë‚®ì€ ë³€ë™ì„± (ì•ˆì „)
            np.where(vol_safe > 50, 0.3, 0.7)  # ë†’ì€ ë³€ë™ì„± (ìœ„í—˜)
        )
        
        # 3-2. ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ ì¢…í•© ì ìˆ˜ (í˜„ì¬ëŠ” ë³€ë™ì„±ë§Œ ì‚¬ìš©)
        df['b_type_risk_score'] = volatility_score
        
        # ì¢…í•© ì§„ì… ì¡°ê±´ ì ìˆ˜
        df['b_type_entry_condition_score'] = (df['b_type_technical_score'] * 0.4 + 
                                             df['b_type_market_env_score'] * 0.35 + 
                                             df['b_type_risk_score'] * 0.25)
        
        # 0-100 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        df['b_type_entry_condition_score'] = df['b_type_entry_condition_score'] * 100
        
        if verbose:
            print(f"  âœ… ì§„ì… ì¡°ê±´ ì ìˆ˜ ìƒì„± ì™„ë£Œ")
            print(f"  ë²”ìœ„: {df['b_type_entry_condition_score'].min():.1f} ~ {df['b_type_entry_condition_score'].max():.1f}")
            print(f"  í‰ê· : {df['b_type_entry_condition_score'].mean():.1f}")
        
        return df
    
    def prepare_b_type_features(self, df, verbose=False):
        """Bìœ í˜•: ì§„ì… ì¡°ê±´ ë¶„ì„ìš© í”¼ì²˜ ì¤€ë¹„ (ì§„ì… ì‹œì  ì •ë³´ë§Œ ì‚¬ìš©)"""
        if verbose:
            print("ğŸ”§ Bìœ í˜•: ì§„ì… ì¡°ê±´ ë¶„ì„ìš© í”¼ì²˜ ì¤€ë¹„ ì¤‘...")
        
        # Bìœ í˜•ì—ì„œëŠ” ë¯¸ë˜ ì •ë³´ ì™„ì „ ê¸ˆì§€!
        forbidden_patterns = ['exit_', 'change_', 'holding', 'return_pct']
        
        # ì§„ì… ì‹œì  ì •ë³´ë§Œ ì‚¬ìš© ê°€ëŠ¥
        available_features = []
        
        # 1. ê¸°ë³¸ ì •ë³´
        basic_features = ['position_size_pct']  # ê³„íšëœ í¬ì§€ì…˜ í¬ê¸°
        available_features.extend([col for col in basic_features if col in df.columns])
        
        # 2. ì§„ì… ì‹œì  ê¸°ìˆ ì  ì§€í‘œë§Œ
        entry_features = [
            'entry_momentum_5d', 'entry_momentum_20d', 'entry_momentum_60d',
            'entry_ma_dev_5d', 'entry_ma_dev_20d', 'entry_ma_dev_60d',
            'entry_volatility_5d', 'entry_volatility_60d',  # entry_volatility_20d ì œì™¸ (íƒ€ê²Ÿ ê³„ì‚°ì— ì‚¬ìš©)
            'entry_vol_change_5d', 'entry_vol_change_20d', 'entry_vol_change_60d'
        ]
        available_features.extend([col for col in entry_features if col in df.columns])
        
        # 3. ì§„ì… ì‹œì  ì‹œì¥ í™˜ê²½
        market_features = ['entry_vix', 'entry_tnx_yield']
        available_features.extend([col for col in market_features if col in df.columns])
        
        # ë¯¸ë˜ ì •ë³´ ì™„ì „ ì œê±°
        safe_features = []
        for feature in available_features:
            is_safe = True
            for pattern in forbidden_patterns:
                if pattern in feature:
                    is_safe = False
                    break
            if is_safe and feature in df.columns:
                safe_features.append(feature)
        
        # entry_volatility_20d, entry_ratio_52w_high ì œê±° (ì ìˆ˜ ê³„ì‚°ì— ì‚¬ìš©ë¨)
        target_calculation_features = {'entry_volatility_20d', 'entry_ratio_52w_high', 'entry_momentum_20d'}
        safe_features = [f for f in safe_features if f not in target_calculation_features]
        
        self.b_type_entry_features = safe_features
        
        if verbose:
            print(f"  Bìœ í˜• ì‚¬ìš© í”¼ì²˜: {len(self.b_type_entry_features)}ê°œ")
            print(f"  í”¼ì²˜ ë²”ìœ„: í˜„ì¬/ì§„ì… ì‹œì  ì •ë³´ë§Œ (ì‹¤ì‹œê°„ í™œìš© ê°€ëŠ¥)")
            print(f"  Data Leakage ë°©ì§€: entry_condition_score ê³„ì‚° í”¼ì²˜ ë° ë¯¸ë˜ ì •ë³´ ì œì™¸")
            if len(self.b_type_entry_features) < 10:
                print(f"  êµ¬ì²´ì  í”¼ì²˜: {self.b_type_entry_features}")
        
        return df[self.b_type_entry_features] if self.b_type_entry_features else pd.DataFrame()
    
    # ================================
    # Walk-Forward Validation
    # ================================
    
    def create_walk_forward_folds(self, df, verbose=False):
        """Walk-Forward ë¶„í•  ìƒì„±"""
        if verbose:
            print("ğŸ“… Walk-Forward ë¶„í•  ìƒì„± ì¤‘...")
        
        df = df.copy()
        df['entry_date'] = pd.to_datetime(df['entry_datetime'])
        df = df.sort_values('entry_date')
        
        start_date = df['entry_date'].min()
        end_date = df['entry_date'].max()
        
        folds = []
        current_date = start_date + pd.DateOffset(months=self.train_months)
        
        while current_date + pd.DateOffset(months=self.val_months + self.test_months) <= end_date:
            train_start = current_date - pd.DateOffset(months=self.train_months)
            train_end = current_date
            val_start = train_end
            val_end = val_start + pd.DateOffset(months=self.val_months)
            test_start = val_end
            test_end = test_start + pd.DateOffset(months=self.test_months)
            
            train_mask = (df['entry_date'] >= train_start) & (df['entry_date'] < train_end)
            val_mask = (df['entry_date'] >= val_start) & (df['entry_date'] < val_end)
            test_mask = (df['entry_date'] >= test_start) & (df['entry_date'] < test_end)
            
            if train_mask.sum() > 1000 and val_mask.sum() > 100 and test_mask.sum() > 100:
                folds.append({
                    'fold_id': len(folds) + 1,
                    'train_start': train_start.date(),
                    'train_end': train_end.date(),
                    'val_start': val_start.date(),
                    'val_end': val_end.date(),
                    'test_start': test_start.date(),
                    'test_end': test_end.date(),
                    'train_idx': df[train_mask].index,
                    'val_idx': df[val_mask].index,
                    'test_idx': df[test_mask].index
                })
            
            current_date += pd.DateOffset(months=self.step_months)
        
        if verbose:
            print(f"  ìƒì„±ëœ í´ë“œ ìˆ˜: {len(folds)}ê°œ")
            for i, fold in enumerate(folds):
                print(f"    Fold {i+1}: Train {fold['train_start']} ~ {fold['train_end']}")
                print(f"             Val   {fold['val_start']} ~ {fold['val_end']}")
                print(f"             Test  {fold['test_start']} ~ {fold['test_end']}")
                print(f"             Size: {len(fold['train_idx'])}/{len(fold['val_idx'])}/{len(fold['test_idx'])}")
        
        return folds
    
    def evaluate_single_fold(self, df, fold, verbose=False):
        """ë‹¨ì¼ í´ë“œì—ì„œ Aìœ í˜•ê³¼ Bìœ í˜• ëª¨ë¸ ëª¨ë‘ í‰ê°€"""
        if verbose:
            print(f"\nğŸ”„ Fold {fold['fold_id']} í‰ê°€ ì¤‘...")
        
        # ë°ì´í„° ë¶„í• 
        train_data = df.loc[fold['train_idx']].copy()
        val_data = df.loc[fold['val_idx']].copy()
        test_data = df.loc[fold['test_idx']].copy()
        
        # GPU ì„¤ì •
        gpu_available = torch.cuda.is_available()
        base_model = xgb.XGBRegressor(
            tree_method='gpu_hist' if gpu_available else 'hist',
            gpu_id=0 if gpu_available else None,
            random_state=42,
            eval_metric='rmse'
        )
        
        param_grid = {
            'n_estimators': [100, 200],
            'learning_rate': [0.05, 0.1],
            'max_depth': [6, 8],
            'subsample': [0.8, 0.9],
            'colsample_bytree': [0.8, 0.9]
        }
        
        results = {}
        
        # ================================
        # Aìœ í˜•: í’ˆì§ˆ í‰ê°€ ëª¨ë¸ í•™ìŠµ
        # ================================
        try:
            # Aìœ í˜• Quality Score ìƒì„±
            train_data_a = self.create_a_type_quality_score(train_data, verbose=False)
            val_data_a = self.create_a_type_quality_score(
                val_data, 
                risk_scaler=self.a_type_quality_scalers.get('risk_scaler'),
                eff_scaler=self.a_type_quality_scalers.get('efficiency_scaler'),
                verbose=False
            )
            test_data_a = self.create_a_type_quality_score(
                test_data,
                risk_scaler=self.a_type_quality_scalers.get('risk_scaler'),
                eff_scaler=self.a_type_quality_scalers.get('efficiency_scaler'),
                verbose=False
            )
            
            # Aìœ í˜• í”¼ì²˜ ì¤€ë¹„
            X_train_a = self.prepare_a_type_features(train_data_a, verbose=False)
            X_val_a = self.prepare_a_type_features(val_data_a, verbose=False)
            X_test_a = self.prepare_a_type_features(test_data_a, verbose=False)
            
            y_train_a = train_data_a['a_type_quality_score']
            y_val_a = val_data_a['a_type_quality_score']
            y_test_a = test_data_a['a_type_quality_score']
            
            # ê²°ì¸¡ì¹˜ ì œê±°
            train_mask_a = ~(X_train_a.isnull().any(axis=1) | y_train_a.isnull())
            val_mask_a = ~(X_val_a.isnull().any(axis=1) | y_val_a.isnull())
            test_mask_a = ~(X_test_a.isnull().any(axis=1) | y_test_a.isnull())
            
            X_train_a = X_train_a[train_mask_a]
            X_val_a = X_val_a[val_mask_a]
            X_test_a = X_test_a[test_mask_a]
            y_train_a = y_train_a[train_mask_a]
            y_val_a = y_val_a[val_mask_a]
            y_test_a = y_test_a[test_mask_a]
            
            if len(X_train_a) > 0 and len(self.a_type_quality_features) > 0:
                # ìŠ¤ì¼€ì¼ë§
                scaler_a = RobustScaler()
                X_train_a_scaled = scaler_a.fit_transform(X_train_a)
                X_val_a_scaled = scaler_a.transform(X_val_a)
                X_test_a_scaled = scaler_a.transform(X_test_a)
                
                # GridSearchCV
                grid_search_a = GridSearchCV(base_model, param_grid, cv=3, scoring='r2', n_jobs=-1, verbose=0)
                grid_search_a.fit(X_train_a_scaled, y_train_a)
                
                # í‰ê°€
                best_model_a = grid_search_a.best_estimator_
                
                y_val_pred_a = best_model_a.predict(X_val_a_scaled)
                y_test_pred_a = best_model_a.predict(X_test_a_scaled)
                
                results['A_quality_model'] = {
                    'val_r2': r2_score(y_val_a, y_val_pred_a),
                    'test_r2': r2_score(y_test_a, y_test_pred_a),
                    'val_rmse': np.sqrt(mean_squared_error(y_val_a, y_val_pred_a)),
                    'test_rmse': np.sqrt(mean_squared_error(y_test_a, y_test_pred_a)),
                    'best_params': grid_search_a.best_params_,
                    'best_cv_score': grid_search_a.best_score_,
                    'train_size': len(X_train_a),
                    'val_size': len(X_val_a),
                    'test_size': len(X_test_a)
                }
            else:
                results['A_quality_model'] = {'error': 'Insufficient data or features'}
                
        except Exception as e:
            results['A_quality_model'] = {'error': str(e)}
        
        # ================================
        # Bìœ í˜•: ì§„ì… ì¡°ê±´ ë¶„ì„ ëª¨ë¸ í•™ìŠµ
        # ================================
        try:
            # Bìœ í˜• Entry Condition Score ìƒì„±
            train_data_b = self.create_b_type_entry_condition_score(train_data, verbose=False)
            val_data_b = self.create_b_type_entry_condition_score(val_data, verbose=False)
            test_data_b = self.create_b_type_entry_condition_score(test_data, verbose=False)
            
            # Bìœ í˜• í”¼ì²˜ ì¤€ë¹„
            X_train_b = self.prepare_b_type_features(train_data_b, verbose=False)
            X_val_b = self.prepare_b_type_features(val_data_b, verbose=False)
            X_test_b = self.prepare_b_type_features(test_data_b, verbose=False)
            
            y_train_b = train_data_b['b_type_entry_condition_score']
            y_val_b = val_data_b['b_type_entry_condition_score']
            y_test_b = test_data_b['b_type_entry_condition_score']
            
            if len(X_train_b.columns) > 0:
                # ê²°ì¸¡ì¹˜ ì œê±°
                train_mask_b = ~(X_train_b.isnull().any(axis=1) | y_train_b.isnull())
                val_mask_b = ~(X_val_b.isnull().any(axis=1) | y_val_b.isnull())
                test_mask_b = ~(X_test_b.isnull().any(axis=1) | y_test_b.isnull())
                
                X_train_b = X_train_b[train_mask_b]
                X_val_b = X_val_b[val_mask_b]
                X_test_b = X_test_b[test_mask_b]
                y_train_b = y_train_b[train_mask_b]
                y_val_b = y_val_b[val_mask_b]
                y_test_b = y_test_b[test_mask_b]
                
                if len(X_train_b) > 100:
                    # ìŠ¤ì¼€ì¼ë§
                    scaler_b = RobustScaler()
                    X_train_b_scaled = scaler_b.fit_transform(X_train_b)
                    X_val_b_scaled = scaler_b.transform(X_val_b)
                    X_test_b_scaled = scaler_b.transform(X_test_b)
                    
                    # GridSearchCV
                    grid_search_b = GridSearchCV(base_model, param_grid, cv=3, scoring='r2', n_jobs=-1, verbose=0)
                    grid_search_b.fit(X_train_b_scaled, y_train_b)
                    
                    # í‰ê°€
                    best_model_b = grid_search_b.best_estimator_
                    
                    y_val_pred_b = best_model_b.predict(X_val_b_scaled)
                    y_test_pred_b = best_model_b.predict(X_test_b_scaled)
                    
                    results['B_entry_model'] = {
                        'val_r2': r2_score(y_val_b, y_val_pred_b),
                        'test_r2': r2_score(y_test_b, y_test_pred_b),
                        'val_rmse': np.sqrt(mean_squared_error(y_val_b, y_val_pred_b)),
                        'test_rmse': np.sqrt(mean_squared_error(y_test_b, y_test_pred_b)),
                        'best_params': grid_search_b.best_params_,
                        'best_cv_score': grid_search_b.best_score_,
                        'train_size': len(X_train_b),
                        'val_size': len(X_val_b),
                        'test_size': len(X_test_b)
                    }
                else:
                    results['B_entry_model'] = {'error': 'Insufficient training data'}
            else:
                results['B_entry_model'] = {'error': 'No valid features for B-type model'}
                
        except Exception as e:
            results['B_entry_model'] = {'error': str(e)}
        
        # ì‹œì¥ í™˜ê²½ ë¶„ì„
        market_stats = {
            'train_vix_mean': train_data['entry_vix'].mean() if 'entry_vix' in train_data.columns else np.nan,
            'val_vix_mean': val_data['entry_vix'].mean() if 'entry_vix' in val_data.columns else np.nan,
            'test_vix_mean': test_data['entry_vix'].mean() if 'entry_vix' in test_data.columns else np.nan,
            'train_return_mean': train_data['return_pct'].mean(),
            'val_return_mean': val_data['return_pct'].mean(),
            'test_return_mean': test_data['return_pct'].mean()
        }
        
        return {
            'fold_id': fold['fold_id'],
            'fold_info': fold,
            'model_results': results,
            'market_stats': market_stats
        }
    
    def run_walk_forward_validation(self, df, verbose=False):
        """ì „ì²´ Walk-Forward Validation ì‹¤í–‰"""
        print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ AI Walk-Forward Validation ì‹œì‘")
        print("="*70)
        
        # í´ë“œ ìƒì„±
        folds = self.create_walk_forward_folds(df, verbose=True)
        
        if len(folds) == 0:
            print("âŒ ìƒì„±ëœ í´ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ê° í´ë“œ í‰ê°€
        all_results = []
        
        print(f"\nğŸ“Š {len(folds)}ê°œ í´ë“œ í‰ê°€ ì¤‘...")
        
        for fold in tqdm(folds, desc="Evaluating folds"):
            try:
                result = self.evaluate_single_fold(df, fold, verbose=False)
                all_results.append(result)
            except Exception as e:
                print(f"âš ï¸ Fold {fold['fold_id']} í‰ê°€ ì‹¤íŒ¨: {e}")
                continue
        
        self.fold_results = all_results
        
        # ê²°ê³¼ ì§‘ê³„
        self.aggregate_results(verbose=True)
        
        return all_results
    
    def aggregate_results(self, verbose=False):
        """í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ê²°ê³¼ ì§‘ê³„"""
        if not self.fold_results:
            print("âŒ ì§‘ê³„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if verbose:
            print("\nğŸ“ˆ í•˜ì´ë¸Œë¦¬ë“œ AI ê²°ê³¼ ì§‘ê³„")
            print("="*50)
        
        # Aìœ í˜• ê²°ê³¼ ì§‘ê³„
        a_results = []
        b_results = []
        
        for result in self.fold_results:
            if 'A_quality_model' in result['model_results'] and 'error' not in result['model_results']['A_quality_model']:
                a_results.append(result['model_results']['A_quality_model'])
            
            if 'B_entry_model' in result['model_results'] and 'error' not in result['model_results']['B_entry_model']:
                b_results.append(result['model_results']['B_entry_model'])
        
        if verbose:
            print(f"\nğŸ¯ Aìœ í˜• (í’ˆì§ˆ í‰ê°€) ì„±ëŠ¥:")
            if a_results:
                val_r2_a = [r['val_r2'] for r in a_results]
                test_r2_a = [r['test_r2'] for r in a_results]
                
                print(f"  ì„±ê³µì ì¸ í´ë“œ: {len(a_results)}/{len(self.fold_results)}")
                print(f"  Validation RÂ²: {np.mean(val_r2_a):.4f} Â± {np.std(val_r2_a):.4f}")
                print(f"  Test RÂ²:       {np.mean(test_r2_a):.4f} Â± {np.std(test_r2_a):.4f}")
                print(f"  Test RÂ² ë²”ìœ„:  [{np.min(test_r2_a):.4f}, {np.max(test_r2_a):.4f}]")
            else:
                print("  âŒ ì„±ê³µí•œ Aìœ í˜• ëª¨ë¸ ì—†ìŒ")
            
            print(f"\nğŸ”® Bìœ í˜• (ì§„ì… ì¡°ê±´) ì„±ëŠ¥:")
            if b_results:
                val_r2_b = [r['val_r2'] for r in b_results]
                test_r2_b = [r['test_r2'] for r in b_results]
                
                print(f"  ì„±ê³µì ì¸ í´ë“œ: {len(b_results)}/{len(self.fold_results)}")
                print(f"  Validation RÂ²: {np.mean(val_r2_b):.4f} Â± {np.std(val_r2_b):.4f}")
                print(f"  Test RÂ²:       {np.mean(test_r2_b):.4f} Â± {np.std(test_r2_b):.4f}")
                print(f"  Test RÂ² ë²”ìœ„:  [{np.min(test_r2_b):.4f}, {np.max(test_r2_b):.4f}]")
            else:
                print("  âŒ ì„±ê³µí•œ Bìœ í˜• ëª¨ë¸ ì—†ìŒ")
            
            # ì‹œì¥ í™˜ê²½ë³„ ì„±ëŠ¥
            print(f"\nğŸŒŠ ì‹œì¥ í™˜ê²½ë³„ ì„±ëŠ¥ ë¶„ì„:")
            for i, result in enumerate(self.fold_results):
                market = result['market_stats']
                vix_level = "ê³ ë³€ë™" if market['test_vix_mean'] > 25 else "ì €ë³€ë™"
                return_level = "ìƒìŠ¹" if market['test_return_mean'] > 0.05 else "í•˜ë½"
                
                a_perf = "N/A"
                b_perf = "N/A"
                
                if 'A_quality_model' in result['model_results'] and 'error' not in result['model_results']['A_quality_model']:
                    a_perf = f"{result['model_results']['A_quality_model']['test_r2']:.4f}"
                
                if 'B_entry_model' in result['model_results'] and 'error' not in result['model_results']['B_entry_model']:
                    b_perf = f"{result['model_results']['B_entry_model']['test_r2']:.4f}"
                
                print(f"  Fold {i+1}: {vix_level}/{return_level} â†’ A:{a_perf} / B:{b_perf}")
    
    def save_results(self, filepath_prefix='hybrid_results'):
        """ê²°ê³¼ ì €ì¥"""
        if not self.fold_results:
            print("âŒ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê²°ê³¼ ì €ì¥
        results_for_save = []
        for result in self.fold_results:
            result_copy = result.copy()
            
            # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            fold_info = result_copy['fold_info'].copy()
            for key in ['train_start', 'train_end', 'val_start', 'val_end', 'test_start', 'test_end']:
                if key in fold_info:
                    fold_info[key] = str(fold_info[key])
            
            # ì¸ë±ìŠ¤ ì œê±°
            del fold_info['train_idx']
            del fold_info['val_idx']
            del fold_info['test_idx']
            
            result_copy['fold_info'] = fold_info
            results_for_save.append(result_copy)
        
        with open(f'{filepath_prefix}.json', 'w') as f:
            json.dump(results_for_save, f, indent=2)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'model_version': 'hybrid_v4',
            'model_type': 'Hybrid A+B Type with XGBoost',
            'A_type_features': self.a_type_quality_features,
            'B_type_features': self.b_type_entry_features,
            'walk_forward_params': {
                'train_months': self.train_months,
                'val_months': self.val_months,
                'test_months': self.test_months,
                'step_months': self.step_months
            },
            'gpu_settings': {
                'gpu_available': torch.cuda.is_available(),
                'num_gpus': torch.cuda.device_count() if torch.cuda.is_available() else 0
            },
            'training_timestamp': datetime.now().isoformat(),
            'model_description': {
                'A_type': {
                    'name': 'Post-Trade Quality Analyzer',
                    'purpose': 'ì´ ê±°ë˜ê°€ ì–¼ë§ˆë‚˜ ì¢‹ì€ ê±°ë˜ì˜€ëŠ”ê°€?',
                    'usage': 'ê±°ë˜ ë³µê¸°, ì„±ê³¼ ë¶„ì„, íŠ¸ë ˆì´ë” í‰ê°€',
                    'data_scope': 'ëª¨ë“  ê±°ë˜ ì •ë³´ í™œìš© (ì§„ì…+ì§„í–‰+ì¢…ë£Œ)',
                    'accuracy': 'ë†’ìŒ (ì™„ì „í•œ ì •ë³´ í™œìš©)'
                },
                'B_type': {
                    'name': 'Real-time Entry Condition Evaluator',
                    'purpose': 'ì§€ê¸ˆ ë§¤ìˆ˜í•˜ê¸° ì¢‹ì€ ì¡°ê±´ì¸ê°€?',
                    'usage': 'ë§¤ìˆ˜ íƒ€ì´ë°, ì¢…ëª© ì„ ë³„, ë¦¬ìŠ¤í¬ ê´€ë¦¬',
                    'data_scope': 'í˜„ì¬ ì‹œì  ì •ë³´ë§Œ (ë¯¸ë˜ ì •ë³´ ì™„ì „ ì°¨ë‹¨)',
                    'practicality': 'ë†’ìŒ (ì‹¤ì œ íŠ¸ë ˆì´ë”© í™˜ê²½ê³¼ ë™ì¼)'
                },
                'key_difference': {
                    'A_type': 'ê³¼ê±° ë¶„ì„ â†’ ì •í™•í•œ í’ˆì§ˆ ì¸¡ì •',
                    'B_type': 'í˜„ì¬ ë¶„ì„ â†’ í˜„ì‹¤ì  í™œìš© ê°€ëŠ¥'
                }
            },
            'total_folds': len(self.fold_results)
        }
        
        with open(f'{filepath_prefix}_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath_prefix}.*")

def main():
    """
    ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ íŠ¸ë ˆì´ë”© AI v4 ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    Aìœ í˜•ê³¼ Bìœ í˜• ëª¨ë¸ì„ ë™ì‹œì— í•™ìŠµí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.
    
    ì‹¤í–‰ ê³¼ì •:
    1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    2. Walk-Forward í´ë“œ ìƒì„±
    3. ê° í´ë“œì—ì„œ Aìœ í˜•, Bìœ í˜• ëª¨ë¸ ë³‘ë ¬ í•™ìŠµ
    4. ì„±ëŠ¥ ê²°ê³¼ ì§‘ê³„ ë° ë¶„ì„
    5. ê²°ê³¼ ì €ì¥
    """
    print("ğŸš€ ì˜ë¯¸ê°€ ëª…í™•í•´ì§„ í•˜ì´ë¸Œë¦¬ë“œ íŠ¸ë ˆì´ë”© AI v4")
    print("   Aìœ í˜•: ì™„ë£Œëœ ê±°ë˜ í’ˆì§ˆ ë¶„ì„ê¸° (Post-Trade Quality Analyzer)")
    print("   Bìœ í˜•: ì‹¤ì‹œê°„ ì§„ì… ì¡°ê±´ í‰ê°€ê¸° (Real-time Entry Condition Evaluator)")
    print("="*80)
    
    # GPU í™•ì¸
    print(f"GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    print(f"GPU ê°œìˆ˜: {torch.cuda.device_count()}")
    
    # ë°ì´í„° ë¡œë“œ
    print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
    df = pd.read_csv('../results/final/trading_episodes_with_rebuilt_market_component.csv')
    print(f"  ì´ ë°ì´í„°: {len(df):,}ê°œ")
    
    # í•˜ì´ë¸Œë¦¬ë“œ AI ëª¨ë¸ ì´ˆê¸°í™”
    print("\nğŸ› ï¸ í•˜ì´ë¸Œë¦¬ë“œ AI ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    model = HybridTradingAI(
        train_months=36,     # í•™ìŠµ ê¸°ê°„: 36ê°œì›” (3ë…„)
        val_months=6,        # ê²€ì¦ ê¸°ê°„: 6ê°œì›”
        test_months=6,       # í…ŒìŠ¤íŠ¸ ê¸°ê°„: 6ê°œì›”
        step_months=3        # ìŠ¬ë¼ì´ë”© ê°„ê²©: 3ê°œì›”
    )
    print(f"   âœ… Walk-Forward ì„¤ì •: {36}ê°œì›” í•™ìŠµ â†’ {6}ê°œì›” ê²€ì¦ â†’ {6}ê°œì›” í…ŒìŠ¤íŠ¸")
    print(f"   âœ… ìŠ¬ë¼ì´ë”© ìœˆë„ìš°: {3}ê°œì›”ì”© ì´ë™")
    
    # Walk-Forward Validation ì‹¤í–‰
    results = model.run_walk_forward_validation(df, verbose=True)
    
    if results:
        # ê²°ê³¼ ì €ì¥
        model.save_results()
        
        print("\n" + "="*80)
        print("ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ AI í•µì‹¬ íŠ¹ì§• ìš”ì•½:")
        print()
        print("ğŸ“Š Aìœ í˜• (ê±°ë˜ í’ˆì§ˆ ë¶„ì„ê¸°):")
        print("   â€¢ ëª©ì : 'ì´ ê±°ë˜ê°€ ì–¼ë§ˆë‚˜ ì¢‹ì•˜ë‚˜?' ê°ê´€ì  í‰ê°€")
        print("   â€¢ í™œìš©: ê±°ë˜ ë³µê¸°, ì„±ê³¼ ë¶„ì„, íŠ¸ë ˆì´ë” í‰ê°€")
        print("   â€¢ ë°ì´í„°: ëª¨ë“  ê±°ë˜ ì •ë³´ í™œìš© (ì§„ì…+ì§„í–‰+ì¢…ë£Œ)")
        print("   â€¢ ì •í™•ë„: ë†’ìŒ (ì™„ì „í•œ ì •ë³´ í™œìš©)")
        print()
        print("ğŸ”® Bìœ í˜• (ì§„ì… ì¡°ê±´ í‰ê°€ê¸°):")
        print("   â€¢ ëª©ì : 'ì§€ê¸ˆ ë§¤ìˆ˜í•˜ê¸° ì¢‹ì€ ì¡°ê±´ì¸ê°€?' ì‹¤ì‹œê°„ íŒë‹¨")
        print("   â€¢ í™œìš©: ë§¤ìˆ˜ íƒ€ì´ë°, ì¢…ëª© ì„ ë³„, ë¦¬ìŠ¤í¬ ê´€ë¦¬")
        print("   â€¢ ë°ì´í„°: í˜„ì¬ ì‹œì  ì •ë³´ë§Œ (ë¯¸ë˜ ì •ë³´ ì™„ì „ ì°¨ë‹¨)")
        print("   â€¢ í˜„ì‹¤ì„±: ë†’ìŒ (ì‹¤ì œ íŠ¸ë ˆì´ë”© í™˜ê²½ê³¼ ë™ì¼)")
        print()
        print("ğŸ’¡ í•µì‹¬ ì°¨ì´ì :")
        print("   â€¢ Aìœ í˜•: ê³¼ê±° ë¶„ì„ â†’ ì •í™•í•œ í’ˆì§ˆ ì¸¡ì •")
        print("   â€¢ Bìœ í˜•: í˜„ì¬ ë¶„ì„ â†’ í˜„ì‹¤ì  í™œìš© ê°€ëŠ¥")
        print("   â†’ ìƒí˜¸ ë³´ì™„ì ì¸ ë“€ì–¼ ì‹œìŠ¤í…œ!")
    else:
        print("âŒ í•˜ì´ë¸Œë¦¬ë“œ AI ì‹¤í–‰ ì‹¤íŒ¨")
    
    print("\n" + "="*80)
    print("ğŸ í•˜ì´ë¸Œë¦¬ë“œ íŠ¸ë ˆì´ë”© AI v4 ì‹¤í–‰ ì™„ë£Œ!")
    print("   ğŸ“ ê²°ê³¼ íŒŒì¼: hybrid_results.json, hybrid_results_metadata.json")
    print("   ğŸ“Š Aìœ í˜• ëª¨ë¸: ê±°ë˜ í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ")
    print("   ğŸ”® Bìœ í˜• ëª¨ë¸: ì§„ì… ì¡°ê±´ í‰ê°€ ì™„ë£Œ")
    print("   ğŸš€ ì‹¤ìš©ì ì¸ íŠ¸ë ˆì´ë”© ì§€ì› ì‹œìŠ¤í…œ ì¤€ë¹„ë¨!")
    print("="*80)

if __name__ == "__main__":
    main()