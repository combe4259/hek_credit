import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV
from tqdm import tqdm
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import xgboost as xgb
import joblib
import json
from datetime import datetime
import warnings
import torch
warnings.filterwarnings('ignore')

class WalkForwardQualityModel:
    """
    Walk-Forward Validation Quality Score ëª¨ë¸
    
    ê°œì„ ì‚¬í•­:
    1. ê°„ì†Œí™”ëœ Quality Score (Risk Management + Efficiency)
    2. Data Leakage ìµœì†Œí™” (3ê°œ í”¼ì²˜ë§Œ Quality Scoreì— ì‚¬ìš©)
    3. Walk-Forward Validationìœ¼ë¡œ ì‹œê³„ì—´ ê²¬ê³ ì„± í™•ë³´
    4. ì‹œì¥ ë ˆì§ë³„ ì„±ëŠ¥ ë¶„ì„
    """
    
    def __init__(self, train_months=36, val_months=6, test_months=6, step_months=3):
        self.train_months = train_months
        self.val_months = val_months
        self.test_months = test_months
        self.step_months = step_months
        
        self.models = {}
        self.scalers = {}
        self.feature_columns = None
        self.fold_results = []
        
    def create_quality_score(self, df, risk_scaler=None, eff_scaler=None, verbose=False):
        """ê°„ì†Œí™”ëœ Quality Score ìƒì„± (Data Leakage ë°©ì§€)"""
        if verbose:
            print("ğŸ¯ Quality Score ìƒì„± ì¤‘...")
        
        df = df.copy()
        
        # --------------------------------
        # 1. NaN ì²˜ë¦¬ (ì¤‘ë¦½ì  ê°’ 0ìœ¼ë¡œ ì²˜ë¦¬)
        # --------------------------------
        # í•„ìˆ˜ ì»¬ëŸ¼ë“¤ì˜ NaNì„ 0ìœ¼ë¡œ ì²˜ë¦¬ (ì •ë³´ ì—†ìŒì„ ì˜ë¯¸)
        df['return_pct'] = df['return_pct'].fillna(0)  # ìˆ˜ìµë¥  ì—†ìœ¼ë©´ 0
        df['entry_volatility_20d'] = df['entry_volatility_20d'].fillna(0)  # ë³€ë™ì„± ì •ë³´ ì—†ìœ¼ë©´ 0
        df['entry_ratio_52w_high'] = df['entry_ratio_52w_high'].fillna(0)  # 52ì£¼ ê³ ì  ë¹„ìœ¨ ì •ë³´ ì—†ìœ¼ë©´ 0
        df['holding_period_days'] = df['holding_period_days'].fillna(0)  # ë³´ìœ ê¸°ê°„ ì •ë³´ ì—†ìœ¼ë©´ 0
        
        # --------------------------------
        # 2. Risk Management Quality (40%)
        # --------------------------------
        # ë¦¬ìŠ¤í¬ ì¡°ì • ìˆ˜ìµë¥  (NaN ì•ˆì „ ì²˜ë¦¬)
        volatility_safe = np.maximum(df['entry_volatility_20d'], 0.01)
        df['risk_adj_return'] = df['return_pct'] / volatility_safe
        
        # ë¬´í•œê°’ ì²˜ë¦¬
        df['risk_adj_return'] = np.where(
            np.isinf(df['risk_adj_return']) | np.isnan(df['risk_adj_return']), 
            0, 
            df['risk_adj_return']
        )
        
        # ê°€ê²© ì•ˆì „ë„ (NaN ì•ˆì „ ì²˜ë¦¬)
        ratio_safe = np.clip(df['entry_ratio_52w_high'], 0, 100)
        df['price_safety'] = (100 - ratio_safe) / 100
        
        # ì¢…í•© ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì ìˆ˜
        df['risk_management_score'] = df['risk_adj_return'] * 0.6 + df['price_safety'] * 0.4
        
        # --------------------------------
        # 3. Efficiency Quality (60%)
        # --------------------------------
        # ì‹œê°„ íš¨ìœ¨ì„± (NaN ì•ˆì „ ì²˜ë¦¬)
        holding_safe = np.maximum(df['holding_period_days'], 1)
        df['time_efficiency'] = df['return_pct'] / holding_safe
        
        # ë¬´í•œê°’ ì²˜ë¦¬
        df['time_efficiency'] = np.where(
            np.isinf(df['time_efficiency']) | np.isnan(df['time_efficiency']), 
            0, 
            df['time_efficiency']
        )
        
        # íš¨ìœ¨ì„± ì ìˆ˜
        df['efficiency_score'] = df['time_efficiency']
        
        # --------------------------------
        # 4. ì¢…í•© Quality Score (Data Leakage ë°©ì§€)
        # --------------------------------
        if risk_scaler is None or eff_scaler is None:
            # í•™ìŠµìš©: ìƒˆë¡œìš´ ìŠ¤ì¼€ì¼ëŸ¬ ìƒì„±
            risk_scaler = RobustScaler()
            eff_scaler = RobustScaler()
            
            risk_scaled = risk_scaler.fit_transform(df[['risk_management_score']])
            eff_scaled = eff_scaler.fit_transform(df[['efficiency_score']])
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
            self.scalers['risk_scaler'] = risk_scaler
            self.scalers['efficiency_scaler'] = eff_scaler
        else:
            # ê²€ì¦/í…ŒìŠ¤íŠ¸ìš©: ê¸°ì¡´ ìŠ¤ì¼€ì¼ëŸ¬ ì‚¬ìš©
            risk_scaled = risk_scaler.transform(df[['risk_management_score']])
            eff_scaled = eff_scaler.transform(df[['efficiency_score']])
        
        df['quality_score'] = risk_scaled.flatten() * 0.4 + eff_scaled.flatten() * 0.6
        
        if verbose:
            print(f"  âœ… Quality Score ìƒì„± ì™„ë£Œ")
            print(f"  ë²”ìœ„: {df['quality_score'].min():.4f} ~ {df['quality_score'].max():.4f}")
            print(f"  í‰ê· : {df['quality_score'].mean():.4f}")
            print(f"  NaN ê°œìˆ˜: {df['quality_score'].isna().sum()}")
            
        return df
    
    def prepare_features(self, df, verbose=False):
        """ML ëª¨ë¸ìš© í”¼ì²˜ ì¤€ë¹„ (Quality Score ê³„ì‚°ì— ì‚¬ìš©ëœ í”¼ì²˜ ì œì™¸)"""
        if verbose:
            print("ğŸ”§ í”¼ì²˜ ì¤€ë¹„ ì¤‘...")
        
        # Quality Score ê³„ì‚°ì— ì‚¬ìš©ëœ í”¼ì²˜ë“¤ (ì œì™¸í•´ì•¼ í•¨)
        excluded_features = {
            'return_pct',  # íƒ€ê²Ÿê³¼ ì§ê²°
            'entry_volatility_20d',  # Risk Managementì— ì‚¬ìš©
            'entry_ratio_52w_high',  # Risk Managementì— ì‚¬ìš©
            'holding_period_days',  # Efficiencyì— ì‚¬ìš©
            
            # Quality Score ê³„ì‚° ê³¼ì •ì—ì„œ ìƒì„±ëœ ì»¬ëŸ¼ë“¤ë„ ì œì™¸
            'risk_adj_return', 'price_safety', 'risk_management_score',
            'time_efficiency', 'efficiency_score', 'quality_score'
        }
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ë“¤ ì„ ì •
        available_features = []
        
        # 1. ê¸°ë³¸ ì •ë³´ (ì¼ë¶€)
        basic_features = ['position_size_pct']  # return_pct, holding_period_days ì œì™¸
        available_features.extend([col for col in basic_features if col in df.columns])
        
        # 2. ëª¨ë©˜í…€ ì§€í‘œë“¤ (entry_momentum_20d ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€)
        momentum_features = ['entry_momentum_5d', 'entry_momentum_60d', 
                           'exit_momentum_5d', 'exit_momentum_20d', 'exit_momentum_60d',
                           'change_momentum_5d', 'change_momentum_20d', 'change_momentum_60d']
        available_features.extend([col for col in momentum_features if col in df.columns])
        
        # 3. ì´ë™í‰ê·  ê´´ë¦¬ë„
        ma_dev_features = ['entry_ma_dev_5d', 'entry_ma_dev_20d', 'entry_ma_dev_60d',
                          'exit_ma_dev_5d', 'exit_ma_dev_20d', 'exit_ma_dev_60d',
                          'change_ma_dev_5d', 'change_ma_dev_20d', 'change_ma_dev_60d']
        available_features.extend([col for col in ma_dev_features if col in df.columns])
        
        # 4. ë³€ë™ì„± ì§€í‘œë“¤ (entry_volatility_20d ì œì™¸)
        vol_features = ['entry_volatility_5d', 'entry_volatility_60d',
                       'exit_volatility_5d', 'exit_volatility_20d', 'exit_volatility_60d',
                       'change_volatility_5d', 'change_volatility_60d',  # change_volatility_20dëŠ” í¬í•¨
                       'entry_vol_change_5d', 'entry_vol_change_20d', 'entry_vol_change_60d']
        available_features.extend([col for col in vol_features if col in df.columns])
        
        # 5. ì‹œì¥ í™˜ê²½ (ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥)
        market_features = ['entry_vix', 'exit_vix', 'change_vix',
                          'entry_tnx_yield', 'exit_tnx_yield', 'change_tnx_yield',
                          'market_return_during_holding', 'excess_return']
        available_features.extend([col for col in market_features if col in df.columns])
        
        # 6. í€ë”ë©˜í„¸ (ëˆ„ë½ì´ ë§ì•„ì„œ ì¼ë‹¨ ì œì™¸)
        # fundamental_features = ['entry_pe_ratio', 'entry_pb_ratio', 'entry_roe', ...]
        # available_features.extend([col for col in fundamental_features if col in df.columns])
        
        # 7. ê¸°íƒ€ ë¹„ìœ¨ ì§€í‘œë“¤ (entry_ratio_52w_high ì œì™¸)
        ratio_features = ['exit_ratio_52w_high', 'change_ratio_52w_high']
        available_features.extend([col for col in ratio_features if col in df.columns])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í”¼ì²˜ë§Œ ì„ íƒ
        self.feature_columns = [col for col in available_features 
                               if col in df.columns and col not in excluded_features]
        
        if verbose:
            print(f"  ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜: {len(self.feature_columns)}ê°œ")
            print(f"  ì œì™¸ëœ í”¼ì²˜: {len(excluded_features)}ê°œ")
            
        return df[self.feature_columns]
    
    def create_walk_forward_folds(self, df, verbose=False):
        """Walk-Forward ë¶„í•  ìƒì„±"""
        if verbose:
            print("ğŸ“… Walk-Forward ë¶„í•  ìƒì„± ì¤‘...")
        
        df = df.copy()
        df['entry_date'] = pd.to_datetime(df['entry_datetime'])
        df = df.sort_values('entry_date')
        
        # ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼
        start_date = df['entry_date'].min()
        end_date = df['entry_date'].max()
        
        folds = []
        
        # ì²« ë²ˆì§¸ í´ë“œì˜ ì‹œì‘ì  ê³„ì‚°
        current_date = start_date + pd.DateOffset(months=self.train_months)
        
        while current_date + pd.DateOffset(months=self.val_months + self.test_months) <= end_date:
            # ê° êµ¬ê°„ ê³„ì‚°
            train_start = current_date - pd.DateOffset(months=self.train_months)
            train_end = current_date
            val_start = train_end
            val_end = val_start + pd.DateOffset(months=self.val_months)
            test_start = val_end
            test_end = test_start + pd.DateOffset(months=self.test_months)
            
            # ì¸ë±ìŠ¤ ìƒì„±
            train_mask = (df['entry_date'] >= train_start) & (df['entry_date'] < train_end)
            val_mask = (df['entry_date'] >= val_start) & (df['entry_date'] < val_end)
            test_mask = (df['entry_date'] >= test_start) & (df['entry_date'] < test_end)
            
            if train_mask.sum() > 1000 and val_mask.sum() > 100 and test_mask.sum() > 100:
                folds.append({
                    'fold_id': len(folds) + 1,
                    'train_start': train_start.date(),
                    'train_end': train_end.date(),
                    'val_start': val_start.date(),
                    'val_end': val_end.date(),
                    'test_start': test_start.date(),
                    'test_end': test_end.date(),
                    'train_idx': df[train_mask].index,
                    'val_idx': df[val_mask].index,
                    'test_idx': df[test_mask].index
                })
            
            # ë‹¤ìŒ í´ë“œë¡œ ì´ë™
            current_date += pd.DateOffset(months=self.step_months)
        
        if verbose:
            print(f"  ìƒì„±ëœ í´ë“œ ìˆ˜: {len(folds)}ê°œ")
            print("  í´ë“œ ì •ë³´:")
            for i, fold in enumerate(folds):
                print(f"    Fold {i+1}: Train {fold['train_start']} ~ {fold['train_end']}")
                print(f"             Val   {fold['val_start']} ~ {fold['val_end']}")
                print(f"             Test  {fold['test_start']} ~ {fold['test_end']}")
                print(f"             Size: {len(fold['train_idx'])}/{len(fold['val_idx'])}/{len(fold['test_idx'])}")
        
        return folds
    
    def evaluate_single_fold(self, df, fold, verbose=False):
        """ë‹¨ì¼ í´ë“œ í‰ê°€"""
        if verbose:
            print(f"\nğŸ”„ Fold {fold['fold_id']} í‰ê°€ ì¤‘...")
        
        # ë°ì´í„° ë¶„í• 
        train_data = df.loc[fold['train_idx']].copy()
        val_data = df.loc[fold['val_idx']].copy()
        test_data = df.loc[fold['test_idx']].copy()
        
        # Quality Score ìƒì„± (Trainì—ì„œë§Œ ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ)
        train_data = self.create_quality_score(train_data, verbose=False)
        val_data = self.create_quality_score(
            val_data, 
            risk_scaler=self.scalers['risk_scaler'],
            eff_scaler=self.scalers['efficiency_scaler'],
            verbose=False
        )
        test_data = self.create_quality_score(
            test_data,
            risk_scaler=self.scalers['risk_scaler'], 
            eff_scaler=self.scalers['efficiency_scaler'],
            verbose=False
        )
        
        # í”¼ì²˜ ì¤€ë¹„
        X_train = self.prepare_features(train_data, verbose=False)
        X_val = self.prepare_features(val_data, verbose=False)
        X_test = self.prepare_features(test_data, verbose=False)
        
        y_train = train_data['quality_score']
        y_val = val_data['quality_score'] 
        y_test = test_data['quality_score']
        
        # ê²°ì¸¡ì¹˜ ì œê±°
        train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())
        val_mask = ~(X_val.isnull().any(axis=1) | y_val.isnull())
        test_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())
        
        X_train = X_train[train_mask]
        X_val = X_val[val_mask]
        X_test = X_test[test_mask]
        y_train = y_train[train_mask]
        y_val = y_val[val_mask]
        y_test = y_test[test_mask]
        
        # í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
        feature_scaler = RobustScaler()
        X_train_scaled = feature_scaler.fit_transform(X_train)
        X_val_scaled = feature_scaler.transform(X_val)
        X_test_scaled = feature_scaler.transform(X_test)
        
        # GPU ì„¤ì • í™•ì¸
        gpu_available = torch.cuda.is_available()
        num_gpus = torch.cuda.device_count() if gpu_available else 0
        
        if verbose:
            print(f"  GPU ì‚¬ìš© ê°€ëŠ¥: {gpu_available}")
            print(f"  GPU ê°œìˆ˜: {num_gpus}")
        
        # XGBoost ë² ì´ìŠ¤ ëª¨ë¸ ì„¤ì •
        base_model = xgb.XGBRegressor(
            tree_method='gpu_hist' if gpu_available else 'hist',
            gpu_id=0 if gpu_available else None,
            random_state=42,
            eval_metric='rmse'
        )
        
        # GridSearchCVë¥¼ ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
        param_grid = {
            'n_estimators': [100, 200, 300],
            'learning_rate': [0.01, 0.05, 0.1],
            'max_depth': [6, 8, 10],
            'subsample': [0.8, 0.9],
            'colsample_bytree': [0.8, 0.9]
        }
        
        # GridSearchCV ì„¤ì •
        grid_search = GridSearchCV(
            estimator=base_model,
            param_grid=param_grid,
            cv=3,  # 3-fold CV
            scoring='r2',
            n_jobs=min(num_gpus, 4) if num_gpus > 0 else -1,  # GPU ê°œìˆ˜ì— ë”°ë¼ ì¡°ì •
            verbose=1 if verbose else 0
        )
        
        if verbose:
            print(f"  GridSearchCV ì‹œì‘: {len(param_grid['n_estimators']) * len(param_grid['learning_rate']) * len(param_grid['max_depth']) * len(param_grid['subsample']) * len(param_grid['colsample_bytree'])} ì¡°í•© í…ŒìŠ¤íŠ¸")
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
        grid_search.fit(X_train_scaled, y_train)
        
        # ìµœì  ëª¨ë¸ë¡œ í‰ê°€
        best_model = grid_search.best_estimator_
        
        # ê²€ì¦ ì„¸íŠ¸ í‰ê°€
        y_val_pred = best_model.predict(X_val_scaled)
        val_r2 = r2_score(y_val, y_val_pred)
        val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))
        
        # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€
        y_test_pred = best_model.predict(X_test_scaled)
        test_r2 = r2_score(y_test, y_test_pred)
        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
        
        fold_results = {
            'xgboost': {
                'val_r2': val_r2,
                'val_rmse': val_rmse,
                'test_r2': test_r2,
                'test_rmse': test_rmse,
                'train_size': len(X_train),
                'val_size': len(X_val),
                'test_size': len(X_test),
                'best_params': grid_search.best_params_,
                'best_cv_score': grid_search.best_score_
            }
        }
        
        # ì‹œì¥ í™˜ê²½ ë¶„ì„
        market_stats = {
            'train_vix_mean': train_data['entry_vix'].mean() if 'entry_vix' in train_data.columns else np.nan,
            'val_vix_mean': val_data['entry_vix'].mean() if 'entry_vix' in val_data.columns else np.nan,
            'test_vix_mean': test_data['entry_vix'].mean() if 'entry_vix' in test_data.columns else np.nan,
            'train_return_mean': train_data['return_pct'].mean(),
            'val_return_mean': val_data['return_pct'].mean(),
            'test_return_mean': test_data['return_pct'].mean()
        }
        
        return {
            'fold_id': fold['fold_id'],
            'fold_info': fold,
            'model_results': fold_results,
            'market_stats': market_stats
        }
    
    def run_walk_forward_validation(self, df, verbose=False):
        """ì „ì²´ Walk-Forward Validation ì‹¤í–‰"""
        print("ğŸš€ Walk-Forward Validation ì‹œì‘")
        print("="*70)
        
        # í´ë“œ ìƒì„±
        folds = self.create_walk_forward_folds(df, verbose=True)
        
        if len(folds) == 0:
            print("âŒ ìƒì„±ëœ í´ë“œê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.")
            return None
        
        # ê° í´ë“œ í‰ê°€
        all_results = []
        
        print(f"\nğŸ“Š {len(folds)}ê°œ í´ë“œ í‰ê°€ ì¤‘...")
        
        for fold in tqdm(folds, desc="Evaluating folds"):
            try:
                result = self.evaluate_single_fold(df, fold, verbose=False)
                all_results.append(result)
            except Exception as e:
                print(f"âš ï¸ Fold {fold['fold_id']} í‰ê°€ ì‹¤íŒ¨: {e}")
                continue
        
        self.fold_results = all_results
        
        # ê²°ê³¼ ì§‘ê³„
        self.aggregate_results(verbose=True)
        
        return all_results
    
    def get_best_models_from_folds(self, verbose=False):
        """í´ë“œë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ"""
        if not self.fold_results:
            return None
            
        # XGBoost ì„±ëŠ¥ ì§‘ê³„
        test_r2_scores = [r['model_results']['xgboost']['test_r2'] for r in self.fold_results]
        cv_scores = [r['model_results']['xgboost']['best_cv_score'] for r in self.fold_results]
        
        avg_test_r2 = np.mean(test_r2_scores)
        avg_cv_score = np.mean(cv_scores)
        
        if verbose:
            print(f"\nğŸ† XGBoost Walk-Forward ì„±ëŠ¥ ìš”ì•½:")
            print(f"  í‰ê·  Test RÂ²: {avg_test_r2:.4f} Â± {np.std(test_r2_scores):.4f}")
            print(f"  í‰ê·  CV Score: {avg_cv_score:.4f} Â± {np.std(cv_scores):.4f}")
            print(f"  Test RÂ² ë²”ìœ„: [{np.min(test_r2_scores):.4f}, {np.max(test_r2_scores):.4f}]")
            
            # ê° í´ë“œì˜ ìµœì  íŒŒë¼ë¯¸í„° í‘œì‹œ
            print(f"\ní´ë“œë³„ ìµœì  íŒŒë¼ë¯¸í„°:")
            for i, result in enumerate(self.fold_results):
                best_params = result['model_results']['xgboost']['best_params']
                test_r2 = result['model_results']['xgboost']['test_r2']
                print(f"  Fold {i+1} (RÂ²={test_r2:.4f}): {best_params}")
        
        return 'xgboost', {'xgboost': avg_test_r2}
    
    def aggregate_results(self, verbose=False):
        """í´ë“œ ê²°ê³¼ ì§‘ê³„ ë° í†µê³„"""
        if not self.fold_results:
            print("âŒ ì§‘ê³„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if verbose:
            print("\nğŸ“ˆ Walk-Forward Validation ê²°ê³¼ ì§‘ê³„")
            print("="*50)
        
        # XGBoost ì„±ëŠ¥ ì§‘ê³„ ë””í…Œì¼
        val_r2_scores = [r['model_results']['xgboost']['val_r2'] for r in self.fold_results]
        test_r2_scores = [r['model_results']['xgboost']['test_r2'] for r in self.fold_results]
        cv_scores = [r['model_results']['xgboost']['best_cv_score'] for r in self.fold_results]
        
        if verbose:
            print(f"\nXGBOOST ì„±ëŠ¥ ìƒì„¸:")
            print(f"  Validation RÂ²: {np.mean(val_r2_scores):.4f} Â± {np.std(val_r2_scores):.4f}")
            print(f"  Test RÂ²:       {np.mean(test_r2_scores):.4f} Â± {np.std(test_r2_scores):.4f}")
            print(f"  CV Score:       {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}")
            print(f"  Test RÂ² ë²”ìœ„:  [{np.min(test_r2_scores):.4f}, {np.max(test_r2_scores):.4f}]")
            print(f"  ì¼ê´€ì„± (CV):   {np.std(test_r2_scores)/np.mean(test_r2_scores)*100:.1f}%")
        
        # ì‹œì¥ í™˜ê²½ë³„ ì„±ëŠ¥
        if verbose:
            print(f"\nğŸŒŠ ì‹œì¥ í™˜ê²½ë³„ ì„±ëŠ¥ ë¶„ì„:")
            
            for i, result in enumerate(self.fold_results):
                market = result['market_stats']
                test_r2 = result['model_results']['xgboost']['test_r2']  # XGBoost ê¸°ì¤€
                
                vix_level = "ê³ ë³€ë™" if market['test_vix_mean'] > 25 else "ì €ë³€ë™"
                return_level = "ìƒìŠ¹" if market['test_return_mean'] > 0.05 else "í•˜ë½"
                
                print(f"  Fold {i+1}: {vix_level}/{return_level} â†’ Test RÂ² = {test_r2:.4f}")
    
    def feature_importance_analysis(self, verbose=False):
        """ë§ˆì§€ë§‰ í´ë“œ XGBoost ëª¨ë¸ë¡œ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„"""
        if verbose:
            print("\nğŸ” í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„")
        
        if not self.fold_results:
            print("  ë¶„ì„í•  í´ë“œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        # ë§ˆì§€ë§‰ í´ë“œì—ì„œ XGBoost ëª¨ë¸ ë‹¤ì‹œ í•™ìŠµ (í”¼ì²˜ ì¤‘ìš”ë„ ì¶”ì¶œìš©)
        last_result = self.fold_results[-1]
        fold = last_result['fold_info']
        
        # ë°ì´í„° ì¤€ë¹„
        df = pd.read_csv('../results/final/trading_episodes_with_rebuilt_market_component.csv')
        train_data = df.loc[fold['train_idx']].copy()
        train_data = self.create_quality_score(train_data, verbose=False)
        
        X_train = self.prepare_features(train_data, verbose=False)
        y_train = train_data['quality_score']
        
        # ê²°ì¸¡ì¹˜ ì œê±°
        mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())
        X_train = X_train[mask]
        y_train = y_train[mask]
        
        # ìŠ¤ì¼€ì¼ë§ ë° í•™ìŠµ
        feature_scaler = RobustScaler()
        X_train_scaled = feature_scaler.fit_transform(X_train)
        
        # GPU ì„¤ì • í™•ì¸
        gpu_available = torch.cuda.is_available()
        
        # ë§ˆì§€ë§‰ í´ë“œì—ì„œ ì‚¬ìš©ëœ ìµœì  íŒŒë¼ë¯¸í„° ì‚¬ìš©
        last_best_params = self.fold_results[-1]['model_results']['xgboost']['best_params']
        
        xgb_model = xgb.XGBRegressor(
            tree_method='gpu_hist' if gpu_available else 'hist',
            gpu_id=0 if gpu_available else None,
            random_state=42,
            eval_metric='rmse',
            **last_best_params  # ìµœì  íŒŒë¼ë¯¸í„° ì ìš©
        )
        xgb_model.fit(X_train_scaled, y_train)
        
        # í”¼ì²˜ ì¤‘ìš”ë„ ì¶”ì¶œ
        feature_importance = xgb_model.feature_importances_
        
        # ì¤‘ìš”ë„ ì •ë ¬
        importance_df = pd.DataFrame({
            'feature': self.feature_columns,
            'importance': feature_importance
        }).sort_values('importance', ascending=False)
        
        if verbose:
            print("\nìƒìœ„ 20ê°œ í”¼ì²˜:")
            print(importance_df.head(20).to_string(index=False))
            print(f"\nì‚¬ìš©ëœ ìµœì  íŒŒë¼ë¯¸í„°: {last_best_params}")
        
        return importance_df
    
    def save_results(self, filepath_prefix='walk_forward_results'):
        """ê²°ê³¼ ì €ì¥"""
        if not self.fold_results:
            print("âŒ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥ (datetime ì²˜ë¦¬)
        results_for_save = []
        for result in self.fold_results:
            result_copy = result.copy()
            
            # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            fold_info = result_copy['fold_info'].copy()
            for key in ['train_start', 'train_end', 'val_start', 'val_end', 'test_start', 'test_end']:
                if key in fold_info:
                    fold_info[key] = str(fold_info[key])
            
            # ì¸ë±ìŠ¤ ì œê±° (ì €ì¥ ìš©ëŸ‰ ì ˆì•½)
            del fold_info['train_idx']
            del fold_info['val_idx'] 
            del fold_info['test_idx']
            
            result_copy['fold_info'] = fold_info
            results_for_save.append(result_copy)
        
        with open(f'{filepath_prefix}.json', 'w') as f:
            json.dump(results_for_save, f, indent=2)
        
        # ë©”íƒ€ë°ì´í„°ë„ ì €ì¥
        metadata = {
            'model_version': 'walk_forward_xgboost_v1',
            'model_type': 'XGBoost with GridSearchCV',
            'feature_columns': self.feature_columns,
            'walk_forward_params': {
                'train_months': self.train_months,
                'val_months': self.val_months,
                'test_months': self.test_months,
                'step_months': self.step_months
            },
            'gpu_settings': {
                'gpu_available': torch.cuda.is_available(),
                'num_gpus': torch.cuda.device_count() if torch.cuda.is_available() else 0
            },
            'training_timestamp': datetime.now().isoformat(),
            'quality_score_components': {
                'risk_management_weight': 0.4,
                'efficiency_weight': 0.6,
                'features_used_for_quality_score': [
                    'entry_volatility_20d',
                    'entry_ratio_52w_high', 
                    'holding_period_days'
                ]
            },
            'total_folds': len(self.fold_results)
        }
        
        with open(f'{filepath_prefix}_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath_prefix}.*")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Walk-Forward XGBoost Quality Score ëª¨ë¸ ê²€ì¦")
    print("="*70)
    
    # GPU í™•ì¸
    print(f"GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    print(f"GPU ê°œìˆ˜: {torch.cuda.device_count()}")
    
    # ë°ì´í„° ë¡œë“œ
    print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
    df = pd.read_csv('../results/final/trading_episodes_with_rebuilt_market_component.csv')
    print(f"  ì´ ë°ì´í„°: {len(df):,}ê°œ")
    
    # Walk-Forward XGBoost ëª¨ë¸ ì´ˆê¸°í™”
    # íŒŒë¼ë¯¸í„°: train 36ê°œì›”, val 6ê°œì›”, test 6ê°œì›”, step 3ê°œì›”
    model = WalkForwardQualityModel(
        train_months=36,
        val_months=6, 
        test_months=6,
        step_months=3
    )
    
    # Walk-Forward Validation ì‹¤í–‰
    results = model.run_walk_forward_validation(df, verbose=True)
    
    if results:
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
        best_model_info = model.get_best_models_from_folds(verbose=True)
        
        # í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ (ë§ˆì§€ë§‰ í´ë“œ ê¸°ì¤€)
        importance_df = model.feature_importance_analysis(verbose=True)
        
        # ê²°ê³¼ ì €ì¥
        model.save_results()
    else:
        print("âŒ Walk-Forward Validation ì‹¤í–‰ ì‹¤íŒ¨")
    
    print("\n" + "="*70)
    print("âœ… Walk-Forward Validation ì™„ë£Œ!")
    print("="*70)

if __name__ == "__main__":
    main()