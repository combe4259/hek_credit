import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import classification_report, confusion_matrix
import xgboost as xgb
import joblib
import warnings
warnings.filterwarnings('ignore')

def prepare_features(df):
    """
    ê°œë³„ ê±°ë˜ í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ìˆœìˆ˜ ê¸°ìˆ ì  ì§€í‘œë§Œ ì¶”ì¶œ
    - symbol, industry ì œì™¸ (ì¢…ëª© íŠ¹ì„± ë°°ì œ)
    - ê±°ë˜ ì‹œì ì˜ ê¸°ìˆ ì  ìƒíƒœë§Œìœ¼ë¡œ í’ˆì§ˆ í‰ê°€
    """
    
    # Baseline features - ìˆœìˆ˜í•˜ê²Œ ê±°ë˜ í’ˆì§ˆê³¼ ê´€ë ¨ëœ ì§€í‘œë§Œ
    baseline_features = [
        # ê±°ë˜ íŠ¹ì„±
        'holding_period_days',      # ë³´ìœ  ê¸°ê°„
        'position_size_pct',        # í¬ì§€ì…˜ í¬ê¸° (ë¦¬ìŠ¤í¬ ë…¸ì¶œë„)
        
        # ì§„ì… ì‹œì  ëª¨ë©˜í…€ (ë‹¨ê¸°/ì¤‘ê¸° ì¶”ì„¸)
        'entry_momentum_5d',        # ë‹¨ê¸° ëª¨ë©˜í…€
        'entry_momentum_20d',       # ì¤‘ê¸° ëª¨ë©˜í…€
        
        # ì§„ì… ì‹œì  ë³€ë™ì„± (ë¦¬ìŠ¤í¬ ìˆ˜ì¤€)
        'entry_volatility_5d',      # ë‹¨ê¸° ë³€ë™ì„±
        'entry_volatility_20d',     # ì¤‘ê¸° ë³€ë™ì„±
        
        # ì§„ì… ì‹œì  ì´ë™í‰ê·  ê´´ë¦¬ (ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ìƒíƒœ)
        'entry_ma_dev_5d',          # ë‹¨ê¸° MA ê´´ë¦¬
        'entry_ma_dev_20d',         # ì¤‘ê¸° MA ê´´ë¦¬
        
        # ì§„ì… ì‹œì  ê±°ë˜ëŸ‰ ë³€í™” (ì‹œì¥ ê´€ì‹¬ë„)
        'entry_vol_change_5d',      # ë‹¨ê¸° ê±°ë˜ëŸ‰ ë³€í™”
        'entry_vol_change_20d',     # ì¤‘ê¸° ê±°ë˜ëŸ‰ ë³€í™”
        
        # ì§„ì… ì‹œì  ìƒëŒ€ ìœ„ì¹˜ (íƒ€ì´ë°)
        'entry_ratio_52w_high',     # 52ì£¼ ê³ ì  ëŒ€ë¹„ ìœ„ì¹˜
    ]
    
    X = df[baseline_features].copy()
    y = df['label']
    
    # ë°ì´í„° ê²€ì¦
    print(f"âœ… ì„ íƒëœ íŠ¹ì„± ìˆ˜: {len(baseline_features)}ê°œ")
    print(f"âœ… ê²°ì¸¡ì¹˜: {X.isnull().sum().sum()}ê°œ")
    
    return X, y

def evaluate_trade_quality_model(model, X, y, dataset_name):
    """ê°œë³„ ê±°ë˜ í’ˆì§ˆ í‰ê°€ ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì •"""
    
    y_pred = model.predict(X)
    y_prob = model.predict_proba(X)[:, 1]
    
    # ê¸°ë³¸ ë©”íŠ¸ë¦­
    metrics = {
        'accuracy': accuracy_score(y, y_pred),
        'precision': precision_score(y, y_pred),
        'recall': recall_score(y, y_pred),
        'f1': f1_score(y, y_pred),
        'auc': roc_auc_score(y, y_prob)
    }
    
    print(f"\nğŸ“Š {dataset_name} ì„±ëŠ¥:")
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.4f}")
    
    # Confusion Matrix
    cm = confusion_matrix(y, y_pred)
    print(f"\ní˜¼ë™ í–‰ë ¬:")
    print(f"  TN: {cm[0,0]:,}  FP: {cm[0,1]:,}")
    print(f"  FN: {cm[1,0]:,}  TP: {cm[1,1]:,}")
    
    # ê±°ë˜ í’ˆì§ˆë³„ ë¶„ì„
    print(f"\nğŸ’° ê±°ë˜ í’ˆì§ˆ ë¶„ì„:")
    true_positive_rate = cm[1,1] / (cm[1,0] + cm[1,1])
    false_positive_rate = cm[0,1] / (cm[0,0] + cm[0,1])
    print(f"  ìš°ìˆ˜ ê±°ë˜ ì •í™•íˆ ì‹ë³„: {true_positive_rate:.1%}")
    print(f"  ë¶ˆëŸ‰ ê±°ë˜ë¥¼ ìš°ìˆ˜ë¡œ ì˜ëª» ë¶„ë¥˜: {false_positive_rate:.1%}")
    
    return metrics, y_prob

def train_trade_quality_baseline():
    """ê°œë³„ ê±°ë˜ í’ˆì§ˆ í‰ê°€ Baseline ëª¨ë¸ í•™ìŠµ"""
    
    print("ğŸ¯ ê°œë³„ ê±°ë˜ í’ˆì§ˆ í‰ê°€ ëª¨ë¸ í•™ìŠµ")
    print("=" * 50)
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")
    train_df = pd.read_csv('../data/baseline_train.csv')
    val_df = pd.read_csv('../data/baseline_val.csv')
    test_df = pd.read_csv('../data/baseline_test.csv')
    
    print(f"í•™ìŠµìš©: {len(train_df):,}ê°œ ê±°ë˜")
    print(f"ê²€ì¦ìš©: {len(val_df):,}ê°œ ê±°ë˜")
    print(f"í…ŒìŠ¤íŠ¸ìš©: {len(test_df):,}ê°œ ê±°ë˜")
    
    # 2. Feature ì¤€ë¹„ (symbol, industry ì œì™¸)
    print("\nğŸ”§ íŠ¹ì„± ì¤€ë¹„ ì¤‘ (ê¸°ìˆ ì  ì§€í‘œë§Œ ì‚¬ìš©)...")
    X_train, y_train = prepare_features(train_df)
    X_val, y_val = prepare_features(val_df)
    X_test, y_test = prepare_features(test_df)
    
    # 3. ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)
    
    # 4. ëª¨ë¸ ì •ì˜
    models = {
        'Logistic Regression': LogisticRegression(
            random_state=42, 
            max_iter=1000,
            class_weight='balanced'  # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
        ),
        'Random Forest': RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            n_jobs=-1,
            class_weight='balanced'
        ),
        'XGBoost': xgb.XGBClassifier(
            n_estimators=100,
            random_state=42,
            scale_pos_weight=sum(y_train==0)/sum(y_train==1)  # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
        )
    }
    
    results = {}
    best_val_f1 = 0
    best_model = None
    best_model_name = None
    
    for name, model in models.items():
        print(f"\n{'='*50}")
        print(f"ğŸ¤– {name} í•™ìŠµ ì¤‘...")
        
        # í•™ìŠµ
        if name == 'Logistic Regression':
            model.fit(X_train_scaled, y_train)
            val_metrics, val_prob = evaluate_trade_quality_model(model, X_val_scaled, y_val, "ê²€ì¦ ë°ì´í„°")
            test_metrics, test_prob = evaluate_trade_quality_model(model, X_test_scaled, y_test, "í…ŒìŠ¤íŠ¸ ë°ì´í„°")
        else:
            model.fit(X_train, y_train)
            val_metrics, val_prob = evaluate_trade_quality_model(model, X_val, y_val, "ê²€ì¦ ë°ì´í„°")
            test_metrics, test_prob = evaluate_trade_quality_model(model, X_test, y_test, "í…ŒìŠ¤íŠ¸ ë°ì´í„°")
        
        results[name] = {
            'val_metrics': val_metrics,
            'test_metrics': test_metrics,
            'model': model
        }
        
        # ìµœê³  ëª¨ë¸ ì¶”ì 
        if val_metrics['f1'] > best_val_f1:
            best_val_f1 = val_metrics['f1']
            best_model = model
            best_model_name = name
        
        # Feature Importance (tree ê¸°ë°˜ ëª¨ë¸ë§Œ)
        if hasattr(model, 'feature_importances_'):
            print(f"\nğŸ“Š ì¤‘ìš” íŠ¹ì„± ìˆœìœ„:")
            feature_importance = pd.DataFrame({
                'feature': X_train.columns,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            for idx, row in feature_importance.head(5).iterrows():
                print(f"  {row['feature']}: {row['importance']:.4f}")
    
    # 5. ìµœì¢… ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*50}")
    print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
    print(f"   ê²€ì¦ F1 ì ìˆ˜: {best_val_f1:.4f}")
    print(f"   í…ŒìŠ¤íŠ¸ F1 ì ìˆ˜: {results[best_model_name]['test_metrics']['f1']:.4f}")
    
    # 6. ê±°ë˜ í’ˆì§ˆ ì ìˆ˜ ë¶„í¬ ë¶„ì„
    print(f"\nğŸ“ˆ ê±°ë˜ í’ˆì§ˆ ì ìˆ˜ ë¶„í¬:")
    test_df['quality_score'] = best_model.predict_proba(
        X_test_scaled if best_model_name == 'Logistic Regression' else X_test
    )[:, 1]
    
    # ì ìˆ˜ êµ¬ê°„ë³„ ì‹¤ì œ ìˆ˜ìµë¥ 
    test_df['score_bin'] = pd.qcut(test_df['quality_score'], q=5, labels=['ìµœí•˜', 'í•˜', 'ì¤‘', 'ìƒ', 'ìµœìƒ'])
    
    score_analysis = test_df.groupby('score_bin').agg({
        'return_pct': ['mean', 'std', 'count'],
        'label': 'mean'
    })
    
    print("\ní’ˆì§ˆ ì ìˆ˜ë³„ ì‹¤ì œ ìˆ˜ìµë¥ :")
    print(score_analysis)
    
    # 7. ëª¨ë¸ ì €ì¥
    import os
    os.makedirs('../models', exist_ok=True)
    
    joblib.dump(best_model, '../models/baseline_model.pkl')
    joblib.dump(scaler, '../models/baseline_scaler.pkl')
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'model_name': best_model_name,
        'features': list(X_train.columns),
        'val_f1': best_val_f1,
        'test_f1': results[best_model_name]['test_metrics']['f1'],
        'label_threshold': 0.005,  # return_pct > 0.5%
        'training_date': pd.Timestamp.now().strftime('%Y-%m-%d')
    }
    
    with open('../models/baseline_metadata.json', 'w') as f:
        import json
        json.dump(metadata, f, indent=2)
    
    print(f"\nâœ… ëª¨ë¸ì´ ../models/ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
    print(f"âœ… ì´ baselineì€ ê¸°ìˆ ì  ì§€í‘œë§Œìœ¼ë¡œ ê°œë³„ ê±°ë˜ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤")
    print(f"âœ… ì¢…ëª©/ì‚°ì—… í¸í–¥ ì—†ìŒ - ìˆœìˆ˜ ê¸°ìˆ ì  ë¶„ì„")
    
    return results, best_model

def analyze_trade_quality_patterns(model_path='../models/baseline_model.pkl'):
    """ê±°ë˜ í’ˆì§ˆ íŒ¨í„´ ì‹¬ì¸µ ë¶„ì„"""
    
    print("\nğŸ” ê±°ë˜ í’ˆì§ˆ íŒ¨í„´ ë¶„ì„ ì¤‘...")
    print("=" * 50)
    
    # ëª¨ë¸ê³¼ ë°ì´í„° ë¡œë“œ
    model = joblib.load(model_path)
    scaler = joblib.load('../models/baseline_scaler.pkl')
    test_df = pd.read_csv('../data/baseline_test.csv')
    
    X_test, y_test = prepare_features(test_df)
    
    # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    if hasattr(model, 'coef_'):  # Logistic Regression
        X_test_scaled = scaler.transform(X_test)
        quality_scores = model.predict_proba(X_test_scaled)[:, 1]
    else:
        quality_scores = model.predict_proba(X_test)[:, 1]
    
    test_df['quality_score'] = quality_scores
    
    # 1. ê³ í’ˆì§ˆ ê±°ë˜ íŠ¹ì„±
    print("\nğŸ“Š ê³ í’ˆì§ˆ ê±°ë˜ íŠ¹ì„± (ìƒìœ„ 20%):")
    high_quality = test_df[test_df['quality_score'] >= test_df['quality_score'].quantile(0.8)]
    low_quality = test_df[test_df['quality_score'] <= test_df['quality_score'].quantile(0.2)]
    
    features = prepare_features(test_df)[0].columns
    for feature in features[:5]:  # ìƒìœ„ 5ê°œ íŠ¹ì„±ë§Œ
        high_avg = high_quality[feature].mean()
        low_avg = low_quality[feature].mean()
        print(f"  {feature}: ìƒìœ„={high_avg:.2f}, í•˜ìœ„={low_avg:.2f}, ì°¨ì´={high_avg-low_avg:.2f}")
    
    # 2. ì‹¤ì œ ìˆ˜ìµë¥ ê³¼ì˜ ê´€ê³„
    print("\nğŸ’° í’ˆì§ˆ ì ìˆ˜ì™€ ì‹¤ì œ ìˆ˜ìµë¥  ê´€ê³„:")
    correlation = test_df['quality_score'].corr(test_df['return_pct'])
    print(f"  ìƒê´€ê³„ìˆ˜: {correlation:.4f}")
    
    # 3. ê±°ë˜ í’ˆì§ˆë³„ ì¶”ì²œ
    print("\nğŸ¯ ê±°ë˜ í’ˆì§ˆë³„ ë¶„ì„:")
    for score_range, label in [(0.8, 'ìµœìƒê¸‰'), (0.6, 'ìš°ìˆ˜'), (0.4, 'ë³´í†µ'), (0.2, 'ë¯¸í¡')]:
        mask = test_df['quality_score'] >= score_range
        if mask.sum() > 0:
            subset = test_df[mask]
            print(f"  {label} ê±°ë˜ (ì ìˆ˜ â‰¥ {score_range:.1f}):")
            print(f"    - ê±°ë˜ ìˆ˜: {len(subset):,}ê°œ")
            print(f"    - í‰ê·  ìˆ˜ìµë¥ : {subset['return_pct'].mean():.2%}")
            print(f"    - ìŠ¹ë¥ : {(subset['return_pct'] > 0.005).mean():.1%}")

if __name__ == "__main__":
    # 1. ê°œë³„ ê±°ë˜ í’ˆì§ˆ í‰ê°€ ëª¨ë¸ í•™ìŠµ
    results, model = train_trade_quality_baseline()
    
    # 2. ê±°ë˜ í’ˆì§ˆ íŒ¨í„´ ë¶„ì„
    analyze_trade_quality_patterns()