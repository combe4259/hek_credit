#!/usr/bin/env python3
"""
Feature Importance Top 5 Analyzer
XGBoost ëª¨ë¸ì˜ ìƒìœ„ 5ê°œ ì¤‘ìš” í”¼ì²˜ì™€ ì˜í–¥ë„ë¥¼ ë¶„ì„
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.facecolor'] = 'white'

# KB ì»¬ëŸ¬ íŒ”ë ˆíŠ¸
KB_COLORS = {
    'primary': '#FFB800',
    'secondary': '#1E3A8A', 
    'accent': '#059669',
    'danger': '#DC2626',
    'text': '#1F2937'
}

class FeatureImportanceAnalyzer:
    """XGBoost ëª¨ë¸ì˜ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.models = {}
        self.feature_importances = {}
        self.feature_impacts = {}
        
    def generate_synthetic_trading_data(self, n_samples=10000):
        """íŠ¸ë ˆì´ë”© ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ íŒ¨í„´ ê¸°ë°˜)"""
        np.random.seed(42)
        
        # ê¸°ë³¸ ì‹œì¥ ì§€í‘œë“¤
        market_trend = np.random.uniform(-0.05, 0.05, n_samples)
        volatility = np.random.exponential(0.02, n_samples)
        volume_ratio = np.random.lognormal(0, 0.5, n_samples)
        
        # ê¸°ìˆ ì  ì§€í‘œë“¤
        rsi = np.random.uniform(20, 80, n_samples)
        macd = np.random.normal(0, 0.01, n_samples)
        bollinger_position = np.random.uniform(-1, 1, n_samples)
        moving_avg_20 = np.random.uniform(-0.1, 0.1, n_samples)
        moving_avg_60 = np.random.uniform(-0.1, 0.1, n_samples)
        
        # í€ë”ë©˜í„¸ ì§€í‘œë“¤
        pe_ratio = np.random.lognormal(2.5, 0.5, n_samples)
        eps_growth = np.random.normal(0.1, 0.3, n_samples)
        debt_ratio = np.random.uniform(0.2, 0.8, n_samples)
        roe = np.random.uniform(0.05, 0.25, n_samples)
        
        # ê±°ì‹œê²½ì œ ì§€í‘œë“¤
        interest_rate = np.random.uniform(1.5, 4.5, n_samples)
        inflation_rate = np.random.uniform(1.0, 5.0, n_samples)
        gdp_growth = np.random.uniform(-2.0, 6.0, n_samples)
        
        # ì‹œì¥ ê°ì • ì§€í‘œë“¤
        fear_greed_index = np.random.uniform(20, 80, n_samples)
        news_sentiment = np.random.normal(0, 1, n_samples)
        analyst_recommendations = np.random.uniform(1, 5, n_samples)
        
        # ì„¹í„°/ì‚°ì—… ì§€í‘œë“¤
        sector_performance = np.random.normal(0, 0.03, n_samples)
        industry_beta = np.random.uniform(0.5, 1.5, n_samples)
        
        # ë¦¬ìŠ¤í¬ ì§€í‘œë“¤
        value_at_risk = np.random.uniform(0.01, 0.05, n_samples)
        sharpe_ratio = np.random.normal(1, 0.5, n_samples)
        
        # ìœ ë™ì„± ì§€í‘œë“¤
        bid_ask_spread = np.random.exponential(0.001, n_samples)
        turnover_rate = np.random.uniform(0.01, 0.2, n_samples)
        
        # ëª¨ë©˜í…€ ì§€í‘œë“¤
        price_momentum_5d = np.random.normal(0, 0.02, n_samples)
        price_momentum_20d = np.random.normal(0, 0.05, n_samples)
        earnings_momentum = np.random.normal(0, 0.1, n_samples)
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        features_df = pd.DataFrame({
            # ê¸°ë³¸ ì‹œì¥ ì§€í‘œ (ë†’ì€ ì¤‘ìš”ë„)
            'market_trend': market_trend,
            'volatility': volatility,
            'volume_ratio': volume_ratio,
            
            # ê¸°ìˆ ì  ì§€í‘œ (ì¤‘ê°„ ì¤‘ìš”ë„)
            'rsi': rsi,
            'macd': macd,
            'bollinger_position': bollinger_position,
            'moving_avg_20': moving_avg_20,
            'moving_avg_60': moving_avg_60,
            
            # í€ë”ë©˜í„¸ ì§€í‘œ (ë†’ì€ ì¤‘ìš”ë„)
            'pe_ratio': pe_ratio,
            'eps_growth': eps_growth,
            'debt_ratio': debt_ratio,
            'roe': roe,
            
            # ê±°ì‹œê²½ì œ ì§€í‘œ (ì¤‘ê°„ ì¤‘ìš”ë„)
            'interest_rate': interest_rate,
            'inflation_rate': inflation_rate,
            'gdp_growth': gdp_growth,
            
            # ì‹œì¥ ê°ì • ì§€í‘œ (ì¤‘ê°„ ì¤‘ìš”ë„)
            'fear_greed_index': fear_greed_index,
            'news_sentiment': news_sentiment,
            'analyst_recommendations': analyst_recommendations,
            
            # ì„¹í„°/ì‚°ì—… ì§€í‘œ (ë‚®ì€ ì¤‘ìš”ë„)
            'sector_performance': sector_performance,
            'industry_beta': industry_beta,
            
            # ë¦¬ìŠ¤í¬ ì§€í‘œ (ì¤‘ê°„ ì¤‘ìš”ë„)
            'value_at_risk': value_at_risk,
            'sharpe_ratio': sharpe_ratio,
            
            # ìœ ë™ì„± ì§€í‘œ (ë‚®ì€ ì¤‘ìš”ë„)
            'bid_ask_spread': bid_ask_spread,
            'turnover_rate': turnover_rate,
            
            # ëª¨ë©˜í…€ ì§€í‘œ (ë†’ì€ ì¤‘ìš”ë„)
            'price_momentum_5d': price_momentum_5d,
            'price_momentum_20d': price_momentum_20d,
            'earnings_momentum': earnings_momentum
        })
        
        return features_df
    
    def create_target_variables(self, features_df):
        """íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (3ê°œ ëª¨ë¸ìš©)"""
        n_samples = len(features_df)
        
        # Buy Signal: í€ë”ë©˜í„¸ + ëª¨ë©˜í…€ ì¤‘ì‹¬
        buy_signal = (
            features_df['eps_growth'] * 0.3 +
            features_df['roe'] * 0.25 +
            features_df['price_momentum_20d'] * 0.2 +
            features_df['market_trend'] * 0.15 +
            features_df['news_sentiment'] * 0.1 +
            np.random.normal(0, 0.1, n_samples)
        )
        
        # Sell Signal: ê¸°ìˆ ì  ì§€í‘œ + ë¦¬ìŠ¤í¬ ì¤‘ì‹¬
        sell_signal = (
            features_df['rsi'] * 0.01 +  # RSIê°€ ë†’ìœ¼ë©´ ë§¤ë„ ì‹ í˜¸
            features_df['volatility'] * 5 +
            features_df['value_at_risk'] * 10 +
            features_df['price_momentum_5d'] * 2 +
            features_df['bollinger_position'] * 0.3 +
            np.random.normal(0, 0.1, n_samples)
        )
        
        # Trade Quality: ì „ì²´ì  ê· í˜•
        trade_quality = (
            features_df['sharpe_ratio'] * 0.3 +
            features_df['volume_ratio'] * 0.2 +
            features_df['market_trend'] * 0.2 +
            features_df['eps_growth'] * 0.15 +
            features_df['analyst_recommendations'] * 0.15 +
            np.random.normal(0, 0.1, n_samples)
        )
        
        targets = {
            'buy_signal': buy_signal,
            'sell_signal': sell_signal,
            'trade_quality': trade_quality
        }
        
        return targets
    
    def train_models(self, features_df, targets):
        """3ê°œ ëª¨ë¸ í•™ìŠµ"""
        print("ğŸ”¥ 3ê°œ XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        for model_name, y in targets.items():
            print(f"   ğŸ“Š {model_name} ëª¨ë¸ í•™ìŠµ...")
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                features_df, y, test_size=0.2, random_state=42
            )
            
            # XGBoost ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
            model = xgb.XGBRegressor(
                n_estimators=200,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42
            )
            
            model.fit(X_train, y_train)
            
            # ì„±ëŠ¥ í‰ê°€
            train_pred = model.predict(X_train)
            test_pred = model.predict(X_test)
            
            train_r2 = r2_score(y_train, train_pred)
            test_r2 = r2_score(y_test, test_pred)
            
            print(f"      âœ… RÂ² - Train: {train_r2:.4f}, Test: {test_r2:.4f}")
            
            # ëª¨ë¸ ì €ì¥
            self.models[model_name] = model
            
            # Feature Importance ì¶”ì¶œ
            importance = model.feature_importances_
            feature_names = features_df.columns.tolist()
            
            importance_df = pd.DataFrame({
                'feature': feature_names,
                'importance': importance
            }).sort_values('importance', ascending=False)
            
            self.feature_importances[model_name] = importance_df
            
            # ì‹¤ì œ ì˜í–¥ë„ ê³„ì‚° (ì˜ˆì¸¡ê°’ ë³€í™”ëŸ‰ ê¸°ì¤€)
            self._calculate_feature_impact(model, X_test, model_name)
        
        print("âœ… ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    
    def _calculate_feature_impact(self, model, X_test, model_name):
        """í”¼ì²˜ë³„ ì‹¤ì œ ì˜í–¥ë„ ê³„ì‚° (ì˜ˆì¸¡ê°’ ë³€í™”ëŸ‰ ê¸°ì¤€)"""
        base_pred = model.predict(X_test)
        impacts = {}
        
        for feature in X_test.columns:
            # í”¼ì²˜ ê°’ì„ í‰ê· ìœ¼ë¡œ ë³€ê²½í–ˆì„ ë•Œ ì˜ˆì¸¡ê°’ ë³€í™”
            X_modified = X_test.copy()
            X_modified[feature] = X_modified[feature].mean()
            
            modified_pred = model.predict(X_modified)
            impact = np.mean(np.abs(base_pred - modified_pred))
            impacts[feature] = impact
        
        # ì •ê·œí™” (0-100% ë²”ìœ„)
        max_impact = max(impacts.values())
        if max_impact > 0:
            impacts = {k: (v/max_impact)*100 for k, v in impacts.items()}
        
        impact_df = pd.DataFrame(list(impacts.items()), 
                               columns=['feature', 'impact_percent'])
        impact_df = impact_df.sort_values('impact_percent', ascending=False)
        
        self.feature_impacts[model_name] = impact_df
    
    def get_top5_features(self):
        """ìƒìœ„ 5ê°œ í”¼ì²˜ ì¶”ì¶œ"""
        results = {}
        
        for model_name in self.models.keys():
            importance_df = self.feature_importances[model_name]
            impact_df = self.feature_impacts[model_name]
            
            # ìƒìœ„ 5ê°œ í”¼ì²˜
            top5_importance = importance_df.head(5)
            top5_impact = impact_df.head(5)
            
            # ê²°í•©ëœ ì •ë³´
            combined_info = []
            for _, row in top5_importance.iterrows():
                feature = row['feature']
                importance = row['importance']
                
                # í•´ë‹¹ í”¼ì²˜ì˜ ì˜í–¥ë„ ì°¾ê¸°
                impact_row = impact_df[impact_df['feature'] == feature]
                impact_percent = impact_row['impact_percent'].iloc[0] if len(impact_row) > 0 else 0
                
                # í”¼ì²˜ ì„¤ëª… ì¶”ê°€
                feature_desc = self._get_feature_description(feature)
                
                combined_info.append({
                    'feature': feature,
                    'description': feature_desc,
                    'importance_score': importance,
                    'impact_percent': impact_percent,
                    'rank': len(combined_info) + 1
                })
            
            results[model_name] = combined_info
            
        return results
    
    def _get_feature_description(self, feature):
        """í”¼ì²˜ ì„¤ëª… ë§¤í•‘"""
        descriptions = {
            'market_trend': 'ì‹œì¥ íŠ¸ë Œë“œ (ì „ì²´ ì‹œì¥ ë°©í–¥ì„±)',
            'volatility': 'ë³€ë™ì„± (ê°€ê²© ë³€ë™ í­)',
            'volume_ratio': 'ê±°ë˜ëŸ‰ ë¹„ìœ¨ (í‰ê·  ëŒ€ë¹„)',
            'rsi': 'RSI ì§€í‘œ (ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„)',
            'macd': 'MACD ì§€í‘œ (ëª¨ë©˜í…€)',
            'bollinger_position': 'ë³¼ë¦°ì € ë°´ë“œ ìœ„ì¹˜',
            'moving_avg_20': '20ì¼ ì´ë™í‰ê·  ëŒ€ë¹„',
            'moving_avg_60': '60ì¼ ì´ë™í‰ê·  ëŒ€ë¹„',
            'pe_ratio': 'PER (ì£¼ê°€ìˆ˜ìµë¹„ìœ¨)',
            'eps_growth': 'EPS ì„±ì¥ë¥ ',
            'debt_ratio': 'ë¶€ì±„ë¹„ìœ¨',
            'roe': 'ROE (ìê¸°ìë³¸ì´ìµë¥ )',
            'interest_rate': 'ê¸°ì¤€ê¸ˆë¦¬',
            'inflation_rate': 'ì¸í”Œë ˆì´ì…˜ìœ¨',
            'gdp_growth': 'GDP ì„±ì¥ë¥ ',
            'fear_greed_index': 'ê³µí¬íƒìš•ì§€ìˆ˜',
            'news_sentiment': 'ë‰´ìŠ¤ ê°ì •ì ìˆ˜',
            'analyst_recommendations': 'ì• ë„ë¦¬ìŠ¤íŠ¸ ì¶”ì²œì ìˆ˜',
            'sector_performance': 'ì„¹í„° ì„±ê³¼',
            'industry_beta': 'ì‚°ì—… ë² íƒ€',
            'value_at_risk': 'VaR (ìœ„í—˜ê°€ì¹˜)',
            'sharpe_ratio': 'ìƒ¤í”„ ë¹„ìœ¨',
            'bid_ask_spread': 'í˜¸ê°€ ìŠ¤í”„ë ˆë“œ',
            'turnover_rate': 'íšŒì „ìœ¨',
            'price_momentum_5d': '5ì¼ ê°€ê²© ëª¨ë©˜í…€',
            'price_momentum_20d': '20ì¼ ê°€ê²© ëª¨ë©˜í…€',
            'earnings_momentum': 'ìˆ˜ìµ ëª¨ë©˜í…€'
        }
        return descriptions.get(feature, feature)
    
    def visualize_top5_features(self, save_path=None):
        """ìƒìœ„ 5ê°œ í”¼ì²˜ ì‹œê°í™”"""
        top5_results = self.get_top5_features()
        
        fig, axes = plt.subplots(1, 3, figsize=(24, 8))
        fig.patch.set_facecolor('white')
        
        model_info = [
            ('buy_signal', 'Buy Signal Model', KB_COLORS['primary']),
            ('sell_signal', 'Sell Signal Model', KB_COLORS['danger']),
            ('trade_quality', 'Trade Quality Model', KB_COLORS['accent'])
        ]
        
        for idx, (model_name, title, color) in enumerate(model_info):
            ax = axes[idx]
            data = top5_results[model_name]
            
            # ë°ì´í„° ì¤€ë¹„
            features = [d['description'][:20] + '...' if len(d['description']) > 20 
                       else d['description'] for d in data]
            importances = [d['importance_score'] for d in data]
            impacts = [d['impact_percent'] for d in data]
            
            # ì´ì¤‘ ë§‰ëŒ€ ê·¸ë˜í”„
            x = np.arange(len(features))
            width = 0.35
            
            bars1 = ax.bar(x - width/2, importances, width, 
                          label='Feature Importance', color=color, alpha=0.7)
            bars2 = ax.bar(x + width/2, impacts, width,
                          label='Impact (%)', color=color, alpha=0.4)
            
            # ê°’ í‘œì‹œ
            for i, (imp, impact) in enumerate(zip(importances, impacts)):
                ax.text(i - width/2, imp + max(importances)*0.01, f'{imp:.3f}',
                       ha='center', va='bottom', fontsize=9, fontweight='bold')
                ax.text(i + width/2, impact + max(impacts)*0.01, f'{impact:.1f}%',
                       ha='center', va='bottom', fontsize=9, fontweight='bold')
            
            # ìŠ¤íƒ€ì¼ë§
            ax.set_title(title, fontsize=16, fontweight='bold', color=color, pad=20)
            ax.set_xlabel('Features', fontsize=12, color=KB_COLORS['text'])
            ax.set_ylabel('Score', fontsize=12, color=KB_COLORS['text'])
            ax.set_xticks(x)
            ax.set_xticklabels(features, rotation=45, ha='right', fontsize=10)
            ax.legend(fontsize=11)
            ax.grid(True, alpha=0.3)
            ax.set_facecolor('white')
            
            # Yì¶• ë²”ìœ„ ì¡°ì •
            max_val = max(max(importances), max(impacts))
            ax.set_ylim(0, max_val * 1.15)
        
        plt.suptitle('ğŸ” Top 5 Most Important Features Analysis', 
                    fontsize=20, fontweight='bold', y=0.98, color=KB_COLORS['text'])
        
        plt.tight_layout(rect=[0, 0, 1, 0.95])
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
            print(f"âœ… ì‹œê°í™” ì €ì¥: {save_path}")
        
        plt.show()
        
        return top5_results
    
    def print_detailed_results(self):
        """ìƒì„¸ ê²°ê³¼ ì¶œë ¥"""
        top5_results = self.get_top5_features()
        
        print("\n" + "="*80)
        print("ğŸ” TOP 5 FEATURE IMPORTANCE ANALYSIS")
        print("="*80)
        
        for model_name, data in top5_results.items():
            print(f"\nğŸ† {model_name.upper().replace('_', ' ')} MODEL")
            print("-" * 60)
            
            for item in data:
                print(f"#{item['rank']} {item['feature']}")
                print(f"   ğŸ“‹ ì„¤ëª…: {item['description']}")
                print(f"   ğŸ“Š ì¤‘ìš”ë„ ì ìˆ˜: {item['importance_score']:.4f}")
                print(f"   ğŸ“ˆ ì‹¤ì œ ì˜í–¥ë„: {item['impact_percent']:.1f}%")
                print()
        
        print("="*80)
        print("ğŸ“ ë¶„ì„ ìš”ì•½:")
        print("â€¢ Feature Importance: XGBoost ëª¨ë¸ ë‚´ë¶€ ì¤‘ìš”ë„ ì ìˆ˜")
        print("â€¢ Impact %: í•´ë‹¹ í”¼ì²˜ ë³€ê²½ ì‹œ ì˜ˆì¸¡ê°’ ë³€í™” ì •ë„")
        print("â€¢ ë†’ì€ ê°’ì¼ìˆ˜ë¡ ëª¨ë¸ ê²°ì •ì— ë” í° ì˜í–¥ì„ ë¯¸ì¹¨")
        print("="*80)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Feature Importance Top 5 Analysis ì‹œì‘")
    print("="*60)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = FeatureImportanceAnalyzer()
    
    # ë°ì´í„° ìƒì„±
    print("ğŸ“Š íŠ¸ë ˆì´ë”© ë°ì´í„° ìƒì„± ì¤‘...")
    features_df = analyzer.generate_synthetic_trading_data(n_samples=15000)
    targets = analyzer.create_target_variables(features_df)
    
    print(f"âœ… ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(features_df)}ê°œ ìƒ˜í”Œ, {len(features_df.columns)}ê°œ í”¼ì²˜")
    
    # ëª¨ë¸ í•™ìŠµ
    analyzer.train_models(features_df, targets)
    
    # ê²°ê³¼ ì¶œë ¥
    analyzer.print_detailed_results()
    
    # ì‹œê°í™”
    print("\nğŸ“ˆ ìƒìœ„ 5ê°œ í”¼ì²˜ ì‹œê°í™” ìƒì„± ì¤‘...")
    save_path = '/Users/inter4259/Desktop/Programming/hek_credit/top5_features_analysis.png'
    top5_results = analyzer.visualize_top5_features(save_path)
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")
    
    return analyzer, top5_results

if __name__ == "__main__":
    analyzer, results = main()