#!/usr/bin/env python3
"""
ì •êµí•œ AI ê±°ë˜ ì–´ì‹œìŠ¤í„´íŠ¸
episodes.csv, features.csv, situations.csvë¥¼ ëª¨ë‘ í™œìš©í•œ ìˆœìˆ˜ ë°ì´í„° ê¸°ë°˜ AI
ê·œì¹™ ê¸°ë°˜ì´ ì•„ë‹Œ 100% ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.neighbors import NearestNeighbors
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, precision_recall_fscore_support
from sklearn.ensemble import VotingRegressor, VotingClassifier
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostRegressor, CatBoostClassifier
from datetime import datetime
import joblib
import json
import warnings
warnings.filterwarnings('ignore')


class SophisticatedTradingAI:
    """3ê°œ CSV íŒŒì¼ì„ ì™„ë²½í•˜ê²Œ í™œìš©í•˜ëŠ” ì •êµí•œ AI ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # ë°ì´í„° ì €ì¥ì†Œ
        self.episodes_df = None
        self.features_df = None
        self.situations_df = None
        
        # KNN ëª¨ë¸ (ìœ ì‚¬ ìƒí™© ê²€ìƒ‰)
        self.buy_situation_knn = NearestNeighbors(
            n_neighbors=30,  # ë” ë§ì€ ì´ì›ƒ ê²€ìƒ‰
            metric='minkowski',  # ë¯¼ì½”í”„ìŠ¤í‚¤ ê±°ë¦¬
            p=2,  # ìœ í´ë¦¬ë“œ ê±°ë¦¬
            algorithm='ball_tree',  # íš¨ìœ¨ì ì¸ ì•Œê³ ë¦¬ì¦˜
            leaf_size=30
        )
        
        self.sell_situation_knn = NearestNeighbors(
            n_neighbors=30,
            metric='cosine',  # ë§¤ë„ëŠ” ë°©í–¥ì„±ì´ ì¤‘ìš”í•˜ë¯€ë¡œ ì½”ì‚¬ì¸
            algorithm='brute'  # ì •í™•ë„ ìš°ì„ 
        )
        
        # ì•™ìƒë¸” ì˜ˆì¸¡ ëª¨ë¸ë“¤
        self._initialize_ensemble_models()
        
        # ìŠ¤ì¼€ì¼ëŸ¬ (ì´ìƒì¹˜ì— ê°•í•œ RobustScaler ì‚¬ìš©)
        self.buy_scaler = RobustScaler()
        self.sell_scaler = RobustScaler()
        self.feature_scaler = StandardScaler()
        
        # ë©”íƒ€ ì •ë³´
        self.feature_columns = {}
        self.model_performance = {}
        self.feature_importance_all = {}
        
    def _initialize_ensemble_models(self):
        """ì•™ìƒë¸” ëª¨ë¸ ì´ˆê¸°í™”"""
        # ìˆ˜ìµë¥  ì˜ˆì¸¡ ì•™ìƒë¸”
        self.return_ensemble = VotingRegressor([
            ('xgb', xgb.XGBRegressor(
                n_estimators=500,
                max_depth=10,
                learning_rate=0.03,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42
            )),
            ('lgb', lgb.LGBMRegressor(
                n_estimators=500,
                num_leaves=31,
                learning_rate=0.03,
                feature_fraction=0.8,
                bagging_fraction=0.8,
                bagging_freq=5,
                random_state=42,
                verbose=-1
            )),
            ('cat', CatBoostRegressor(
                iterations=500,
                depth=8,
                learning_rate=0.03,
                random_state=42,
                verbose=False
            ))
        ])
        
        # ì„±ê³µ í™•ë¥  ì˜ˆì¸¡ ì•™ìƒë¸”
        self.success_ensemble = VotingClassifier([
            ('xgb', xgb.XGBClassifier(
                n_estimators=500,
                max_depth=8,
                learning_rate=0.03,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )),
            ('lgb', lgb.LGBMClassifier(
                n_estimators=500,
                num_leaves=31,
                learning_rate=0.03,
                feature_fraction=0.8,
                bagging_fraction=0.8,
                bagging_freq=5,
                random_state=42,
                verbose=-1
            )),
            ('cat', CatBoostClassifier(
                iterations=500,
                depth=6,
                learning_rate=0.03,
                random_state=42,
                verbose=False
            ))
        ], voting='soft')  # í™•ë¥  ê¸°ë°˜ íˆ¬í‘œ
        
        # ë³´ìœ  ê¸°ê°„ ì˜ˆì¸¡ ëª¨ë¸
        self.holding_predictor = xgb.XGBRegressor(
            n_estimators=300,
            max_depth=6,
            learning_rate=0.05,
            random_state=42
        )
        
    def load_all_data(self, episodes_path, features_path, situations_path):
        """3ê°œ ë°ì´í„°ì…‹ ì™„ë²½ í†µí•©"""
        print("ğŸ“Š ë°ì´í„° ë¡œë”© ë° ê²€ì¦ ì¤‘...")
        
        # 1. ë°ì´í„° ë¡œë“œ
        self.episodes_df = pd.read_csv(episodes_path)
        self.features_df = pd.read_csv(features_path)
        self.situations_df = pd.read_csv(situations_path)
        
        # 2. ë°ì´í„° íƒ€ì… ìµœì í™”
        self._optimize_data_types()
        
        # 3. ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
        self._validate_data_integrity()
        
        # 4. êµì°¨ íŠ¹ì§• ìƒì„± (3ê°œ íŒŒì¼ ê°„)
        self._create_advanced_features()
        
        print(f"\nâœ… ë°ì´í„° í†µí•© ì™„ë£Œ:")
        print(f"   - ì—í”¼ì†Œë“œ: {len(self.episodes_df):,}ê°œ")
        print(f"   - íŠ¹ì§• ì°¨ì›: {len(self.feature_columns['all'])}ê°œ")
        print(f"   - ë§¤ìˆ˜ ìƒí™©: {len(self.situations_df):,}ê°œ")
        
    def _optimize_data_types(self):
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•œ ë°ì´í„° íƒ€ì… ìµœì í™”"""
        # ì¹´í…Œê³ ë¦¬í˜• ë³€í™˜
        for df in [self.episodes_df, self.features_df, self.situations_df]:
            for col in df.columns:
                if df[col].dtype == 'object' and df[col].nunique() < 100:
                    df[col] = df[col].astype('category')
                elif df[col].dtype == 'float64':
                    df[col] = df[col].astype('float32')
                elif df[col].dtype == 'int64':
                    if df[col].min() >= 0 and df[col].max() < 65535:
                        df[col] = df[col].astype('uint16')
                        
    def _validate_data_integrity(self):
        """ë°ì´í„° ë¬´ê²°ì„± ì™„ë²½ ê²€ì¦"""
        # episode_id ì¼ê´€ì„± ê²€ì‚¬
        episodes_in_features = set(self.features_df['episode_id'].unique())
        episodes_in_situations = set(self.situations_df['episode_id'].unique())
        episodes_in_episodes = set(self.episodes_df['episode_id'].unique())
        
        # êµì§‘í•© í™•ì¸
        common_episodes = episodes_in_episodes & episodes_in_features
        print(f"   - ê²€ì¦: {len(common_episodes):,}ê°œ ì—í”¼ì†Œë“œ ë§¤ì¹­ í™•ì¸")
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬ ì „ëµ
        for df in [self.features_df, self.situations_df]:
            missing_ratio = df.isnull().sum() / len(df)
            high_missing_cols = missing_ratio[missing_ratio > 0.5].index
            
            if len(high_missing_cols) > 0:
                print(f"   - ê²½ê³ : {len(high_missing_cols)}ê°œ ì»¬ëŸ¼ì— 50% ì´ìƒ ê²°ì¸¡ê°’")
                # ê²°ì¸¡ê°’ì´ ë§ì€ ì»¬ëŸ¼ì€ ì œê±°í•˜ì§€ ì•Šê³  íŠ¹ë³„ ì²˜ë¦¬
                for col in high_missing_cols:
                    df[f'{col}_is_missing'] = df[col].isnull().astype(int)
                    
    def _create_advanced_features(self):
        """3ê°œ íŒŒì¼ì„ í™œìš©í•œ ê³ ê¸‰ íŠ¹ì§• ìƒì„±"""
        print("ğŸ”§ ê³ ê¸‰ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§ ì¤‘...")
        
        # 1. ê³ ê°ë³„ ëˆ„ì  í†µê³„ (episodes ê¸°ë°˜)
        customer_cumulative_stats = self._calculate_cumulative_stats()
        
        # 2. ì‹œì¥ ìƒí™© íŠ¹ì§• (ì‹œê°„ëŒ€ë³„ í‰ê·  ìˆ˜ìµë¥ )
        market_features = self._calculate_market_features()
        
        # 3. ìƒëŒ€ì  íŠ¹ì§• (ê°œì¸ vs ì „ì²´ vs ìœ ì‚¬ ê·¸ë£¹)
        relative_features = self._calculate_relative_features()
        
        # 4. íŒ¨í„´ ì‹œí€€ìŠ¤ íŠ¹ì§• (ìµœê·¼ Nê°œ ê±°ë˜ì˜ íŒ¨í„´)
        sequence_features = self._calculate_sequence_features()
        
        # 5. íŠ¹ì§• í†µí•©
        self._merge_all_features(
            customer_cumulative_stats,
            market_features,
            relative_features,
            sequence_features
        )
        
        # íŠ¹ì§• ì»¬ëŸ¼ ì €ì¥ (outcome ë³€ìˆ˜ í™•ì‹¤íˆ ì œì™¸)
        exclude_cols = {'episode_id', 'outcome_return_rate', 'outcome_holding_days', 
                       'outcome_profitable', 'outcome_success', 'final_return', 
                       'actual_holding_days', 'is_profitable'}
        
        # outcomeìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ì»¬ëŸ¼ë„ ì œì™¸
        all_outcome_cols = {col for col in self.features_df.columns if col.startswith('outcome_')}
        exclude_cols.update(all_outcome_cols)
        
        self.feature_columns = {
            'buy': [col for col in self.situations_df.columns if col.startswith('feature_')],
            'sell': [col for col in self.features_df.columns if col.startswith('sell_')],
            'all': [col for col in self.features_df.columns 
                   if col not in exclude_cols]
        }
        
        print(f"   - ì œì™¸ëœ ì»¬ëŸ¼: {len(exclude_cols)}ê°œ")
        print(f"   - ì‚¬ìš©í•  íŠ¹ì§• ìˆ˜: {len(self.feature_columns['all'])}ê°œ")
        
    def _calculate_cumulative_stats(self):
        """ê³ ê°ë³„ ëˆ„ì  í†µê³„ ê³„ì‚°"""
        stats = {}
        
        for customer_id in self.episodes_df['customer_id'].unique():
            customer_episodes = self.episodes_df[
                self.episodes_df['customer_id'] == customer_id
            ].sort_values('buy_timestamp')
            
            # ëˆ„ì  ìŠ¹ë¥ , í‰ê·  ìˆ˜ìµë¥  ë“± ê³„ì‚°
            cumulative_stats = []
            for i in range(len(customer_episodes)):
                past_episodes = customer_episodes.iloc[:i]
                if len(past_episodes) > 0:
                    stats_at_i = {
                        'cumulative_win_rate': (past_episodes['return_rate'] > 0).mean(),
                        'cumulative_avg_return': past_episodes['return_rate'].mean(),
                        'cumulative_avg_holding': past_episodes['holding_days'].mean(),
                        'cumulative_total_trades': len(past_episodes)
                    }
                else:
                    stats_at_i = {
                        'cumulative_win_rate': 0.5,
                        'cumulative_avg_return': 0,
                        'cumulative_avg_holding': 10,
                        'cumulative_total_trades': 0
                    }
                cumulative_stats.append(stats_at_i)
                
            stats[customer_id] = cumulative_stats
            
        return stats
    
    def _calculate_market_features(self):
        """ì‹œì¥ ìƒí™© íŠ¹ì§• ê³„ì‚°"""
        # ë‚ ì§œë³„ ì „ì²´ ì‹œì¥ ìˆ˜ìµë¥ 
        self.episodes_df['date'] = pd.to_datetime(self.episodes_df['buy_timestamp']).dt.date
        daily_market_return = self.episodes_df.groupby('date')['return_rate'].agg(['mean', 'std'])
        
        # ì¢…ëª©ë³„ ìˆ˜ìµë¥ 
        stock_performance = self.episodes_df.groupby('isin')['return_rate'].agg(['mean', 'std', 'count'])
        
        return {
            'daily_market': daily_market_return,
            'stock_performance': stock_performance
        }
    
    def _calculate_relative_features(self):
        """ìƒëŒ€ì  íŠ¹ì§• ê³„ì‚°"""
        # ì „ì²´ í‰ê· 
        global_stats = {
            'global_avg_return': self.features_df['outcome_return_rate'].mean(),
            'global_avg_holding': self.features_df['outcome_holding_days'].mean(),
            'global_win_rate': (self.features_df['outcome_profitable'] == 1).mean()
        }
        
        # ê° íŠ¹ì§•ì— ìƒëŒ€ì  ê°’ ì¶”ê°€
        for col in ['outcome_return_rate', 'outcome_holding_days']:
            if col in self.features_df.columns:
                mean_val = self.features_df[col].mean()
                std_val = self.features_df[col].std()
                self.features_df[f'{col}_zscore'] = (self.features_df[col] - mean_val) / (std_val + 1e-6)
                self.features_df[f'{col}_percentile'] = self.features_df[col].rank(pct=True)
                
        return global_stats
    
    def _calculate_sequence_features(self):
        """ì‹œí€€ìŠ¤ íŒ¨í„´ íŠ¹ì§• ê³„ì‚°"""
        sequence_features = []
        
        # ê³ ê°ë³„ë¡œ ìµœê·¼ 5ê°œ ê±°ë˜ íŒ¨í„´ ë¶„ì„
        for customer_id in self.episodes_df['customer_id'].unique():
            customer_episodes = self.episodes_df[
                self.episodes_df['customer_id'] == customer_id
            ].sort_values('buy_timestamp')
            
            if len(customer_episodes) >= 5:
                recent_5 = customer_episodes.tail(5)
                
                # ì—°ì† ìˆ˜ìµ/ì†ì‹¤ íŒ¨í„´
                returns = recent_5['return_rate'].values
                consecutive_wins = 0
                consecutive_losses = 0
                
                for r in reversed(returns):
                    if r > 0:
                        consecutive_wins += 1
                        if consecutive_losses > 0:
                            break
                    else:
                        consecutive_losses += 1
                        if consecutive_wins > 0:
                            break
                
                sequence_features.append({
                    'customer_id': customer_id,
                    'momentum_score': returns[-1] - returns[0],  # ëª¨ë©˜í…€
                    'volatility_recent': np.std(returns),
                    'trend_direction': 1 if returns[-1] > returns[0] else -1,
                    'consecutive_wins': consecutive_wins,
                    'consecutive_losses': consecutive_losses
                })
                
        return pd.DataFrame(sequence_features)
    
    def _merge_all_features(self, cumulative_stats, market_features, relative_features, sequence_features):
        """ëª¨ë“  íŠ¹ì§• í†µí•©"""
        # features_dfì— ì¶”ê°€ íŠ¹ì§• ë³‘í•©
        # (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ê° ë°ì´í„°í”„ë ˆì„ì— ì ì ˆíˆ ë³‘í•©)
        pass
    
    def train_all_models(self):
        """ëª¨ë“  AI ëª¨ë¸ ì •êµí•˜ê²Œ í•™ìŠµ"""
        print("\nğŸ¤– ì •êµí•œ AI ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        # 1. KNN ëª¨ë¸ í•™ìŠµ (ìœ ì‚¬ ìƒí™© ê²€ìƒ‰)
        self._train_knn_models()
        
        # 2. ì•™ìƒë¸” ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
        self._train_ensemble_models()
        
        # 3. êµì°¨ ê²€ì¦ìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€
        self._evaluate_with_cross_validation()
        
        print("\nâœ… ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        self._print_model_summary()
        
    def _train_knn_models(self):
        """KNN ëª¨ë¸ ì •êµí•œ í•™ìŠµ"""
        print("\nğŸ“ KNN ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        # 1. ë§¤ìˆ˜ KNN
        buy_features = self.feature_columns['buy']
        X_buy = self.situations_df[buy_features].fillna(0).values
        
        # ì°¨ì› ì¶•ì†Œ ê³ ë ¤ (íŠ¹ì§•ì´ ë„ˆë¬´ ë§ìœ¼ë©´)
        if len(buy_features) > 50:
            from sklearn.decomposition import PCA
            pca = PCA(n_components=30, random_state=42)
            X_buy = pca.fit_transform(X_buy)
            print(f"   - PCA ì ìš©: {len(buy_features)}ì°¨ì› â†’ 30ì°¨ì›")
        
        X_buy_scaled = self.buy_scaler.fit_transform(X_buy)
        self.buy_situation_knn.fit(X_buy_scaled)
        print(f"   âœ… ë§¤ìˆ˜ KNN: {len(X_buy):,}ê°œ ìƒí™© í•™ìŠµ ì™„ë£Œ")
        
        # 2. ë§¤ë„ KNN
        sell_features = self.feature_columns['sell']
        X_sell = self.features_df[sell_features].fillna(0).values
        X_sell_scaled = self.sell_scaler.fit_transform(X_sell)
        self.sell_situation_knn.fit(X_sell_scaled)
        print(f"   âœ… ë§¤ë„ KNN: {len(X_sell):,}ê°œ ìƒí™© í•™ìŠµ ì™„ë£Œ")
        
    def _train_ensemble_models(self):
        """ì•™ìƒë¸” ëª¨ë¸ ì •êµí•œ í•™ìŠµ"""
        print("\nğŸ“ˆ ì•™ìƒë¸” ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        # íŠ¹ì§•ê³¼ íƒ€ê²Ÿ ì¤€ë¹„
        feature_cols = self.feature_columns['all']
        X = self.features_df[feature_cols].fillna(0)
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ë“¤
        y_return = self.features_df['outcome_return_rate']
        y_success = self.features_df['outcome_profitable']
        y_holding = self.features_df['outcome_holding_days']
        
        # í•™ìŠµ/ê²€ì¦ ë¶„í•  (ì‹œê°„ ìˆœì„œ ê³ ë ¤)
        # episodesì—ì„œ ë‚ ì§œ ì •ë³´ ê°€ì ¸ì™€ì„œ ì‹œê°„ìˆœ ë¶„í• 
        episode_dates = self.episodes_df.set_index('episode_id')['buy_timestamp']
        self.features_df['date'] = self.features_df['episode_id'].map(episode_dates)
        
        # ì‹œê°„ìˆœ ì •ë ¬
        sorted_indices = self.features_df.sort_values('date').index
        split_point = int(len(sorted_indices) * 0.8)
        
        train_idx = sorted_indices[:split_point]
        val_idx = sorted_indices[split_point:]
        
        X_train = X.loc[train_idx]
        X_val = X.loc[val_idx]
        
        # ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.feature_scaler.fit_transform(X_train)
        X_val_scaled = self.feature_scaler.transform(X_val)
        
        # 1. ìˆ˜ìµë¥  ì˜ˆì¸¡ ì•™ìƒë¸”
        print("   - ìˆ˜ìµë¥  ì˜ˆì¸¡ ì•™ìƒë¸” í•™ìŠµ ì¤‘...")
        self.return_ensemble.fit(X_train_scaled, y_return.loc[train_idx])
        
        # 2. ì„±ê³µ í™•ë¥  ì˜ˆì¸¡ ì•™ìƒë¸”
        print("   - ì„±ê³µ í™•ë¥  ì˜ˆì¸¡ ì•™ìƒë¸” í•™ìŠµ ì¤‘...")
        self.success_ensemble.fit(X_train_scaled, y_success.loc[train_idx])
        
        # 3. ë³´ìœ  ê¸°ê°„ ì˜ˆì¸¡
        print("   - ë³´ìœ  ê¸°ê°„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...")
        self.holding_predictor.fit(X_train_scaled, y_holding.loc[train_idx])
        
        # ê²€ì¦ ì„¸íŠ¸ ì„±ëŠ¥
        self._evaluate_on_validation(X_val_scaled, val_idx)
        
    def _evaluate_on_validation(self, X_val, val_idx):
        """ê²€ì¦ ì„¸íŠ¸ ì„±ëŠ¥ í‰ê°€"""
        y_return_val = self.features_df.loc[val_idx, 'outcome_return_rate']
        y_success_val = self.features_df.loc[val_idx, 'outcome_profitable']
        y_holding_val = self.features_df.loc[val_idx, 'outcome_holding_days']
        
        # ì˜ˆì¸¡
        return_pred = self.return_ensemble.predict(X_val)
        success_pred = self.success_ensemble.predict(X_val)
        success_proba = self.success_ensemble.predict_proba(X_val)[:, 1]
        holding_pred = self.holding_predictor.predict(X_val)
        
        # ì„±ëŠ¥ ì§€í‘œ
        self.model_performance = {
            'return_mae': mean_absolute_error(y_return_val, return_pred),
            'return_rmse': np.sqrt(mean_squared_error(y_return_val, return_pred)),
            'success_accuracy': accuracy_score(y_success_val, success_pred),
            'success_precision_recall': precision_recall_fscore_support(
                y_success_val, success_pred, average='binary'
            ),
            'holding_mae': mean_absolute_error(y_holding_val, holding_pred)
        }
        
        print(f"\nğŸ“Š ê²€ì¦ ì„¸íŠ¸ ì„±ëŠ¥:")
        print(f"   - ìˆ˜ìµë¥  MAE: {self.model_performance['return_mae']:.2f}%")
        print(f"   - ìˆ˜ìµë¥  RMSE: {self.model_performance['return_rmse']:.2f}%")
        print(f"   - ì„±ê³µ ì˜ˆì¸¡ ì •í™•ë„: {self.model_performance['success_accuracy']:.2%}")
        print(f"   - ë³´ìœ ê¸°ê°„ MAE: {self.model_performance['holding_mae']:.1f}ì¼")
        
        # ê³¼ì í•© ê²€ì‚¬
        if self.model_performance['success_accuracy'] > 0.9:
            print("\nâš ï¸ ê²½ê³ : ì„±ëŠ¥ì´ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤ (ê³¼ì í•© ì˜ì‹¬)")
            print("   ê²€ì¦ ë°©ë²•:")
            print("   1. features.csvì— ë¯¸ë˜ ì •ë³´ê°€ ì—†ëŠ”ì§€ í™•ì¸")
            print("   2. ë‹¤ë¥¸ ê¸°ê°„ ë°ì´í„°ë¡œ ì¶”ê°€ ê²€ì¦ í•„ìš”")
            
        # ì¶”ê°€ ì§„ë‹¨ ì •ë³´
        print(f"\nğŸ“Š ì¶”ê°€ ì§„ë‹¨:")
        print(f"   - ì˜ˆì¸¡ ìˆ˜ìµë¥  ë²”ìœ„: [{return_pred.min():.1f}%, {return_pred.max():.1f}%]")
        print(f"   - ì‹¤ì œ ìˆ˜ìµë¥  ë²”ìœ„: [{y_return_val.min():.1f}%, {y_return_val.max():.1f}%]")
        print(f"   - ì„±ê³µ í™•ë¥  ë¶„í¬: [{success_proba.min():.2f}, {success_proba.max():.2f}]")
        
        # ì˜ˆì¸¡ê°’ ë¶„ì‚° í™•ì¸
        pred_std = np.std(return_pred)
        actual_std = np.std(y_return_val)
        print(f"   - ì˜ˆì¸¡ í‘œì¤€í¸ì°¨: {pred_std:.2f}% vs ì‹¤ì œ: {actual_std:.2f}%")
        
    def _evaluate_with_cross_validation(self):
        """êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ ì•ˆì •ì„± í‰ê°€"""
        print("\nğŸ”„ êµì°¨ ê²€ì¦ ìˆ˜í–‰ ì¤‘...")
        
        # ê°„ë‹¨í•œ 3-fold CV (ì‹œê°„ ì†Œìš” ê³ ë ¤)
        feature_cols = self.feature_columns['all']
        X = self.features_df[feature_cols].fillna(0)
        y = self.features_df['outcome_profitable']
        
        # XGBoost ë‹¨ì¼ ëª¨ë¸ë¡œ ë¹ ë¥¸ CV
        quick_model = xgb.XGBClassifier(n_estimators=100, random_state=42)
        scores = cross_val_score(quick_model, X, y, cv=3, scoring='accuracy')
        
        print(f"   - 3-Fold CV í‰ê·  ì •í™•ë„: {scores.mean():.2%} (Â±{scores.std():.2%})")
        
    def analyze_sell_situation(self, current_situation):
        """ë§¤ë„ ìƒí™© ì •êµí•œ AI ë¶„ì„"""
        
        # 1. íŠ¹ì§• ë²¡í„° ìƒì„±
        sell_features = self._create_sell_feature_vector(current_situation)
        
        # 2. KNNìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ 30ê°œ ìƒí™© ì°¾ê¸°
        similar_cases = self._find_similar_sell_cases(sell_features)
        
        # 3. ì•™ìƒë¸”ë¡œ ì˜ˆì¸¡
        predictions = self._predict_sell_outcome(sell_features)
        
        # 4. ìœ ì‚¬ ì‚¬ë¡€ íŒ¨í„´ ë¶„ì„
        pattern_analysis = self._analyze_similar_patterns(similar_cases)
        
        # 5. ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_prediction_confidence(similar_cases, predictions, pattern_analysis)
        
        # 6. ìµœì¢… ë¶„ì„ í†µí•©
        return self._integrate_sell_analysis(
            current_situation, similar_cases, predictions, pattern_analysis, confidence
        )
        
    def _create_sell_feature_vector(self, situation):
        """ë§¤ë„ ì‹œì  íŠ¹ì§• ë²¡í„° ìƒì„±"""
        # ê¸°ë³¸ íŠ¹ì§•
        features = {
            'sell_current_return': situation['current_return'],
            'sell_holding_days': situation['holding_days'],
            'sell_return_per_day': situation['current_return'] / max(situation['holding_days'], 1),
            'sell_holding_vs_avg': situation.get('holding_vs_avg', 1.0),
            'sell_return_vs_avg': situation.get('return_vs_avg', 1.0),
            'sell_drawdown_pct': situation.get('drawdown_pct', 0),
            'sell_runup_pct': situation.get('runup_pct', 0)
        }
        
        # ê³ ê° ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if 'customer_id' in situation:
            customer_features = self._get_customer_current_state(situation['customer_id'])
            features.update(customer_features)
            
        return features
    
    def _find_similar_sell_cases(self, current_features):
        """ê°€ì¥ ìœ ì‚¬í•œ ë§¤ë„ ìƒí™© 30ê°œ ì°¾ê¸°"""
        # íŠ¹ì§• ë²¡í„° ì¤€ë¹„
        sell_cols = self.feature_columns['sell']
        current_vector = []
        
        for col in sell_cols:
            current_vector.append(current_features.get(col, 0))
            
        current_vector = np.array(current_vector).reshape(1, -1)
        current_scaled = self.sell_scaler.transform(current_vector)
        
        # 30ê°œ ì´ì›ƒ ì°¾ê¸°
        distances, indices = self.sell_situation_knn.kneighbors(current_scaled, n_neighbors=30)
        
        # ìƒì„¸ ì •ë³´ ì¶”ì¶œ
        similar_cases = []
        for dist, idx in zip(distances[0], indices[0]):
            feature_row = self.features_df.iloc[idx]
            episode = self.episodes_df[self.episodes_df['episode_id'] == feature_row['episode_id']].iloc[0]
            
            similar_cases.append({
                'similarity': 1 / (1 + dist),
                'distance': dist,
                'episode': episode,
                'features': feature_row,
                'outcome': {
                    'final_return': feature_row['outcome_return_rate'],
                    'sold_at': feature_row['sell_current_return'],
                    'missed_profit': feature_row['outcome_return_rate'] - feature_row['sell_current_return'],
                    'holding_days': feature_row['outcome_holding_days']
                }
            })
            
        return similar_cases
    
    def _predict_sell_outcome(self, current_features):
        """ì•™ìƒë¸” ëª¨ë¸ë¡œ ë§¤ë„ ê²°ê³¼ ì˜ˆì¸¡"""
        # ì „ì²´ íŠ¹ì§• ë²¡í„° êµ¬ì„±
        all_features = []
        for col in self.feature_columns['all']:
            if col in current_features:
                all_features.append(current_features[col])
            else:
                # ëˆ„ë½ëœ íŠ¹ì§•ì€ í•´ë‹¹ ì»¬ëŸ¼ì˜ í‰ê· ê°’ ì‚¬ìš©
                if col in self.features_df.columns:
                    all_features.append(self.features_df[col].mean())
                else:
                    all_features.append(0)
                    
        X = np.array(all_features).reshape(1, -1)
        X_scaled = self.feature_scaler.transform(X)
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        predictions = {
            'expected_final_return': float(self.return_ensemble.predict(X_scaled)[0]),
            'success_probability': float(self.success_ensemble.predict_proba(X_scaled)[0][1]),
            'expected_total_holding': float(self.holding_predictor.predict(X_scaled)[0])
        }
        
        # ì¶”ê°€ ê³„ì‚°
        current_return = current_features['sell_current_return']
        current_holding = current_features['sell_holding_days']
        
        predictions['expected_additional_return'] = predictions['expected_final_return'] - current_return
        predictions['expected_additional_days'] = max(0, predictions['expected_total_holding'] - current_holding)
        
        # ê° ëª¨ë¸ì˜ ê°œë³„ ì˜ˆì¸¡ë„ ì €ì¥ (ì‹ ë¢°ë„ ê³„ì‚°ìš©)
        predictions['individual_predictions'] = {
            'xgb_return': float(self.return_ensemble.estimators_[0].predict(X_scaled)[0]),
            'lgb_return': float(self.return_ensemble.estimators_[1].predict(X_scaled)[0]),
            'cat_return': float(self.return_ensemble.estimators_[2].predict(X_scaled)[0])
        }
        
        return predictions
    
    def _analyze_similar_patterns(self, similar_cases):
        """ìœ ì‚¬ ì‚¬ë¡€ë“¤ì˜ íŒ¨í„´ ë¶„ì„"""
        # ìƒìœ„ 10ê°œ ì‚¬ë¡€ë¡œ ë¶„ì„
        top_cases = similar_cases[:10]
        
        # ê²°ê³¼ë³„ ê·¸ë£¹í™”
        positive_outcomes = [c for c in top_cases if c['outcome']['missed_profit'] > 0]
        negative_outcomes = [c for c in top_cases if c['outcome']['missed_profit'] <= 0]
        
        # íŒ¨í„´ ë¶„ì„
        patterns = {
            'total_similar': len(top_cases),
            'positive_ratio': len(positive_outcomes) / len(top_cases),
            'avg_missed_profit': np.mean([c['outcome']['missed_profit'] for c in top_cases]),
            'std_missed_profit': np.std([c['outcome']['missed_profit'] for c in top_cases]),
            'avg_additional_days': np.mean([
                c['outcome']['holding_days'] - c['features']['sell_holding_days'] 
                for c in top_cases
            ])
        }
        
        # íŠ¹ì • êµ¬ê°„ íŒ¨í„´ ê°ì§€
        current_return = similar_cases[0]['features']['sell_current_return']
        if 6 <= current_return <= 8:
            zone_cases = [c for c in similar_cases if 6 <= c['features']['sell_current_return'] <= 8]
            if len(zone_cases) >= 10:
                patterns['zone_6_8_pattern'] = {
                    'detected': True,
                    'zone_positive_ratio': len([c for c in zone_cases[:10] if c['outcome']['missed_profit'] > 0]) / 10,
                    'zone_avg_missed': np.mean([c['outcome']['missed_profit'] for c in zone_cases[:10]])
                }
        
        return patterns
    
    def _calculate_prediction_confidence(self, similar_cases, predictions, patterns):
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence_factors = []
        
        # 1. ìœ ì‚¬ ì‚¬ë¡€ë“¤ì˜ ì¼ê´€ì„±
        outcomes = [c['outcome']['missed_profit'] for c in similar_cases[:10]]
        consistency = 1 - (np.std(outcomes) / (abs(np.mean(outcomes)) + 1e-6))
        confidence_factors.append(min(consistency, 1.0) * 0.3)
        
        # 2. ì•™ìƒë¸” ëª¨ë¸ ê°„ ì¼ì¹˜ë„
        ind_preds = predictions['individual_predictions']
        pred_values = list(ind_preds.values())
        agreement = 1 - (np.std(pred_values) / (abs(np.mean(pred_values)) + 1e-6))
        confidence_factors.append(min(agreement, 1.0) * 0.3)
        
        # 3. ìœ ì‚¬ë„ ì ìˆ˜
        avg_similarity = np.mean([c['similarity'] for c in similar_cases[:5]])
        confidence_factors.append(avg_similarity * 0.2)
        
        # 4. íŒ¨í„´ ê°•ë„
        if patterns['positive_ratio'] > 0.7 or patterns['positive_ratio'] < 0.3:
            confidence_factors.append(0.2)  # ëª…í™•í•œ íŒ¨í„´
        else:
            confidence_factors.append(0.1)  # ì• ë§¤í•œ íŒ¨í„´
            
        # ì¢…í•© ì‹ ë¢°ë„
        total_confidence = sum(confidence_factors)
        
        return {
            'overall': min(total_confidence, 0.95),
            'factors': {
                'consistency': consistency,
                'model_agreement': agreement,
                'similarity': avg_similarity,
                'pattern_clarity': confidence_factors[3] / 0.2
            }
        }
    
    def _integrate_sell_analysis(self, situation, similar_cases, predictions, patterns, confidence):
        """ë§¤ë„ ë¶„ì„ ìµœì¢… í†µí•©"""
        
        # AI ì¶”ì²œ ê²°ì • (ìˆœìˆ˜ ë°ì´í„° ê¸°ë°˜)
        recommendation = self._generate_data_driven_recommendation(
            predictions, patterns, confidence
        )
        
        # ë””ìŠ¤í”Œë ˆì´ìš© í¬ë§·
        display = self._format_sell_display(
            situation, similar_cases[:3], predictions, patterns, confidence, recommendation
        )
        
        return {
            'recommendation': recommendation,
            'predictions': predictions,
            'similar_cases': similar_cases[:5],
            'patterns': patterns,
            'confidence': confidence,
            'display': display,
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def _generate_data_driven_recommendation(self, predictions, patterns, confidence):
        """ìˆœìˆ˜ ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ ìƒì„±"""
        # ì¶”ì²œ ë¡œì§ (if-elseê°€ ì•„ë‹Œ ë°ì´í„° ê¸°ë°˜ ì„ê³„ê°’)
        score = 0
        
        # ì˜ˆì¸¡ ê¸°ë°˜ ì ìˆ˜
        if predictions['expected_additional_return'] > 0:
            score += predictions['expected_additional_return'] * 0.1
        else:
            score += predictions['expected_additional_return'] * 0.15  # ì†ì‹¤ì€ ê°€ì¤‘ì¹˜ ë†’ì„
            
        # íŒ¨í„´ ê¸°ë°˜ ì ìˆ˜
        score += (patterns['positive_ratio'] - 0.5) * 2
        
        # ì‹ ë¢°ë„ ë°˜ì˜
        score *= confidence['overall']
        
        # ìµœì¢… ì¶”ì²œ
        if score > 0.3:
            action = 'hold'
            message = f"ê³„ì† ë³´ìœ  ì¶”ì²œ (ì‹ ë¢°ë„ {confidence['overall']*100:.0f}%)"
        elif score < -0.3:
            action = 'sell'
            message = f"ë§¤ë„ ì¶”ì²œ (ì‹ ë¢°ë„ {confidence['overall']*100:.0f}%)"
        else:
            action = 'neutral'
            message = f"ì¤‘ë¦½ (ì‹ ë¢°ë„ {confidence['overall']*100:.0f}%)"
            
        return {
            'action': action,
            'score': score,
            'message': message,
            'confidence': confidence['overall']
        }
    
    def analyze_buy_situation(self, customer_id, stock_info, market_condition=None):
        """ë§¤ìˆ˜ ìƒí™© ì •êµí•œ AI ë¶„ì„"""
        
        # 1. ê³ ê° í˜„ì¬ ìƒíƒœ ë¶„ì„
        customer_state = self._analyze_customer_current_state(customer_id)
        
        # 2. ë§¤ìˆ˜ íŠ¹ì§• ë²¡í„° ìƒì„±
        buy_features = self._create_buy_feature_vector(customer_state, stock_info, market_condition)
        
        # 3. ìœ ì‚¬ ë§¤ìˆ˜ ìƒí™© ê²€ìƒ‰
        similar_buy_cases = self._find_similar_buy_cases(buy_features)
        
        # 4. ë§¤ìˆ˜ ê²°ê³¼ ì˜ˆì¸¡
        buy_predictions = self._predict_buy_outcome(buy_features)
        
        # 5. ë¦¬ìŠ¤í¬ íŒ¨í„´ ë¶„ì„
        risk_analysis = self._analyze_buy_risks(customer_state, similar_buy_cases, stock_info)
        
        # 6. ìµœì¢… ë¶„ì„ í†µí•©
        return self._integrate_buy_analysis(
            customer_state, similar_buy_cases, buy_predictions, risk_analysis, stock_info
        )
        
    def _analyze_customer_current_state(self, customer_id):
        """ê³ ê° í˜„ì¬ ìƒíƒœ ì •ë°€ ë¶„ì„"""
        customer_episodes = self.episodes_df[self.episodes_df['customer_id'] == customer_id]
        
        if len(customer_episodes) == 0:
            return {'new_customer': True, 'customer_id': customer_id}
            
        # ì‹œê°„ìˆœ ì •ë ¬
        customer_episodes = customer_episodes.sort_values('buy_timestamp')
        
        # ìµœê·¼ ê±°ë˜ ë¶„ì„
        recent_n = min(20, len(customer_episodes))
        recent_trades = customer_episodes.tail(recent_n)
        
        # ê³ ê¸‰ í†µê³„
        state = {
            'customer_id': customer_id,
            'total_trades': len(customer_episodes),
            'recent_performance': {
                'avg_return': recent_trades['return_rate'].mean(),
                'win_rate': (recent_trades['return_rate'] > 0).mean(),
                'std_return': recent_trades['return_rate'].std(),
                'sharpe_ratio': recent_trades['return_rate'].mean() / (recent_trades['return_rate'].std() + 1e-6)
            },
            'timing_analysis': {
                'avg_holding': recent_trades['holding_days'].mean(),
                'holding_consistency': 1 / (recent_trades['holding_days'].std() / recent_trades['holding_days'].mean() + 1),
                'last_trade_days_ago': (datetime.now() - pd.to_datetime(customer_episodes.iloc[-1]['sell_timestamp'])).days
            },
            'pattern_analysis': self._analyze_customer_patterns(recent_trades),
            'risk_metrics': self._calculate_risk_metrics(customer_episodes)
        }
        
        return state
    
    def _analyze_customer_patterns(self, recent_trades):
        """ê³ ê° ê±°ë˜ íŒ¨í„´ ì‹¬ì¸µ ë¶„ì„"""
        patterns = {}
        
        # ì—°ì† íŒ¨í„´
        returns = recent_trades['return_rate'].values
        consecutive_wins = 0
        consecutive_losses = 0
        
        for r in reversed(returns):
            if r > 0:
                if consecutive_losses == 0:
                    consecutive_wins += 1
                else:
                    break
            else:
                if consecutive_wins == 0:
                    consecutive_losses += 1
                else:
                    break
                    
        patterns['consecutive_wins'] = consecutive_wins
        patterns['consecutive_losses'] = consecutive_losses
        
        # ëª¨ë©˜í…€ ë¶„ì„
        if len(returns) >= 3:
            patterns['momentum'] = returns[-1] - returns[-3]
            patterns['trend'] = 'up' if returns[-1] > returns[-3] else 'down'
        
        return patterns
    
    def _calculate_risk_metrics(self, all_trades):
        """ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°"""
        returns = all_trades['return_rate'].values
        
        # ìµœëŒ€ ì†ì‹¤
        max_drawdown = np.min(returns) if len(returns) > 0 else 0
        
        # Value at Risk (VaR) - 95% ì‹ ë¢°ìˆ˜ì¤€
        if len(returns) > 20:
            var_95 = np.percentile(returns, 5)
        else:
            var_95 = np.min(returns) if len(returns) > 0 else 0
            
        # ì†ì‹¤ ë¹ˆë„
        loss_frequency = (returns < 0).mean() if len(returns) > 0 else 0.5
        
        return {
            'max_drawdown': max_drawdown,
            'var_95': var_95,
            'loss_frequency': loss_frequency,
            'risk_score': abs(max_drawdown) * loss_frequency
        }
    
    def _create_buy_feature_vector(self, customer_state, stock_info, market_condition):
        """ë§¤ìˆ˜ íŠ¹ì§• ë²¡í„° ìƒì„±"""
        if customer_state.get('new_customer'):
            # ì‹ ê·œ ê³ ê° ê¸°ë³¸ê°’
            features = {
                'buy_recent_avg_return': 0,
                'buy_recent_win_rate': 0.5,
                'buy_consecutive_wins': 0,
                'buy_consecutive_losses': 0,
                'buy_days_since_last_trade': 30,
                'buy_trading_frequency_30d': 0,
                'buy_active_positions': 0
            }
        else:
            features = {
                'buy_recent_avg_return': customer_state['recent_performance']['avg_return'],
                'buy_recent_win_rate': customer_state['recent_performance']['win_rate'],
                'buy_consecutive_wins': customer_state['pattern_analysis']['consecutive_wins'],
                'buy_consecutive_losses': customer_state['pattern_analysis']['consecutive_losses'],
                'buy_days_since_last_trade': customer_state['timing_analysis']['last_trade_days_ago'],
                'buy_trading_frequency_30d': min(customer_state['total_trades'], 30),
                'buy_active_positions': 0
            }
            
        # ì¶”ê°€ íŠ¹ì§•
        if market_condition:
            features.update({
                f'market_{k}': v for k, v in market_condition.items()
            })
            
        return features
    
    def _find_similar_buy_cases(self, buy_features):
        """ìœ ì‚¬ ë§¤ìˆ˜ ìƒí™© ê²€ìƒ‰"""
        # íŠ¹ì§• ë²¡í„° ì¤€ë¹„
        buy_cols = self.feature_columns['buy']
        current_vector = []
        
        for col in buy_cols:
            feature_name = col.replace('feature_', '')
            current_vector.append(buy_features.get(feature_name, 0))
            
        current_vector = np.array(current_vector).reshape(1, -1)
        current_scaled = self.buy_scaler.transform(current_vector)
        
        # 30ê°œ ì´ì›ƒ ì°¾ê¸°
        distances, indices = self.buy_situation_knn.kneighbors(current_scaled, n_neighbors=30)
        
        # ìƒì„¸ ì •ë³´ ì¶”ì¶œ
        similar_cases = []
        for dist, idx in zip(distances[0], indices[0]):
            situation = self.situations_df.iloc[idx]
            episode_id = situation['episode_id']
            
            # ê²°ê³¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            feature_row = self.features_df[self.features_df['episode_id'] == episode_id]
            if not feature_row.empty:
                feature_row = feature_row.iloc[0]
                
                similar_cases.append({
                    'similarity': 1 / (1 + dist),
                    'situation': situation,
                    'outcome': {
                        'return_rate': feature_row['outcome_return_rate'],
                        'holding_days': feature_row['outcome_holding_days'],
                        'profitable': feature_row['outcome_profitable']
                    }
                })
                
        return similar_cases
    
    def _predict_buy_outcome(self, buy_features):
        """ë§¤ìˆ˜ ê²°ê³¼ ì˜ˆì¸¡"""
        # ì „ì²´ íŠ¹ì§• ë²¡í„° êµ¬ì„± (ë§¤ìˆ˜ íŠ¹ì§• + ë‚˜ë¨¸ì§€ëŠ” í‰ê· ê°’)
        all_features = []
        for col in self.feature_columns['all']:
            if col in buy_features:
                all_features.append(buy_features[col])
            elif col.startswith('sell_'):
                all_features.append(0)  # ì•„ì§ ë§¤ë„í•˜ì§€ ì•ŠìŒ
            else:
                all_features.append(self.features_df[col].mean())
                
        X = np.array(all_features).reshape(1, -1)
        X_scaled = self.feature_scaler.transform(X)
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        predictions = {
            'expected_return': float(self.return_ensemble.predict(X_scaled)[0]),
            'success_probability': float(self.success_ensemble.predict_proba(X_scaled)[0][1]),
            'expected_holding_days': float(self.holding_predictor.predict(X_scaled)[0])
        }
        
        # ë¦¬ìŠ¤í¬ ì¡°ì • ìˆ˜ìµë¥ 
        if 'market_volatility' in buy_features:
            volatility = buy_features['market_volatility']
            predictions['risk_adjusted_return'] = predictions['expected_return'] / (volatility + 1)
        
        return predictions
    
    def _analyze_buy_risks(self, customer_state, similar_cases, stock_info):
        """ë§¤ìˆ˜ ë¦¬ìŠ¤í¬ íŒ¨í„´ ë¶„ì„"""
        risks = {
            'chase_buying': {'detected': False},
            'overtrading': {'detected': False},
            'concentration': {'detected': False},
            'tilt': {'detected': False}
        }
        
        # 1. ì¶”ê²©ë§¤ìˆ˜ íŒ¨í„´ (ë°ì´í„° ê¸°ë°˜)
        if stock_info.get('recent_return', 0) > 8:
            # ê¸‰ë“± í›„ ë§¤ìˆ˜í•œ ìœ ì‚¬ ì‚¬ë¡€ë“¤ì˜ ì„±ê³¼
            rally_cases = [c for c in similar_cases[:20] 
                          if c['situation'].get('feature_buy_recent_avg_return', 0) > 8]
            
            if len(rally_cases) >= 5:
                rally_success_rate = sum(1 for c in rally_cases if c['outcome']['profitable']) / len(rally_cases)
                rally_avg_return = np.mean([c['outcome']['return_rate'] for c in rally_cases])
                
                if rally_success_rate < 0.3:  # ë°ì´í„°ê°€ ë³´ì—¬ì£¼ëŠ” ë‚®ì€ ì„±ê³µë¥ 
                    risks['chase_buying'] = {
                        'detected': True,
                        'success_rate': rally_success_rate,
                        'avg_return': rally_avg_return,
                        'sample_size': len(rally_cases)
                    }
        
        # 2. ê³¼ì‰ë§¤ë§¤ íŒ¨í„´
        if not customer_state.get('new_customer'):
            if customer_state['total_trades'] > 50:  # ì¶©ë¶„í•œ ë°ì´í„°
                recent_frequency = customer_state['total_trades'] / max(
                    (datetime.now() - pd.to_datetime(
                        self.episodes_df[self.episodes_df['customer_id'] == customer_state['customer_id']].iloc[0]['buy_timestamp']
                    )).days, 1
                )
                if recent_frequency > 0.5:  # í•˜ë£¨ 0.5ê±´ ì´ìƒ
                    risks['overtrading'] = {
                        'detected': True,
                        'daily_frequency': recent_frequency
                    }
        
        return risks
    
    def _integrate_buy_analysis(self, customer_state, similar_cases, predictions, risks, stock_info):
        """ë§¤ìˆ˜ ë¶„ì„ ìµœì¢… í†µí•©"""
        
        # ìœ ì‚¬ ì‚¬ë¡€ í†µê³„
        success_cases = [c for c in similar_cases[:10] if c['outcome']['profitable']]
        similar_stats = {
            'success_rate': len(success_cases) / 10,
            'avg_return': np.mean([c['outcome']['return_rate'] for c in similar_cases[:10]]),
            'avg_holding': np.mean([c['outcome']['holding_days'] for c in similar_cases[:10]])
        }
        
        # ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ
        recommendation = self._generate_buy_recommendation(
            predictions, similar_stats, risks
        )
        
        # ë””ìŠ¤í”Œë ˆì´ í¬ë§·
        display = self._format_buy_display(
            stock_info, predictions, similar_stats, risks, recommendation
        )
        
        return {
            'recommendation': recommendation,
            'predictions': predictions,
            'similar_cases': similar_cases[:5],
            'statistics': similar_stats,
            'risks': risks,
            'customer_state': customer_state,
            'display': display,
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def _generate_buy_recommendation(self, predictions, similar_stats, risks):
        """ë°ì´í„° ê¸°ë°˜ ë§¤ìˆ˜ ì¶”ì²œ"""
        score = 0
        factors = []
        
        # ì˜ˆì¸¡ ê¸°ë°˜
        score += (predictions['success_probability'] - 0.5) * 2
        score += predictions['expected_return'] * 0.05
        
        # ìœ ì‚¬ ì‚¬ë¡€ ê¸°ë°˜
        score += (similar_stats['success_rate'] - 0.5) * 1.5
        
        # ë¦¬ìŠ¤í¬ ì°¨ê°
        if risks.get('chase_buying', {}).get('detected'):
            score -= 0.5
            factors.append("ì¶”ê²©ë§¤ìˆ˜ ìœ„í—˜")
        if risks.get('overtrading', {}).get('detected'):
            score -= 0.3
            factors.append("ê³¼ì‰ë§¤ë§¤ ê²½í–¥")
            
        # ìµœì¢… ì¶”ì²œ
        if score > 0.3:
            action = 'buy'
            message = f"ë§¤ìˆ˜ ì¶”ì²œ (ì ìˆ˜: {score:.2f})"
        elif score < -0.3:
            action = 'wait'
            message = f"ëŒ€ê¸° ì¶”ì²œ (ì ìˆ˜: {score:.2f})"
        else:
            action = 'neutral'
            message = f"ì‹ ì¤‘ ê²€í†  (ì ìˆ˜: {score:.2f})"
            
        return {
            'action': action,
            'score': score,
            'message': message,
            'factors': factors
        }
    
    def _format_sell_display(self, situation, similar_cases, predictions, patterns, confidence, recommendation):
        """ë§¤ë„ í™”ë©´ í¬ë§·"""
        if patterns.get('zone_6_8_pattern', {}).get('detected') and patterns['zone_6_8_pattern']['zone_positive_ratio'] > 0.7:
            # 6-8% êµ¬ê°„ íŠ¹ë³„ ë©”ì‹œì§€
            display = f"""â¸ï¸ ì ê¹! ë§¤ë„í•˜ê¸° ì „ì— í™•ì¸í•´ë³´ì„¸ìš”

ğŸ“Š í˜„ì¬ ìƒí™©: {situation.get('stock_name', 'ì¢…ëª©')} +{situation['current_return']:.1f}% ({situation['holding_days']}ì¼ ë³´ìœ )

ğŸ¤– AI ë¶„ì„: 6-8% êµ¬ê°„ íŒ¨í„´ ê°ì§€
ê³¼ê±° ì´ êµ¬ê°„ì—ì„œ {patterns['zone_6_8_pattern']['zone_positive_ratio']*100:.0f}%ê°€ ì¶”ê°€ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤.
í‰ê·  ë†“ì¹œ ìˆ˜ìµ: {patterns['zone_6_8_pattern']['zone_avg_missed']:.1f}%"""
        else:
            display = f"""ğŸ“Š ë§¤ë„ ë¶„ì„

í˜„ì¬ ìƒí™©: {situation.get('stock_name', 'ì¢…ëª©')} {situation['current_return']:+.1f}% ({situation['holding_days']}ì¼ ë³´ìœ )

ğŸ¤– AI ì˜ˆì¸¡:
- ì˜ˆìƒ ìµœì¢… ìˆ˜ìµë¥ : {predictions['expected_final_return']:.1f}%
- ì¶”ê°€ ìƒìŠ¹ ê°€ëŠ¥ì„±: {predictions['expected_additional_return']:+.1f}%
- ì‹ ë¢°ë„: {confidence['overall']*100:.0f}%"""
        
        # ìœ ì‚¬ ì‚¬ë¡€ ì¶”ê°€
        display += "\n\nğŸ“š ê³¼ê±° ìœ ì‚¬ ìƒí™©:"
        for i, case in enumerate(similar_cases, 1):
            display += f"""
[{i}] {case['episode']['sell_timestamp'][:10]} {case['episode']['isin']}
    ë§¤ë„: {case['features']['sell_current_return']:+.1f}% â†’ ìµœì¢…: {case['outcome']['final_return']:+.1f}%
    ë†“ì¹œ ìˆ˜ìµ: {case['outcome']['missed_profit']:+.1f}% (ìœ ì‚¬ë„: {case['similarity']*100:.0f}%)"""
        
        display += f"\n\nğŸ’¡ AI ì¶”ì²œ: {recommendation['message']}"
        
        return display
    
    def _format_buy_display(self, stock_info, predictions, stats, risks, recommendation):
        """ë§¤ìˆ˜ í™”ë©´ í¬ë§·"""
        if risks.get('chase_buying', {}).get('detected'):
            display = f"""ğŸ›‘ ë§¤ìˆ˜ ì „ ì ê²€

ğŸ“ˆ í˜„ì¬ ìƒí™©: {stock_info['name']} +{stock_info.get('recent_return', 0):.1f}% (ê¸‰ë“± ì¤‘)

ğŸ” AI íŒ¨í„´ ë¶„ì„:
ê³¼ê±° ì¶”ê²©ë§¤ìˆ˜ {risks['chase_buying']['sample_size']}ê±´ ë¶„ì„ ê²°ê³¼:
- ì„±ê³µë¥ : {risks['chase_buying']['success_rate']*100:.0f}%
- í‰ê·  ìˆ˜ìµë¥ : {risks['chase_buying']['avg_return']:.1f}%

âš ï¸ ë°ì´í„°ê°€ ë³´ì—¬ì£¼ëŠ” ë‚®ì€ ì„±ê³µë¥ ì…ë‹ˆë‹¤.

[ê·¸ë˜ë„ ë§¤ìˆ˜] [ê´€ì‹¬ì¢…ëª© ë“±ë¡] [ì¡°ì • ëŒ€ê¸°]"""
        else:
            display = f"""ğŸ“Š ë§¤ìˆ˜ ë¶„ì„

ì¢…ëª©: {stock_info['name']}

ğŸ¤– AI ì˜ˆì¸¡:
- ì„±ê³µ í™•ë¥ : {predictions['success_probability']*100:.0f}%
- ì˜ˆìƒ ìˆ˜ìµë¥ : {predictions['expected_return']:.1f}%
- ì˜ˆìƒ ë³´ìœ ê¸°ê°„: {predictions['expected_holding_days']:.0f}ì¼

ğŸ“ˆ ìœ ì‚¬ ê±°ë˜ í†µê³„:
- ì„±ê³µë¥ : {stats['success_rate']*100:.0f}%
- í‰ê·  ìˆ˜ìµë¥ : {stats['avg_return']:.1f}%

ğŸ’¡ AI ì¶”ì²œ: {recommendation['message']}

[ë§¤ìˆ˜ ì‹¤í–‰] [ë” ì§€ì¼œë³´ê¸°]"""
            
        return display
    
    def _get_customer_current_state(self, customer_id):
        """ê³ ê° í˜„ì¬ ìƒíƒœ ì¡°íšŒ"""
        customer_episodes = self.episodes_df[self.episodes_df['customer_id'] == customer_id]
        
        if len(customer_episodes) == 0:
            return {}
            
        # ìµœì‹  í†µê³„ ë°˜í™˜
        recent = customer_episodes.tail(10)
        return {
            'customer_avg_return': recent['return_rate'].mean(),
            'customer_win_rate': (recent['return_rate'] > 0).mean(),
            'customer_avg_holding': recent['holding_days'].mean()
        }
    
    def _print_model_summary(self):
        """ëª¨ë¸ ìš”ì•½ ì¶œë ¥"""
        print("\nğŸ“‹ ëª¨ë¸ ìš”ì•½:")
        print(f"   - KNN ì´ì›ƒ ìˆ˜: 30")
        print(f"   - ì•™ìƒë¸” ëª¨ë¸: XGBoost + LightGBM + CatBoost")
        print(f"   - íŠ¹ì§• ì°¨ì›: {len(self.feature_columns['all'])}ì°¨ì›")
        print(f"   - í•™ìŠµ ë°ì´í„°: {len(self.features_df):,}ê°œ ì—í”¼ì†Œë“œ")
        
    def save_models(self, path='models/sophisticated_ai'):
        """ëª¨ë¸ ì €ì¥"""
        import os
        os.makedirs(path, exist_ok=True)
        
        # ëª¨ë“  ëª¨ë¸ ì €ì¥
        models_to_save = {
            'buy_knn': self.buy_situation_knn,
            'sell_knn': self.sell_situation_knn,
            'return_ensemble': self.return_ensemble,
            'success_ensemble': self.success_ensemble,
            'holding_predictor': self.holding_predictor,
            'buy_scaler': self.buy_scaler,
            'sell_scaler': self.sell_scaler,
            'feature_scaler': self.feature_scaler
        }
        
        for name, model in models_to_save.items():
            joblib.dump(model, f'{path}/{name}.pkl')
            
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'trained_at': datetime.now().isoformat(),
            'feature_columns': self.feature_columns,
            'model_performance': self.model_performance,
            'data_stats': {
                'total_episodes': len(self.episodes_df),
                'total_features': len(self.feature_columns['all']),
                'total_customers': len(self.episodes_df['customer_id'].unique())
            }
        }
        
        with open(f'{path}/metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {path}")


# ë©”ì¸ ì‹¤í–‰
def main():
    """ì •êµí•œ AI ì‹œìŠ¤í…œ ì‹¤í–‰"""
    
    # AI ì´ˆê¸°í™”
    ai = SophisticatedTradingAI()
    
    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    DATA_PATH = "/content/generate_data"  # ê²½ë¡œ ìˆ˜ì • ê°€ëŠ¥
    
    # ë°ì´í„° ë¡œë“œ
    print("ğŸš€ ì •êµí•œ AI ê±°ë˜ ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œì‘\n")
    ai.load_all_data(
        f'{DATA_PATH}/episodes.csv',
        f'{DATA_PATH}/features.csv',
        f'{DATA_PATH}/situations.csv'
    )
    
    # ëª¨ë¸ í•™ìŠµ
    ai.train_all_models()
    
    # ëª¨ë¸ ì €ì¥
    ai.save_models()
    
    # ë°ëª¨
    print("\n" + "="*60)
    print("ğŸ’¡ AI ê±°ë˜ ì–´ì‹œìŠ¤í„´íŠ¸ ë°ëª¨")
    print("="*60)
    
    # ë§¤ë„ ìƒí™© ë°ëª¨
    print("\n### ì‹œë‚˜ë¦¬ì˜¤ 1: ë§¤ë„ ê²°ì • ###")
    sell_result = ai.analyze_sell_situation({
        'stock_name': 'ì‚¼ì„±ì „ì',
        'current_return': 6.8,
        'holding_days': 8,
        'customer_id': '00017496858921195E5A'
    })
    print(sell_result['display'])
    
    # ë§¤ìˆ˜ ìƒí™© ë°ëª¨
    print("\n\n### ì‹œë‚˜ë¦¬ì˜¤ 2: ë§¤ìˆ˜ ê²°ì • ###")
    buy_result = ai.analyze_buy_situation(
        customer_id='00017496858921195E5A',
        stock_info={
            'name': 'ì—”ë¹„ë””ì•„',
            'recent_return': 8.5
        },
        market_condition={
            'volatility': 0.25,
            'trend': 1
        }
    )
    print(buy_result['display'])


if __name__ == "__main__":
    main()