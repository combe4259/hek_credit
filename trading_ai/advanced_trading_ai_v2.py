# advanced_trading_ai_v2.py

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score, GridSearchCV
from sklearn.metrics import (accuracy_score, roc_auc_score, mean_squared_error, 
                           classification_report, confusion_matrix, precision_recall_curve)
from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as ImbPipeline
import pickle
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import json
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# ì‹œë“œ ê³ ì • (ì¬í˜„ì„± í™•ë³´)
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)
import random
random.seed(RANDOM_STATE)

class AdvancedTradingAI:

    def __init__(self):
        # ëª¨ë¸ë“¤  
        self.sell_probability_model = None      # ë§¤ë„ í™•ë¥  ì˜ˆì¸¡ (ê¸°ì¡´)
        self.action_classifier = None          # 3-Class ì•¡ì…˜ ì˜ˆì¸¡ (ìƒˆë¡œìš´!)
        self.ensemble_model = None             # ì•™ìƒë¸” ëª¨ë¸
        
        # ë°ì´í„° ì²˜ë¦¬
        self.scaler = RobustScaler()  # ì´ìƒì¹˜ì— ê°•í•œ ìŠ¤ì¼€ì¼ëŸ¬
        self.feature_scaler = StandardScaler()
        self.stock_encoder = LabelEncoder()
        self.sector_encoder = LabelEncoder()
        
        # ê°œì¸ ë§¤ë§¤ ì´ë ¥
        self.trading_history = []
        self.loss_patterns = []
        self.profit_patterns = defaultdict(list)
        
        # ì„¤ì •
        self.is_trained = False
        self.feature_names = None
        self.model_performance = {}
        self.random_state = RANDOM_STATE
        
        # ìµœì  ì„ê³„ê°’
        self.optimal_threshold = 0.5

    def _generate_loss_pattern_cases(self, df):
        """ê³¼ê±° ì†ì‹¤ íŒ¨í„´ ì‚¬ë¡€ ìƒì„±"""
        self.loss_patterns = [
            {
                'case_id': 'LOSS_001',
                'date': '2024-03-15',
                'stock': 'NVIDIA',
                'initial_loss': -0.042,
                'final_loss': -0.128,
                'holding_days': 15,
                'pattern_description': 'ì†ì‹¤ ìƒí™©ì—ì„œ í™€ë”© â†’ ì¶”ê°€ í•˜ë½',
                'market_condition': 'í•˜ë½ì¥',
                'similar_cases': ['LOSS_005', 'LOSS_012']
            }
        ]

    def load_trading_data(self, csv_path="../generate_data/output/trading_patterns_augmented.csv"):
        """generate_dataì—ì„œ ìƒì„±í•œ CSV ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“Š ë§¤ë§¤ íŒ¨í„´ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        try:
            df = pd.read_csv(csv_path)
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ ë ˆì½”ë“œ")
            
            # ë°ì´í„° ì „ì²˜ë¦¬
            df = self._preprocess_csv_data(df)
            return df
            
        except FileNotFoundError:
            print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
            print("ğŸ“Œ generate_data/main.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
            raise
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def _preprocess_csv_data(self, df):
        """CSV ë°ì´í„° ì „ì²˜ë¦¬ (generate_data í˜•ì‹ â†’ AI ëª¨ë¸ í˜•ì‹)"""
        print("ğŸ”„ ë°ì´í„° í˜•ì‹ ë³€í™˜ ì¤‘...")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ ë§¤í•‘
        processed_df = pd.DataFrame()
        
        # ê¸°ë³¸ ì •ë³´
        processed_df['user_id'] = df['investor_profile']
        processed_df['ticker'] = 'NVDA'
        processed_df['stock_name'] = 'NVIDIA'
        processed_df['sector'] = 'ì „ì'
        processed_df['market_cap'] = 'ëŒ€í˜•ì£¼'
        
        # ì‹œê°„ ì •ë³´ - ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì¶”ì •
        processed_df['buy_date'] = pd.to_numeric(df.get('timestamp', 0))
        
        # íˆ¬ìì í”„ë¡œí•„ë³„ ì¼ê´€ëœ ê±°ë˜ ì‹œê°„ íŒ¨í„´
        profile_time_map = {
            'Conservative': (10, 30),      # 10:30 - ì•ˆì •ì ì¸ ì‹œê°„
            'Aggressive': (9, 15),         # 9:15 - ì¥ ì´ˆë°˜
            'Technical_Trader': (11, 0),   # 11:00 - ì§€í‘œ í™•ì¸ í›„
            'Momentum_Trader': (14, 30),   # 14:30 - ëª¨ë©˜í…€ í™•ì¸
            'Swing_Trader': (13, 0)        # 13:00 - ì¤‘ê°„ ì‹œì 
        }
        
        # í”„ë¡œí•„ë³„ë¡œ ì‹œê°„ í• ë‹¹ (ë³€í˜• í”„ë¡œí•„ë„ ê¸°ë³¸ í”„ë¡œí•„ ì‹œê°„ ì‚¬ìš©)
        def get_trading_time(profile_name):
            base_profile = profile_name.split('_variant')[0]
            return profile_time_map.get(base_profile, (10, 0))
        
        processed_df['buy_hour'] = df['investor_profile'].apply(lambda x: get_trading_time(x)[0])
        processed_df['buy_minute'] = df['investor_profile'].apply(lambda x: get_trading_time(x)[1])
        
        # ì‹œì¥ ìƒí™© - ê¸°ìˆ ì  ì§€í‘œ ê¸°ë°˜ ì¶”ì •
        def estimate_market_condition(row):
            rsi = row.get('rsi', 50)
            macd_signal = row.get('macd_signal', 0)
            volatility = row.get('volatility_reaction', 0.5)
            
            # RSIì™€ MACDë¥¼ ì¢…í•©í•˜ì—¬ ì‹œì¥ ìƒí™© íŒë‹¨
            if rsi > 60 and macd_signal > 0:
                return 'ìƒìŠ¹ì¥'
            elif rsi < 40 and macd_signal < 0:
                return 'í•˜ë½ì¥'
            else:
                return 'íš¡ë³´ì¥'
        
        processed_df['market_condition'] = df.apply(estimate_market_condition, axis=1)
        
        # ë³´ìœ  ê¸°ê°„ - ì•¡ì…˜ê³¼ ìˆ˜ìµë¥  ê¸°ë°˜ ì¶”ì •
        def estimate_holding_days(row):
            action = row.get('action', 'HOLD')
            return_1d = row.get('return_1d', 0)
            return_7d = row.get('return_7d', 0)
            return_30d = row.get('return_30d', 0)
            
            # ìˆ˜ìµë¥  ë³€í™” íŒ¨í„´ìœ¼ë¡œ ë³´ìœ  ê¸°ê°„ ì¶”ì •
            if action == 'SELL':
                # ë§¤ë„í•œ ê²½ìš°, ìˆ˜ìµë¥ ì— ë”°ë¼ ë³´ìœ  ê¸°ê°„ ì¶”ì •
                if abs(return_1d) > 0.05:
                    return np.random.randint(1, 5)  # ë‹¨ê¸°
                elif abs(return_7d) > 0.1:
                    return np.random.randint(5, 15)  # ì¤‘ê¸°
                else:
                    return np.random.randint(15, 30)  # ì¥ê¸°
            elif action == 'BUY':
                return 1  # ë§¤ìˆ˜ëŠ” ì‹œì‘
            else:  # HOLD
                return np.random.randint(5, 20)  # ì¤‘ê°„ ì •ë„
        
        # ì‹œë“œ ê³ ì •ëœ ëœë¤ ìƒì„±
        np.random.seed(self.random_state)
        processed_df['holding_days'] = df.apply(estimate_holding_days, axis=1)
        
        # ê±°ë˜ ê²°ê³¼
        processed_df['final_profit_rate'] = df['return_1d'].fillna(0)
        processed_df['max_profit_rate'] = df[['return_1d', 'return_7d']].max(axis=1)
        processed_df['min_profit_rate'] = df[['return_1d', 'return_7d']].min(axis=1)
        processed_df['profit_volatility'] = df.get('volatility_reaction', 0.02)
        
        # ë§¤ë§¤ ê²°ì • - 3ê°€ì§€ ì•¡ì…˜ ëª¨ë‘ í•™ìŠµ! (ì—…ê·¸ë ˆì´ë“œ)
        # BUY=0, HOLD=1, SELL=2 (ì§„ì§œ 3-Class AI)
        action_mapping = {'BUY': 0, 'HOLD': 1, 'SELL': 2}
        processed_df['action_class'] = df['action'].map(action_mapping)
        
        # ê¸°ì¡´ ë§¤ë„ ì˜ˆì¸¡ë„ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
        processed_df['sold'] = (df['action'] == 'SELL').astype(int)
        
        print(f"\nğŸ¤– ì—…ê·¸ë ˆì´ë“œëœ AI í•™ìŠµ ëª¨ë“œ:")
        print(f"   - ì…ë ¥: ìˆœìˆ˜ ì‹œì¥ ë°ì´í„° (RSI, ìˆ˜ìµë¥ , ë³€ë™ì„± ë“±)")
        print(f"   - ì •ë‹µ: BUY(0), HOLD(1), SELL(2) - 3ê°€ì§€ ì•¡ì…˜ ëª¨ë‘!")
        print(f"   - AI ëª©í‘œ: 'ì–¸ì œ ë§¤ìˆ˜/ë³´ìœ /ë§¤ë„í•˜ëŠ”ì§€' íŒ¨í„´ í•™ìŠµ")
        
        # ì•¡ì…˜ ë¶„í¬ í™•ì¸
        action_counts = df['action'].value_counts()
        print(f"\nğŸ“ˆ ì•¡ì…˜ ë¶„í¬:")
        for action, count in action_counts.items():
            percentage = count / len(df) * 100
            print(f"   - {action}: {count:,}ê°œ ({percentage:.1f}%)")
        
        processed_df['sell_reason'] = df.get('reasoning', 'holding')
        
        # ìˆ˜ìµë¥  êµ¬ê°„ - ë¯¸ë˜ ì •ë³´ ì œê±°
        # processed_df['profit_zone'] = processed_df['final_profit_rate'].apply(self._get_profit_zone)
        
        # ì†ì‹¤ íŒ¨í„´ - ë¯¸ë˜ ì •ë³´ ì œê±°
        # processed_df['is_loss_pattern'] = (
        #     (processed_df['max_profit_rate'] > 0.05) &
        #     (processed_df['final_profit_rate'] < -0.05)
        # ).astype(int)
        
        print(f"âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {len(processed_df)}ê°œ ë ˆì½”ë“œ")
        
        # ë°ì´í„° í’ˆì§ˆ ì²´í¬
        print(f"\nğŸ” ë°ì´í„° í’ˆì§ˆ ì²´í¬:")
        print(f"   - ë§¤ë„ ë¹„ìœ¨: {processed_df['sold'].mean()*100:.1f}%")
        print(f"   - ìˆ˜ìµë¥  ë¶„í¬: í‰ê·  {processed_df['final_profit_rate'].mean():.3f}, í‘œì¤€í¸ì°¨ {processed_df['final_profit_rate'].std():.3f}")
        print(f"   - ë³´ìœ ê¸°ê°„ ë¶„í¬: í‰ê·  {processed_df['holding_days'].mean():.1f}ì¼")
        
        # ğŸ¯ ê¸°ìˆ ì  ì§€í‘œë“¤ ë³µì‚¬ (í•µì‹¬!)
        technical_indicators = ['rsi', 'macd_signal', 'bb_position', 'volume_ratio', 'daily_return', 'gap']
        for indicator in technical_indicators:
            if indicator in df.columns:
                processed_df[indicator] = df[indicator]
                print(f"âœ… {indicator} ë³µì‚¬ë¨")
            else:
                print(f"âš ï¸ {indicator} ëˆ„ë½")
        
        # ì†ì‹¤ íŒ¨í„´ ìƒì„±
        self._generate_loss_pattern_cases(processed_df)
        
        return processed_df

    def _get_profit_zone(self, profit_rate):
        """ìˆ˜ìµë¥  êµ¬ê°„ ë¶„ë¥˜"""
        if profit_rate < 0:
            return 'loss'
        elif profit_rate < 0.05:
            return '0-5%'
        elif profit_rate < 0.10:
            return '5-10%'
        elif profit_rate < 0.20:
            return '10-20%'
        else:
            return '20%+'

    def create_features(self, df):
        """ê³ ê¸‰ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§"""
        df = df.copy()
        
        # 1. ì‹œê°„ëŒ€ íŠ¹ì§•
        df['time_slot'] = pd.cut(df['buy_hour'],
                                 bins=[9, 10, 11, 13, 14, 16],
                                 labels=['morning', 'mid_morning', 'lunch',
                                         'afternoon', 'closing'])
        df['is_closing_hour'] = (df['buy_hour'] >= 14).astype(int)
        df['is_morning_hour'] = (df['buy_hour'] <= 10).astype(int)
        
        # 2. ìˆ˜ìµë¥  íŠ¹ì§• - ë¯¸ë˜ ì •ë³´ ì œê±°
        # df['profit_to_max_ratio'] = df['final_profit_rate'] / (df['max_profit_rate'] + 0.001)
        # df['drawdown'] = df['max_profit_rate'] - df['final_profit_rate']
        # df['profit_per_day'] = df['final_profit_rate'] / (df['holding_days'] + 1)
        # df['is_profitable'] = (df['final_profit_rate'] > 0).astype(int)
        
        # 3. ë³€ë™ì„± íŠ¹ì§• - ë¯¸ë˜ ì •ë³´ ì œê±°
        # df['volatility_ratio'] = df['profit_volatility'] / (abs(df['final_profit_rate']) + 0.001)
        # df['extreme_move'] = (abs(df['final_profit_rate']) > 0.1).astype(int)
        
        # 4. ì¢…ëª© íŠ¹ì§• ì¸ì½”ë”©
        df['sector_encoded'] = self.sector_encoder.fit_transform(df['sector'])
        df['market_cap_score'] = df['market_cap'].map({
            'ëŒ€í˜•ì£¼': 3, 'ì¤‘í˜•ì£¼': 2, 'ì†Œí˜•ì£¼': 1
        })
        
        # 5. ì‹œì¥ ìƒí™©
        df['market_condition_encoded'] = df['market_condition'].map({
            'ìƒìŠ¹ì¥': 1, 'íš¡ë³´ì¥': 0, 'í•˜ë½ì¥': -1
        })
        
        # 6. ë³´ìœ ê¸°ê°„ íŠ¹ì§•
        df['is_short_term'] = (df['holding_days'] < 5).astype(int)
        df['is_mid_term'] = ((df['holding_days'] >= 5) & (df['holding_days'] < 20)).astype(int)
        df['is_long_term'] = (df['holding_days'] >= 20).astype(int)
        
        # 7. ì¶”ê°€ íŠ¹ì§• (ê¸ˆìœµê³µí•™ì  ê´€ì ) - ë¯¸ë˜ ì •ë³´ ì œê±°
        # df['sharpe_ratio'] = df['profit_per_day'] / (df['profit_volatility'] + 0.001)
        # df['risk_adjusted_return'] = df['final_profit_rate'] / (df['profit_volatility'] + 0.001)
        
        # 8. ğŸ¯ ê¸°ìˆ ì  ì§€í‘œ ë³´ì¡´ í™•ì¸ (ì¤‘ìš”!)
        technical_indicators = ['rsi', 'macd_signal', 'bb_position', 'volume_ratio', 'daily_return', 'gap']
        missing_indicators = [ind for ind in technical_indicators if ind not in df.columns]
        if missing_indicators:
            print(f"âš ï¸ ê²½ê³ : ê¸°ìˆ ì  ì§€í‘œ ëˆ„ë½ - {missing_indicators}")
        else:
            print(f"âœ… ê¸°ìˆ ì  ì§€í‘œ ë³´ì¡´ë¨: {technical_indicators}")
        
        return df

    def train_models(self, test_size=0.2, csv_path="../generate_data/output/trading_patterns_augmented.csv"):
        """ëª¨ë“  ëª¨ë¸ í›ˆë ¨ (ê°œì„ ëœ ë²„ì „)"""
        print("ğŸ¤– ê³ ê¸‰ ë§¤ë§¤ íŒ¨í„´ AI ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        # CSV ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        df = self.load_trading_data(csv_path)
        df = self.create_features(df)
        
        # íŠ¹ì§• ì„ íƒ - ìˆœìˆ˜ ì‹œì¥ ë°ì´í„°ë§Œ (íˆ¬ìì ì„±í–¥ ë°ì´í„° ì œê±°, ì‹¤ì œ ì§€í‘œ ì¶”ê°€)
        # ğŸš¨ ë¯¸ë˜ ìˆ˜ìµë¥  ì •ë³´ ì œê±°! (final_profit_rate, max_profit_rate, min_profit_rate)
        # ğŸš¨ buy_minute ì œê±°! (ë„ˆë¬´ ì„¸ë°€í•œ ì •ë³´ë¡œ ê³¼ì í•© ìœ ë°œ)
        feature_cols = [
            # ê¸°ë³¸ ì‹œì¥ ì •ë³´
            'sector_encoded', 'market_cap_score', 'market_condition_encoded',
            
            # ì‹œê°„ ì •ë³´ (ë¶„ ë‹¨ìœ„ ì œì™¸)
            'buy_hour', 'is_closing_hour', 'is_morning_hour',
            
            # ë³€ë™ì„± ì •ë³´ë§Œ (ë¯¸ë˜ ì •ë³´ ì•„ë‹˜)
            'profit_volatility',
            
            # ğŸ¯ ì‹¤ì œ ê¸°ìˆ ì  ì§€í‘œë“¤ (í•µì‹¬ ì¶”ê°€!)
            'rsi',           # RSI ì§€í‘œ (ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„)
            'macd_signal',   # MACD ì‹ í˜¸ (0 ë˜ëŠ” 1)
            'bb_position',   # ë³¼ë¦°ì €ë°´ë“œ ìœ„ì¹˜ (0-1)
            'volume_ratio',  # ê±°ë˜ëŸ‰ ë¹„ìœ¨ (ê¸‰ì¦ ì—¬ë¶€)
            'daily_return',  # ì¼ì¼ ìˆ˜ìµë¥ 
            'gap',           # ê°­ ìƒìŠ¹/í•˜ë½
        ]
        
        # ë¨¼ì € processed_dfì—ì„œ ê¸°ë³¸ íŠ¹ì§•ë“¤ì„ ë§Œë“¤ê³  ë‚˜ì„œ feature_cols ì„¤ì •í•´ì•¼ í•¨
                
        print(f"\nğŸ“‹ ì‚¬ìš©í•  íŠ¹ì§•ë“¤:")
        for i, feature in enumerate(feature_cols, 1):
            print(f"   {i:2d}. {feature}")
        
        # ë””ë²„ê¹…: íŠ¹ì§• ìƒì„± í™•ì¸
        print(f"\nğŸ” íŠ¹ì§• ìƒì„± í™•ì¸:")
        print(f"   - ì „ì²´ ë°ì´í„°: {len(df)}ê°œ")
        print(f"   - ìµœì¢… íŠ¹ì§• ìˆ˜: {len(feature_cols)}ê°œ")
        print(f"   - ë°ì´í„° ëˆ„ìˆ˜ ì œê±° ì™„ë£Œ!")
        
        # âŒ ë¶ˆí•„ìš”í•œ ì¤‘ë³µ ì œê±° - ê¸°ìˆ ì  ì§€í‘œëŠ” ì´ë¯¸ feature_colsì— í¬í•¨ë¨
        # âŒ íˆ¬ìì ì„±í–¥ íŒ¨í„´ ì œê±° - ì˜ë¯¸ì—†ëŠ” ê°œì¸ì°¨ ë°ì´í„° (ì¼ë°˜í™” ë¶ˆê°€)
        
        # dfì—ì„œ ì¡´ì¬í•˜ëŠ” íŠ¹ì§•ë“¤ë§Œ ì„ íƒ
        available_features = [col for col in feature_cols if col in df.columns]
        print(f"\nâš ï¸ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ íŠ¹ì§•: {set(feature_cols) - set(available_features)}")
        
        X = df[available_features].copy()
        self.feature_names = X.columns.tolist()
        
        print(f"\nğŸ¤– ìµœì¢… AI ì…ë ¥ ë°ì´í„°:")
        print(f"   - íŠ¹ì§• ìˆ˜: {len(self.feature_names)}ê°œ")
        print(f"   - ë°ì´í„° í¬ê¸°: {X.shape}")
        print(f"   - ëˆ„ìˆ˜ ì œê±°: holding_days, is_short_term ë“± action ê¸°ë°˜ íŠ¹ì§• ëª¨ë‘ ì œê±°")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ - ë‘ ê°€ì§€ ì˜ˆì¸¡ ëª¨ë¸
        y_sell = df['sold'].astype(int)           # ê¸°ì¡´: ë§¤ë„ vs ë¹„ë§¤ë„
        y_action = df['action_class'].astype(int) # ìƒˆë¡œìš´: BUY/HOLD/SELL
        
        print(f"   - ë§¤ë„ ë°ì´í„°: {sum(y_sell)}ê°œ ({sum(y_sell)/len(y_sell)*100:.1f}%)")
        print(f"   - 3-Class ë°ì´í„°: BUY={sum(y_action==0)}, HOLD={sum(y_action==1)}, SELL={sum(y_action==2)}")
        
        # ì‹œê³„ì—´ ë¶„í•  (ê¸ˆìœµ ë°ì´í„°ì˜ íŠ¹ì„± ê³ ë ¤)
        tscv = TimeSeriesSplit(n_splits=5)
        
        # ë°ì´í„° ë¶„í•  - ëˆ„ìˆ˜ ì²´í¬
        print(f"\nğŸ“Š ë°ì´í„° ë¶„í•  ì „ ìµœì¢… ì²´í¬:")
        print(f"   - X ë³€ìˆ˜ë“¤: {list(X.columns)}")
        print(f"   - y ë³€ìˆ˜: ë§¤ë„={sum(y_sell)}, ë³´ìœ ={len(y_sell)-sum(y_sell)}")
        
        # ëˆ„ìˆ˜ ì²´í¬: action ê´€ë ¨ ì»¬ëŸ¼ì´ Xì— ìˆëŠ”ì§€ í™•ì¸
        leak_keywords = ['action', 'sell', 'buy', 'hold', 'sold']
        potential_leaks = [col for col in X.columns if any(keyword in col.lower() for keyword in leak_keywords)]
        if potential_leaks:
            print(f"   âš ï¸ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼: {potential_leaks}")
        else:
            print(f"   âœ… ëˆ„ìˆ˜ ì²´í¬ í†µê³¼!")
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_sell, test_size=test_size, random_state=self.random_state, stratify=y_sell
        )
        
        # SMOTE ì ìš©
        print("\nğŸ“Š ë°ì´í„° ê· í˜• ë§ì¶”ê¸°...")
        min_class_samples = min(sum(y_train == 0), sum(y_train == 1))
        
        if min_class_samples > 5:
            smote = SMOTE(random_state=self.random_state, k_neighbors=min(5, min_class_samples-1))
            X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
            print(f"   - SMOTE í›„: ë§¤ë„ {sum(y_train_balanced)}ê°œ, ë³´ìœ  {len(y_train_balanced)-sum(y_train_balanced)}ê°œ")
        else:
            X_train_balanced, y_train_balanced = X_train, y_train
            print("   - í´ë˜ìŠ¤ ìƒ˜í”Œì´ ë¶€ì¡±í•˜ì—¬ SMOTE ë¯¸ì ìš©")
        
        # ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scaler.fit_transform(X_train_balanced)
        X_test_scaled = self.scaler.transform(X_test)
        
        # 1. ê¸°ì¡´ ë§¤ë„ ëª¨ë¸ (Binary)
        print("\nâ³ 1ë²ˆì§¸ AI: ë§¤ë„ vs ë¹„ë§¤ë„ í•™ìŠµ...")
        
        self.sell_probability_model = xgb.XGBClassifier(
            n_estimators=100,        # 500â†’100 (ê³¼ì í•© ë°©ì§€)
            max_depth=4,             # 6â†’4 (ë‹¨ìˆœí™”)
            learning_rate=0.1,       # 0.03â†’0.1 
            subsample=0.8,
            colsample_bytree=0.8,
            min_child_weight=5,      # 3â†’5 (ë³´ìˆ˜ì )
            reg_alpha=0.5,           # 0.1â†’0.5 (ì •ê·œí™”)
            reg_lambda=2,            # 1â†’2 (ì •ê·œí™”)
            random_state=self.random_state,
            n_jobs=-1,
            objective='binary:logistic',
            eval_metric='logloss'
        )
        
        # ëª¨ë¸ í•™ìŠµ
        self.sell_probability_model.fit(
            X_train_scaled, 
            y_train_balanced,
            eval_set=[(X_test_scaled, y_test)],
            verbose=False
        )
        
        # 1ë²ˆì§¸ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        self._evaluate_model_performance(X_test_scaled, y_test, X_train_scaled, y_train_balanced)
        
        # ìµœì  ì„ê³„ê°’ ì°¾ê¸°
        self._find_optimal_threshold(X_test_scaled, y_test)
        
        # 2. ìƒˆë¡œìš´ 3-Class ì•¡ì…˜ ëª¨ë¸
        print("\nâ³ 2ë²ˆì§¸ AI: BUY/HOLD/SELL 3-Class í•™ìŠµ...")
        self._train_action_classifier(X, y_action, test_size)
        
        self.is_trained = True
        print("\nâœ… ëª¨ë“  ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        
        # íŠ¹ì§• ì¤‘ìš”ë„ ì¶œë ¥
        self._print_feature_importance()
        
        # âœ¨ ì‹¤ë¬´ ê²€ì¦: ì‹œê°„ ë¶„í•  í…ŒìŠ¤íŠ¸
        self._time_series_validation(X, y_sell)
        
        return True
    
    def _train_action_classifier(self, X, y_action, test_size):
        """ìƒˆë¡œìš´ 3-Class ì•¡ì…˜ ëª¨ë¸ í›ˆë ¨"""
        from sklearn.metrics import classification_report, confusion_matrix
        
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_action, test_size=test_size, random_state=self.random_state, stratify=y_action
        )
        
        # ìŠ¤ì¼€ì¼ë§ (ê¸°ì¡´ scaler ì‚¬ìš©)
        X_train_scaled = self.scaler.transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # 3-Class XGBoost ëª¨ë¸
        self.action_classifier = xgb.XGBClassifier(
            n_estimators=100,
            max_depth=4,
            learning_rate=0.1,
            random_state=self.random_state,
            n_jobs=-1,
            objective='multi:softprob',  # 3í´ë˜ìŠ¤ ë¶„ë¥˜
            num_class=3
        )
        
        # í•™ìŠµ
        self.action_classifier.fit(X_train_scaled, y_train)
        
        # ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€
        y_pred = self.action_classifier.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"\nğŸ† 3-Class AI ì„±ëŠ¥:")
        print(f"   - ì •í™•ë„: {accuracy:.3f}")
        
        # ë‹¤ì¤‘ë¶„ë¥˜ ë¦¬í¬íŠ¸
        class_names = ['BUY', 'HOLD', 'SELL']
        report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)
        
        print(f"\nğŸ“„ ê° ì•¡ì…˜ë³„ ì„±ëŠ¥:")
        for action in class_names:
            if action in report:
                metrics = report[action]
                print(f"   {action:4s}: ì •ë°€ë„ {metrics['precision']:.3f}, ì¬í˜„ë¥  {metrics['recall']:.3f}, F1 {metrics['f1-score']:.3f}")
        
        # í˜¼ë™í–‰ë ¬
        cm = confusion_matrix(y_test, y_pred)
        print(f"\nğŸ“ˆ 3-Class í˜¼ë™í–‰ë ¬:")
        print(f"        ì˜ˆì¸¡")
        print(f"       BUY HOLD SELL")
        for i, actual in enumerate(['BUY', 'HOLD', 'SELL']):
            if i < len(cm):
                print(f"{actual:4s} {cm[i][0] if 0 < len(cm[i]) else 0:4d} {cm[i][1] if 1 < len(cm[i]) else 0:4d} {cm[i][2] if 2 < len(cm[i]) else 0:4d}")
        
        # 3-Class íŠ¹ì§• ì¤‘ìš”ë„
        print(f"\nğŸ¯ 3-Class AIê°€ ì¤‘ìš”í•˜ê²Œ ë³´ëŠ” ìš”ì†Œ Top 5:")
        importances = self.action_classifier.feature_importances_
        feature_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        for idx, (_, row) in enumerate(feature_df.head(5).iterrows(), 1):
            print(f"   {idx}. {row['feature']}: {row['importance']:.1%}")
    
    def _time_series_validation(self, X, y):
        """ì‹œê°„ ë¶„í•  ê²€ì¦ - AIê°€ ì§„ì§œ í•™ìŠµí–ˆëŠ”ì§€ í™•ì¸"""
        print("\n" + "="*60)
        print("ğŸ“ˆ ì‹¤ë¬´ ê²€ì¦: ì‹œê°„ ë¶„í•  í…ŒìŠ¤íŠ¸")
        print("ğŸ¯ ëª©í‘œ: 'ê³¼ê±° ë°ì´í„°ë¡œ í•™ìŠµ â†’ ë¯¸ë˜ ë°ì´í„° ì˜ˆì¸¡'ì´ ê°€ëŠ¥í•œì§€ í™•ì¸")
        print("="*60)
        
        # ë°ì´í„°ë¥¼ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬ (ì´ë¯¸ ì‹œê°„ìˆœì´ë¼ê³  ê°€ì •)
        n_samples = len(X)
        
        # 70% ê³¼ê±° ë°ì´í„°ë¡œ í•™ìŠµ, 30% ë¯¸ë˜ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
        split_point = int(n_samples * 0.7)
        
        X_past = X.iloc[:split_point]
        y_past = y.iloc[:split_point]
        X_future = X.iloc[split_point:]
        y_future = y.iloc[split_point:]
        
        print(f"ğŸ“… ë°ì´í„° ë¶„í• :")
        print(f"   - ê³¼ê±° ë°ì´í„° (í•™ìŠµìš©): {len(X_past):,}ê°œ ({split_point}ë²ˆê¹Œì§€)")
        print(f"   - ë¯¸ë˜ ë°ì´í„° (í…ŒìŠ¤íŠ¸ìš©): {len(X_future):,}ê°œ ({split_point}ë²ˆë¶€í„°)")
        
        # ê³¼ê±° ë°ì´í„°ë¡œë§Œ ìƒˆë¡œìš´ ëª¨ë¸ í›ˆë ¨
        print(f"\nğŸ“ ê³¼ê±° ë°ì´í„°ë¡œ ìƒˆ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        scaler_past = RobustScaler()
        X_past_scaled = scaler_past.fit_transform(X_past)
        X_future_scaled = scaler_past.transform(X_future)
        
        # ê°„ë‹¨í•œ ëª¨ë¸ë¡œ í•™ìŠµ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´)
        past_model = xgb.XGBClassifier(
            n_estimators=50,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
            max_depth=4,
            learning_rate=0.1,
            random_state=self.random_state,
            n_jobs=-1
        )
        
        past_model.fit(X_past_scaled, y_past)
        
        # ë¯¸ë˜ ë°ì´í„°ë¡œ ì˜ˆì¸¡
        y_future_pred = past_model.predict(X_future_scaled)
        y_future_proba = past_model.predict_proba(X_future_scaled)[:, 1]
        
        # ì„±ëŠ¥ ë¹„êµ
        from sklearn.metrics import accuracy_score, roc_auc_score
        
        future_accuracy = accuracy_score(y_future, y_future_pred)
        future_auc = roc_auc_score(y_future, y_future_proba)
        
        # ê¸°ì¡´ ëª¨ë¸ ì„±ëŠ¥ (ëœë¤ ë¶„í• )
        original_auc = self.model_performance.get('auc_score', 0)
        original_accuracy = self.model_performance.get('accuracy', 0)
        
        print(f"\nğŸ“ˆ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼:")
        print(f"" + "-"*50)
        print(f"ğŸ² ê¸°ì¡´ ëª¨ë¸ (ëœë¤ ë¶„í• ):")
        print(f"   - AUC: {original_auc:.3f}")
        print(f"   - ì •í™•ë„: {original_accuracy:.3f}")
        print(f"")
        print(f"ğŸ“… ì‹œê°„ ë¶„í•  ëª¨ë¸ (ê³¼ê±°â†’ë¯¸ë˜):")
        print(f"   - AUC: {future_auc:.3f}")
        print(f"   - ì •í™•ë„: {future_accuracy:.3f}")
        print(f"" + "-"*50)
        
        # ì„±ëŠ¥ í•˜ë½ ê³„ì‚°
        auc_drop = original_auc - future_auc
        accuracy_drop = original_accuracy - future_accuracy
        
        print(f"ğŸ“‰ ì„±ëŠ¥ ë³€í™”:")
        print(f"   - AUC ë³€í™”: {auc_drop:+.3f} ({auc_drop/original_auc*100:+.1f}%)")
        print(f"   - ì •í™•ë„ ë³€í™”: {accuracy_drop:+.3f} ({accuracy_drop/original_accuracy*100:+.1f}%)")
        
        # ê²°ê³¼ í•´ì„
        print(f"\nğŸ§ ì‹¤ë¬´ í•´ì„:")
        
        if abs(auc_drop) < 0.05 and abs(accuracy_drop) < 0.05:
            print(f"   âœ… ìš°ìˆ˜: AIê°€ ì‹œê°„ì— ë¬´ê´€í•œ ì¼ë°˜í™”ëœ íŒ¨í„´ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤!")
            print(f"   â†’ ë¯¸ë˜ ë°ì´í„°ì—ë„ ë¹„ìŠ·í•œ ì„±ëŠ¥ ìœ ì§€")
        elif abs(auc_drop) < 0.1 and abs(accuracy_drop) < 0.1:
            print(f"   ğŸŸ¡ ì–‘í˜¸: ì•½ê°„ì˜ ì„±ëŠ¥ í•˜ë½ì´ ìˆì§€ë§Œ ìˆ˜ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€")
            print(f"   â†’ ì‹œì¥ í™˜ê²½ ë³€í™”ì— ì•½ê°„ ë¯¼ê°")
        elif abs(auc_drop) < 0.2:
            print(f"   ğŸŸ  ì£¼ì˜: ì„±ëŠ¥ í•˜ë½ì´ ìˆìŒ. ê³¼ì í•© ê°€ëŠ¥ì„±")
            print(f"   â†’ ë” ë§ì€ ë°ì´í„°ë‚˜ ì •ê·œí™” í•„ìš”")
        else:
            print(f"   ğŸ”´ ìœ„í—˜: ì‹¬ê°í•œ ì„±ëŠ¥ í•˜ë½. ê³¼ì í•© ì˜ì‹¬")
            print(f"   â†’ ëª¨ë¸ ì¬ì„¤ê³„ í•„ìš”")
        
        print(f"\nğŸ“Š ì¶”ê°€ ë¶„ì„:")
        
        # ë¯¸ë˜ ë°ì´í„°ì—ì„œì˜ íŠ¹ì§• ì¤‘ìš”ë„
        past_importance = past_model.feature_importances_
        original_importance = self.sell_probability_model.feature_importances_
        
        print(f"   - íŠ¹ì§• ì¤‘ìš”ë„ ì¼ê´€ì„±: {np.corrcoef(past_importance, original_importance)[0,1]:.3f}")
        print(f"     (ê°’ì´ 0.8 ì´ìƒì´ë©´ ì¼ê´€ëœ í•™ìŠµ íŒ¨í„´)")
        
        # ë¯¸ë˜ ë°ì´í„°ì˜ í´ë˜ìŠ¤ ë¶„í¬
        future_sell_rate = y_future.mean()
        past_sell_rate = y_past.mean()
        
        print(f"   - ê³¼ê±° ë§¤ë„ ë¹„ìœ¨: {past_sell_rate:.1%}")
        print(f"   - ë¯¸ë˜ ë§¤ë„ ë¹„ìœ¨: {future_sell_rate:.1%}")
        print(f"   - íŒ¨í„´ ë™ì¼ì„±: {'Yes' if abs(future_sell_rate - past_sell_rate) < 0.1 else 'No'}")
        
        print("\n" + "="*60)
        
        return {
            'future_auc': future_auc,
            'future_accuracy': future_accuracy,
            'auc_drop': auc_drop,
            'accuracy_drop': accuracy_drop,
            'feature_consistency': np.corrcoef(past_importance, original_importance)[0,1]
        }

    def _evaluate_model_performance(self, X_test, y_test, X_train, y_train):
        """ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© í‰ê°€"""
        # ì˜ˆì¸¡
        y_pred = self.sell_probability_model.predict(X_test)
        y_pred_proba = self.sell_probability_model.predict_proba(X_test)[:, 1]
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        auc_score = roc_auc_score(y_test, y_pred_proba)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"\nğŸ“ˆ AI í•™ìŠµ ê²°ê³¼:")
        print(f"   - AUC: {auc_score:.3f}")
        print(f"   - ì •í™•ë„: {accuracy:.3f}")
        
        # ì„±ëŠ¥ í‰ê°€
        if auc_score > 0.95:
            print("   âš ï¸ ê²½ê³ : AUC {:.3f} - ê³¼ì í•© ì˜ì‹¬! ë°ì´í„° ëˆ„ìˆ˜ ì²´í¬ í•„ìš”".format(auc_score))
        elif auc_score > 0.8:
            print("   âœ… ìš°ìˆ˜: ì¢‹ì€ ì„±ëŠ¥")
        elif auc_score > 0.6:
            print("   âœ… ì–‘í˜¸: í˜„ì‹¤ì ì¸ AI ì„±ëŠ¥")
        else:
            print("   âŒ ì£¼ì˜: ì„±ëŠ¥ ë¶€ì¡± - ë°ì´í„°ë‚˜ ëª¨ë¸ ê°œì„  í•„ìš”")
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(y_test, y_pred)
        print(f"\ní˜¼ë™ í–‰ë ¬:")
        print(f"   TN: {cm[0,0]}, FP: {cm[0,1]}")
        print(f"   FN: {cm[1,0]}, TP: {cm[1,1]}")
        
        # Precisionê³¼ Recall
        if cm[1,1] + cm[0,1] > 0:
            precision = cm[1,1] / (cm[1,1] + cm[0,1])
            print(f"   - Precision: {precision:.3f}")
        
        if cm[1,1] + cm[1,0] > 0:
            recall = cm[1,1] / (cm[1,1] + cm[1,0])
            print(f"   - Recall: {recall:.3f}")
        
        # êµì°¨ ê²€ì¦
        cv_scores = cross_val_score(
            self.sell_probability_model, 
            X_train, 
            y_train, 
            cv=5, 
            scoring='roc_auc',
            n_jobs=-1
        )
        print(f"\nğŸ”„ 5-Fold êµì°¨ ê²€ì¦ AUC: {cv_scores.mean():.3f} (Â±{cv_scores.std():.3f})")
        
        self.model_performance = {
            'auc_score': auc_score,
            'accuracy': accuracy,
            'cv_auc_mean': cv_scores.mean(),
            'cv_auc_std': cv_scores.std(),
            'confusion_matrix': cm.tolist()
        }

    def _find_optimal_threshold(self, X_test, y_test):
        """ìµœì  ì„ê³„ê°’ ì°¾ê¸°"""
        y_pred_proba = self.sell_probability_model.predict_proba(X_test)[:, 1]
        
        # Precision-Recall ê³¡ì„ ì—ì„œ ìµœì  ì„ê³„ê°’ ì°¾ê¸°
        precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)
        
        # F1 ìŠ¤ì½”ì–´ê°€ ìµœëŒ€ì¸ ì§€ì  ì°¾ê¸°
        f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)
        optimal_idx = np.argmax(f1_scores[:-1])
        self.optimal_threshold = thresholds[optimal_idx]
        
        print(f"\nğŸ¯ ìµœì  ì„ê³„ê°’: {self.optimal_threshold:.3f}")
        print(f"   - F1 Score: {f1_scores[optimal_idx]:.3f}")

    def _print_feature_importance(self):
        """ì£¼ìš” íŠ¹ì§• ì¤‘ìš”ë„ ì¶œë ¥"""
        if self.sell_probability_model and self.feature_names:
            print("\nğŸ“Š ë§¤ë„ ê²°ì • ì£¼ìš” ìš”ì¸ Top 10:")
            importance_df = pd.DataFrame({
                'feature': self.feature_names,
                'importance': self.sell_probability_model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            for _, row in importance_df.head(10).iterrows():
                print(f"   {row['feature']}: {row['importance']:.3f}")

    def predict_realtime(self,
                        ticker: str,
                        stock_name: str,
                        current_profit_rate: float,
                        holding_days: int,
                        current_time: str,
                        market_data: Dict,
                        user_history: Optional[Dict] = None) -> Dict:
        """ì‹¤ì‹œê°„ ë§¤ë§¤ ì˜ì‚¬ê²°ì • ì˜ˆì¸¡ (ê°œì„ ëœ ë²„ì „)"""
        if not self.is_trained:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì‹œë“œ ê³ ì •ìœ¼ë¡œ ì¼ê´€ëœ ì˜ˆì¸¡
        np.random.seed(self.random_state)
        
        # ì‹œê°„ íŒŒì‹±
        hour, minute = map(int, current_time.split(':'))
        
        # ê¸°ë³¸ íŠ¹ì§• ìƒì„±
        features = {
            'sector': market_data['sector'],
            'market_cap': market_data['market_cap'],
            'buy_hour': hour,
            'buy_minute': minute,
            'holding_days': holding_days,
            # ë¯¸ë˜ ì •ë³´ ì œê±° - ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œì—ëŠ” ë¯¸ë˜ë¥¼ ëª¨ë¦„
            # 'final_profit_rate': current_profit_rate,
            # 'max_profit_rate': max(current_profit_rate, current_profit_rate * 1.1),
            # 'min_profit_rate': min(0, current_profit_rate * 0.9),
            'profit_volatility': market_data.get('daily_volatility', 0.02),
            'market_condition': market_data['market_condition'],
            
            # ğŸ¯ ì‹¤ì‹œê°„ ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ (í•µì‹¬ ìˆ˜ì •!)
            'rsi': market_data.get('rsi', 50),                    # RSI ì§€í‘œ (ê¸°ë³¸ê°’: 50)
            'macd_signal': market_data.get('macd_signal', 0),     # MACD ì‹ í˜¸ (ê¸°ë³¸ê°’: 0)
            'bb_position': market_data.get('bb_position', 0.5),   # ë³¼ë¦°ì €ë°´ë“œ ìœ„ì¹˜ (ê¸°ë³¸ê°’: 0.5)
            'volume_ratio': market_data.get('volume_ratio', 1.0), # ê±°ë˜ëŸ‰ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 1.0)
            'daily_return': market_data.get('daily_return', 0),   # ì¼ì¼ ìˆ˜ìµë¥  (ê¸°ë³¸ê°’: 0)
            'gap': market_data.get('gap', 0)                      # ê°­ ìƒìŠ¹/í•˜ë½ (ê¸°ë³¸ê°’: 0)
        }
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§
        df = pd.DataFrame([features])
        # df['profit_zone'] = df['final_profit_rate'].apply(self._get_profit_zone)  # ë¯¸ë˜ ì •ë³´ ì œê±°
        df = self.create_features(df)
        
        # ì›-í•« ì¸ì½”ë”© ì¶”ê°€
        time_slot_dummies = pd.get_dummies(df['time_slot'], prefix='time')
        # profit_zone_dummies = pd.get_dummies(df['profit_zone'], prefix='zone')  # ë¯¸ë˜ ì •ë³´ ì œê±°
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = [col for col in self.feature_names if col in df.columns]
        X = pd.concat([df[numeric_cols], time_slot_dummies], axis=1)
        
        # ëª¨ë“  íŠ¹ì§•ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ëŠ” ê²ƒì€ 0ìœ¼ë¡œ ì±„ì›€
        for col in self.feature_names:
            if col not in X.columns:
                X[col] = 0
        X = X[self.feature_names]
        
        # ì˜ˆì¸¡
        X_scaled = self.scaler.transform(X)
        
        # ë§¤ë„ í™•ë¥  (ì¼ê´€ëœ ì˜ˆì¸¡)
        sell_probability = self.sell_probability_model.predict_proba(X_scaled)[0, 1]
        
        # ìµœì  ì„ê³„ê°’ ì‚¬ìš©
        sell_decision = sell_probability > self.optimal_threshold
        
        # 3-Class ì•¡ì…˜ ì˜ˆì¸¡ (BUY/HOLD/SELL)
        action_prediction = None
        if hasattr(self, 'action_classifier') and self.action_classifier is not None:
            action_proba = self.action_classifier.predict_proba(X_scaled)[0]
            action_pred = self.action_classifier.predict(X_scaled)[0]
            action_mapping = {0: 'BUY', 1: 'HOLD', 2: 'SELL'}
            
            action_prediction = {
                'BUY_prob': f"{action_proba[0]:.0%}",
                'HOLD_prob': f"{action_proba[1]:.0%}",
                'SELL_prob': f"{action_proba[2]:.0%}",
                'predicted_action': action_mapping[action_pred],
                'confidence': f"{max(action_proba):.0%}"
            }
        
        # ê³¼ê±° ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰
        similar_loss_pattern = self._find_similar_loss_pattern(
            stock_name, current_profit_rate, holding_days
        )
        
        # ì¢…í•© ë¶„ì„ ë° ì¶”ì²œ
        recommendation = self._generate_recommendation_v2(
            sell_probability, sell_decision, similar_loss_pattern, 
            current_profit_rate, holding_days
        )
        
        return {
            'ticker': ticker,
            'stock_name': stock_name,
            'current_status': {
                'profit_rate': f"{current_profit_rate:.1%}",
                'holding_days': f"{holding_days}ì¼",
                'time': current_time,
                'volatility': f"{market_data.get('daily_volatility', 0):.1%}"
            },
            'analysis': {
                'sell_probability': f"{sell_probability:.0%}",
                'optimal_threshold': f"{self.optimal_threshold:.0%}",
                'decision': 'ë§¤ë„' if sell_decision else 'ë³´ìœ ',
                'profit_zone': self._get_profit_zone(current_profit_rate),
                'similar_loss_pattern': similar_loss_pattern,
                'action_prediction': action_prediction
            },
            'recommendation': recommendation,
            'timestamp': datetime.now().isoformat()
        }

    def _find_similar_loss_pattern(self, stock_name, current_profit, holding_days):
        """ê³¼ê±° ìœ ì‚¬ ì†ì‹¤ íŒ¨í„´ ê²€ìƒ‰"""
        if current_profit >= 0:
            return None
        
        similar_patterns = []
        for pattern in self.loss_patterns:
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarity = 0
            
            # ì¢…ëª© ì¼ì¹˜
            if pattern['stock'] == stock_name:
                similarity += 0.3
            
            # ì†ì‹¤ë¥  ìœ ì‚¬ë„
            if abs(pattern['initial_loss'] - current_profit) < 0.02:
                similarity += 0.4
            
            # ë³´ìœ ê¸°ê°„ ìœ ì‚¬ë„
            if abs(pattern['holding_days'] - holding_days) < 5:
                similarity += 0.3
            
            if similarity > 0.6:
                similar_patterns.append({
                    'pattern': pattern,
                    'similarity': similarity
                })
        
        if similar_patterns:
            best_match = max(similar_patterns, key=lambda x: x['similarity'])
            return {
                'warning': f"âš ï¸ ìœ„í—˜ íŒ¨í„´ ê°ì§€",
                'message': f"ìœ ì‚¬í•œ ì†ì‹¤ íŒ¨í„´ ë°œê²¬ (ìœ ì‚¬ë„ {best_match['similarity']*100:.0f}%)",
                'case': best_match['pattern'],
                'recommendation': "ì¦‰ì‹œ ì†ì ˆ ê²€í† "
            }
        
        return None

    def _generate_recommendation_v2(self, sell_prob, sell_decision, loss_pattern, 
                                   current_profit, holding_days):
        """ì¢…í•© ì¶”ì²œ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        reasons = []
        action = "ë³´ìœ "
        urgency = "ë‚®ìŒ"
        
        # ë§¤ë„ ê²°ì • ê¸°ë°˜
        if sell_decision:
            action = "ë§¤ë„"
            if sell_prob > 0.8:
                urgency = "ë§¤ìš° ë†’ìŒ"
                reasons.append(f"ë§¤ìš° ë†’ì€ ë§¤ë„ í™•ë¥  ({sell_prob:.0%})")
            elif sell_prob > 0.6:
                urgency = "ë†’ìŒ"
                reasons.append(f"ë†’ì€ ë§¤ë„ í™•ë¥  ({sell_prob:.0%})")
            else:
                urgency = "ì¤‘ê°„"
                reasons.append(f"ì„ê³„ê°’ ì´ˆê³¼ ({sell_prob:.0%} > {self.optimal_threshold:.0%})")
        
        # ìˆ˜ìµë¥  ê¸°ë°˜ ì¶”ê°€ ë¶„ì„
        if current_profit > 0.15:
            reasons.append(f"ë†’ì€ ìˆ˜ìµë¥  ({current_profit:.1%}) - ì´ìµ ì‹¤í˜„ ê³ ë ¤")
            if action == "ë³´ìœ ":
                action = "ë§¤ë„ ê³ ë ¤"
                urgency = "ì¤‘ê°„"
        elif current_profit < -0.05:
            reasons.append(f"ì†ì‹¤ í™•ëŒ€ ì¤‘ ({current_profit:.1%})")
            if action == "ë³´ìœ ":
                action = "ì†ì ˆ ê³ ë ¤"
                urgency = "ì¤‘ê°„"
        
        # ì¥ê¸° ë³´ìœ 
        if holding_days > 30:
            reasons.append(f"ì¥ê¸° ë³´ìœ  ì¤‘ ({holding_days}ì¼)")
        
        # ì†ì‹¤ íŒ¨í„´
        if loss_pattern:
            action = "ì¦‰ì‹œ ì†ì ˆ"
            urgency = "ë§¤ìš° ë†’ìŒ"
            reasons.append(loss_pattern['message'])
        
        # ìµœì¢… ì¶”ì²œ
        emoji_map = {
            "ë§¤ìš° ë†’ìŒ": "ğŸ”´",
            "ë†’ìŒ": "ğŸŸ ",
            "ì¤‘ê°„": "ğŸŸ¡",
            "ë‚®ìŒ": "ğŸŸ¢"
        }
        
        return {
            'action': action,
            'urgency': urgency,
            'reasons': reasons[:3],  # ìµœëŒ€ 3ê°œ
            'summary': f"{emoji_map.get(urgency, 'ğŸŸ¡')} {action} ê¶Œì¥"
        }

    def save_model(self, filepath='trading_ai_model.pkl'):
        """ëª¨ë¸ ì €ì¥"""
        if not self.is_trained:
            raise ValueError("í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        model_data = {
            'sell_probability_model': self.sell_probability_model,
            'scaler': self.scaler,
            'feature_names': self.feature_names,
            'optimal_threshold': self.optimal_threshold,
            'model_performance': self.model_performance,
            'random_state': self.random_state,
            'action_classifier': getattr(self, 'action_classifier', None)  # 3-Class ëª¨ë¸
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filepath}")

    def load_model(self, filepath='trading_ai_model.pkl'):
        """ëª¨ë¸ ë¡œë“œ"""
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
        
        self.sell_probability_model = model_data['sell_probability_model']
        self.scaler = model_data['scaler']
        self.feature_names = model_data['feature_names']
        self.optimal_threshold = model_data['optimal_threshold']
        self.model_performance = model_data['model_performance']
        self.random_state = model_data['random_state']
        self.action_classifier = model_data.get('action_classifier', None)  # 3-Class ëª¨ë¸
        self.is_trained = True
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {filepath}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # AI ëª¨ë¸ ìƒì„± ë° í›ˆë ¨
    ai = AdvancedTradingAI()
    
    # CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œí•˜ì—¬ ëª¨ë¸ í›ˆë ¨
    try:
        ai.train_models(csv_path="../generate_data/output/trading_patterns_augmented.csv")
        
        # ëª¨ë¸ ì €ì¥
        ai.save_model('trained_trading_ai_v2.pkl')
        
        print("\n" + "="*60)
        print("ğŸ¯ ì‹¤ì‹œê°„ ë§¤ë§¤ ì˜ì‚¬ê²°ì • ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸")
        print("="*60)
        
        # ì‹œë‚˜ë¦¬ì˜¤ 1: NVIDIA +6.8% (ë³´ìœ  8ì¼ì°¨), 14:30
        result1 = ai.predict_realtime(
            ticker="NVDA",
            stock_name="NVIDIA",
            current_profit_rate=0.068,
            holding_days=8,
            current_time="14:30",
            market_data={
                'sector': 'ì „ì',
                'market_cap': 'ëŒ€í˜•ì£¼',
                'daily_volatility': 0.021,
                'market_condition': 'ìƒìŠ¹ì¥',
                # ğŸ¯ ì‹¤ì œ ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ (ì‹œë‚˜ë¦¬ì˜¤ 1: ìˆ˜ìµ ì¤‘)
                'rsi': 58,              # ì¤‘ë¦½ êµ¬ê°„
                'macd_signal': 1,       # ë§¤ìˆ˜ ì‹ í˜¸
                'bb_position': 0.65,    # ìƒë‹¨ ê·¼ì²˜
                'volume_ratio': 1.2,    # ê±°ë˜ëŸ‰ ì¦ê°€
                'daily_return': 0.015,  # 1.5% ìƒìŠ¹
                'gap': 0.008            # 0.8% ê°­ì—…
            }
        )
        
        print(f"\nğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ 1 - ìˆ˜ìµ ì¤‘")
        print(f"ì¢…ëª©: {result1['stock_name']} ({result1['ticker']})")
        print(f"í˜„ì¬ ìƒíƒœ: {result1['current_status']['profit_rate']} ({result1['current_status']['holding_days']})")
        print(f"ì‹œê°„: {result1['current_status']['time']}")
        print(f"\në¶„ì„:")
        print(f"  - ë§¤ë„ í™•ë¥ : {result1['analysis']['sell_probability']}")
        print(f"  - ì„ê³„ê°’: {result1['analysis']['optimal_threshold']}")
        print(f"  - ê²°ì •: {result1['analysis']['decision']}")
        print(f"\nì¶”ì²œ: {result1['recommendation']['summary']}")
        for reason in result1['recommendation']['reasons']:
            print(f"  - {reason}")
        
        # ì‹œë‚˜ë¦¬ì˜¤ 2: NVIDIA -4.2% (ë³´ìœ  15ì¼ì°¨), 10:30
        result2 = ai.predict_realtime(
            ticker="NVDA",
            stock_name="NVIDIA",
            current_profit_rate=-0.042,
            holding_days=15,
            current_time="10:30",
            market_data={
                'sector': 'ì „ì',
                'market_cap': 'ëŒ€í˜•ì£¼',
                'daily_volatility': 0.035,
                'market_condition': 'í•˜ë½ì¥',
                # ğŸ¯ ì‹¤ì œ ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ (ì‹œë‚˜ë¦¬ì˜¤ 2: ì†ì‹¤ ì¤‘)
                'rsi': 35,              # ê³¼ë§¤ë„ êµ¬ê°„
                'macd_signal': 0,       # ë§¤ë„ ì‹ í˜¸
                'bb_position': 0.25,    # í•˜ë‹¨ ê·¼ì²˜
                'volume_ratio': 1.8,    # ê±°ë˜ëŸ‰ ê¸‰ì¦ (ê³µí¬ë§¤ë„)
                'daily_return': -0.025, # -2.5% í•˜ë½
                'gap': -0.012           # -1.2% ê°­ë‹¤ìš´  
            }
        )
        
        print(f"\n\nğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ 2 - ì†ì‹¤ ì¤‘")
        print(f"ì¢…ëª©: {result2['stock_name']} ({result2['ticker']})")
        print(f"í˜„ì¬ ìƒíƒœ: {result2['current_status']['profit_rate']} ({result2['current_status']['holding_days']})")
        print(f"ì‹œê°„: {result2['current_status']['time']}")
        print(f"\në¶„ì„:")
        print(f"  - ë§¤ë„ í™•ë¥ : {result2['analysis']['sell_probability']}")
        print(f"  - ì„ê³„ê°’: {result2['analysis']['optimal_threshold']}")
        print(f"  - ê²°ì •: {result2['analysis']['decision']}")
        print(f"\nì¶”ì²œ: {result2['recommendation']['summary']}")
        for reason in result2['recommendation']['reasons']:
            print(f"  - {reason}")
            
    except FileNotFoundError:
        print("\nâŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ“Œ ë¨¼ì € generate_data í´ë”ì—ì„œ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:")
        print("   cd ../generate_data")
        print("   python main.py")