#!/usr/bin/env python3
"""
ì •êµí•œ AI ê±°ë˜ ì–´ì‹œìŠ¤í„´íŠ¸ - ê³¼ì í•© ë¬¸ì œ í•´ê²° ë²„ì „
- customer_id ê¸°ë°˜ íŠ¹ì§• ì œê±°
- isin ê¸°ë°˜ íŠ¹ì§• ì œê±°
- ë¯¸ë˜ ì •ë³´ ì‚¬ìš© ì œê±°
- ì¼ë°˜í™” ê°€ëŠ¥í•œ íŒ¨í„´ë§Œ í•™ìŠµ
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.neighbors import NearestNeighbors
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, precision_recall_fscore_support
from sklearn.ensemble import VotingRegressor, VotingClassifier
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostRegressor, CatBoostClassifier
from datetime import datetime
import joblib
import json
import warnings
warnings.filterwarnings('ignore')


class SophisticatedTradingAI:
    """ê³¼ì í•© ë¬¸ì œë¥¼ í•´ê²°í•œ ì •êµí•œ AI ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # ë°ì´í„° ì €ì¥ì†Œ
        self.episodes_df = None
        self.features_df = None
        self.situations_df = None
        
        # KNN ëª¨ë¸ (ìœ ì‚¬ ìƒí™© ê²€ìƒ‰)
        self.buy_situation_knn = NearestNeighbors(
            n_neighbors=30,
            metric='minkowski',
            p=2,
            algorithm='ball_tree',
            leaf_size=30
        )
        
        self.sell_situation_knn = NearestNeighbors(
            n_neighbors=30,
            metric='cosine',
            algorithm='brute'
        )
        
        # ì•™ìƒë¸” ì˜ˆì¸¡ ëª¨ë¸ë“¤
        self._initialize_ensemble_models()
        
        # ìŠ¤ì¼€ì¼ëŸ¬
        self.buy_scaler = RobustScaler()
        self.sell_scaler = RobustScaler()
        self.feature_scaler = StandardScaler()
        
        # ë©”íƒ€ ì •ë³´
        self.feature_columns = {}
        self.model_performance = {}
        self.feature_importance_all = {}
        
    def _initialize_ensemble_models(self):
        """ì•™ìƒë¸” ëª¨ë¸ ì´ˆê¸°í™”"""
        # ìˆ˜ìµë¥  ì˜ˆì¸¡ ì•™ìƒë¸”
        self.return_ensemble = VotingRegressor([
            ('xgb', xgb.XGBRegressor(
                n_estimators=300,
                max_depth=6,
                learning_rate=0.05,
                subsample=0.7,
                colsample_bytree=0.7,
                random_state=42
            )),
            ('lgb', lgb.LGBMRegressor(
                n_estimators=300,
                num_leaves=20,
                learning_rate=0.05,
                feature_fraction=0.7,
                bagging_fraction=0.7,
                bagging_freq=5,
                random_state=42,
                verbose=-1
            )),
            ('cat', CatBoostRegressor(
                iterations=300,
                depth=5,
                learning_rate=0.05,
                random_state=42,
                verbose=False
            ))
        ])
        
        # ì„±ê³µ í™•ë¥  ì˜ˆì¸¡ ì•™ìƒë¸”
        self.success_ensemble = VotingClassifier([
            ('xgb', xgb.XGBClassifier(
                n_estimators=300,
                max_depth=5,
                learning_rate=0.05,
                subsample=0.7,
                colsample_bytree=0.7,
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )),
            ('lgb', lgb.LGBMClassifier(
                n_estimators=300,
                num_leaves=20,
                learning_rate=0.05,
                feature_fraction=0.7,
                bagging_fraction=0.7,
                bagging_freq=5,
                random_state=42,
                verbose=-1
            )),
            ('cat', CatBoostClassifier(
                iterations=300,
                depth=5,
                learning_rate=0.05,
                random_state=42,
                verbose=False
            ))
        ], voting='soft')
        
        # ë³´ìœ  ê¸°ê°„ ì˜ˆì¸¡ ëª¨ë¸
        self.holding_predictor = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=5,
            learning_rate=0.05,
            random_state=42
        )
        
    def load_all_data(self, episodes_path, features_path, situations_path):
        """3ê°œ ë°ì´í„°ì…‹ í†µí•© (ê³¼ì í•© íŠ¹ì§• ì œê±°)"""
        print("ğŸ“Š ë°ì´í„° ë¡œë”© ë° ê²€ì¦ ì¤‘...")
        
        # 1. ë°ì´í„° ë¡œë“œ
        self.episodes_df = pd.read_csv(episodes_path)
        self.features_df = pd.read_csv(features_path)
        self.situations_df = pd.read_csv(situations_path)
        
        # 2. ë°ì´í„° íƒ€ì… ìµœì í™”
        self._optimize_data_types()
        
        # 3. ê³¼ì í•© íŠ¹ì§• ì œê±°
        self._remove_overfitting_features()
        
        # 4. ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
        self._validate_data_integrity()
        
        # 5. ì¼ë°˜í™” ê°€ëŠ¥í•œ íŠ¹ì§•ë§Œ ìƒì„±
        self._create_generalizable_features()
        
        print(f"\nâœ… ë°ì´í„° í†µí•© ì™„ë£Œ:")
        print(f"   - ì—í”¼ì†Œë“œ: {len(self.episodes_df):,}ê°œ")
        print(f"   - íŠ¹ì§• ì°¨ì›: {len(self.feature_columns['all'])}ê°œ")
        print(f"   - ìƒí™©: {len(self.situations_df):,}ê°œ")
        
    def _optimize_data_types(self):
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•œ ë°ì´í„° íƒ€ì… ìµœì í™”"""
        for df in [self.episodes_df, self.features_df, self.situations_df]:
            for col in df.columns:
                if df[col].dtype == 'float64':
                    df[col] = df[col].astype('float32')
                elif df[col].dtype == 'int64':
                    if df[col].min() >= 0 and df[col].max() < 65535:
                        df[col] = df[col].astype('uint16')
                        
    def _remove_overfitting_features(self):
        """ê³¼ì í•© ìœ ë°œ íŠ¹ì§• ì œê±°"""
        print("ğŸ§¹ ê³¼ì í•© íŠ¹ì§• ì œê±° ì¤‘...")
        
        # 1. customer_id ê´€ë ¨ íŠ¹ì§• ì œê±°
        customer_cols = [col for col in self.features_df.columns if 'customer' in col.lower()]
        print(f"   - customer_id ê´€ë ¨ {len(customer_cols)}ê°œ ì»¬ëŸ¼ ì œê±°")
        
        # 2. isin ê´€ë ¨ íŠ¹ì§• ì œê±°
        isin_cols = [col for col in self.features_df.columns if 'isin' in col.lower()]
        print(f"   - isin ê´€ë ¨ {len(isin_cols)}ê°œ ì»¬ëŸ¼ ì œê±°")
        
        # 3. ë¯¸ë˜ ì •ë³´ë¥¼ í¬í•¨í•œ íŠ¹ì§• ì œê±°
        future_cols = ['outcome_return_rate', 'outcome_holding_days', 'outcome_profitable',
                      'global_avg_return', 'global_win_rate', 'global_avg_holding']
        future_cols.extend([col for col in self.features_df.columns if 'outcome_' in col])
        future_cols.extend([col for col in self.features_df.columns if 'global_' in col])
        
        # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì œê±°
        cols_to_remove = set()
        for col in customer_cols + isin_cols + future_cols:
            if col in self.features_df.columns:
                cols_to_remove.add(col)
                
        print(f"   - ë¯¸ë˜ ì •ë³´ {len([c for c in future_cols if c in self.features_df.columns])}ê°œ ì»¬ëŸ¼ ì œê±°")
        
        # situations_dfì—ì„œë„ ì œê±°
        if 'customer_id' in self.situations_df.columns:
            self.situations_df = self.situations_df.drop(columns=['customer_id'])
        if 'isin' in self.situations_df.columns:
            self.situations_df = self.situations_df.drop(columns=['isin'])
            
        print(f"   - ì´ {len(cols_to_remove)}ê°œ ê³¼ì í•© íŠ¹ì§• ì œê±°")
        
    def _validate_data_integrity(self):
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        # episode_id ì¼ê´€ì„± ê²€ì‚¬
        episodes_in_features = set(self.features_df['episode_id'].unique())
        episodes_in_situations = set(self.situations_df['episode_id'].unique())
        episodes_in_episodes = set(self.episodes_df['episode_id'].unique())
        
        common_episodes = episodes_in_episodes & episodes_in_features
        print(f"   - ê²€ì¦: {len(common_episodes):,}ê°œ ì—í”¼ì†Œë“œ ë§¤ì¹­ í™•ì¸")
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        for df in [self.features_df, self.situations_df]:
            missing_ratio = df.isnull().sum() / len(df)
            high_missing_cols = missing_ratio[missing_ratio > 0.5].index
            
            if len(high_missing_cols) > 0:
                print(f"   - ê²½ê³ : {len(high_missing_cols)}ê°œ ì»¬ëŸ¼ì— 50% ì´ìƒ ê²°ì¸¡ê°’")
                for col in high_missing_cols:
                    df[f'{col}_is_missing'] = df[col].isnull().astype(int)
                    
    def _create_generalizable_features(self):
        """ì¼ë°˜í™” ê°€ëŠ¥í•œ íŠ¹ì§•ë§Œ ìƒì„±"""
        print("ğŸ”§ ì¼ë°˜í™” ê°€ëŠ¥í•œ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§ ì¤‘...")
        
        # 1. ì‹œì¥ ìƒí™© íŠ¹ì§• (ë‚ ì§œë³„, ê°œì¸ ì •ë³´ ì—†ì´)
        market_features = self._calculate_market_features_without_identity()
        
        # 2. ìƒëŒ€ì  íŠ¹ì§• (ì „ì²´ ëŒ€ë¹„, ê°œì¸ ì •ë³´ ì—†ì´)
        relative_features = self._calculate_relative_features_without_identity()
        
        # 3. ì‹œê°„ íŒ¨í„´ íŠ¹ì§• (ìš”ì¼, ì›”, ê³„ì ˆ ë“±)
        temporal_features = self._calculate_temporal_features()
        
        # 4. ê¸°ìˆ ì  ì§€í‘œ ìŠ¤íƒ€ì¼ íŠ¹ì§•
        technical_features = self._calculate_technical_style_features()
        
        # íŠ¹ì§• í†µí•©
        self._merge_generalizable_features(
            market_features,
            relative_features,
            temporal_features,
            technical_features
        )
        
        # íŠ¹ì§• ì»¬ëŸ¼ ì €ì¥ (outcome ë³€ìˆ˜ í™•ì‹¤íˆ ì œì™¸)
        exclude_cols = {'episode_id', 'customer_id', 'isin'}
        exclude_cols.update({col for col in self.features_df.columns if 'outcome' in col})
        exclude_cols.update({col for col in self.features_df.columns if 'customer' in col})
        exclude_cols.update({col for col in self.features_df.columns if 'isin' in col})
        
        self.feature_columns = {
            'buy': [col for col in self.situations_df.columns if col.startswith('feature_')],
            'sell': [col for col in self.features_df.columns if col not in exclude_cols],
            'all': [col for col in self.features_df.columns if col not in exclude_cols]
        }
        
        print(f"   - ì‚¬ìš©í•  íŠ¹ì§• ìˆ˜: {len(self.feature_columns['all'])}ê°œ")
        
    def _calculate_market_features_without_identity(self):
        """ê°œì¸ ì •ë³´ ì—†ëŠ” ì‹œì¥ íŠ¹ì§• ê³„ì‚°"""
        # ë‚ ì§œë³„ ì‹œì¥ ì „ì²´ í†µê³„ (ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©)
        self.episodes_df['date'] = pd.to_datetime(self.episodes_df['buy_timestamp']).dt.date
        
        market_stats = {}
        unique_dates = sorted(self.episodes_df['date'].unique())
        
        for i, date in enumerate(unique_dates):
            # í•´ë‹¹ ë‚ ì§œ ì´ì „ì˜ ë°ì´í„°ë§Œ ì‚¬ìš©
            past_data = self.episodes_df[self.episodes_df['date'] < date]
            
            if len(past_data) > 10:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ
                market_stats[date] = {
                    'market_avg_return_7d': past_data.tail(7)['return_rate'].mean() if len(past_data) > 7 else 0,
                    'market_volatility_7d': past_data.tail(7)['return_rate'].std() if len(past_data) > 7 else 0,
                    'market_avg_return_30d': past_data.tail(30)['return_rate'].mean() if len(past_data) > 30 else 0,
                    'market_volatility_30d': past_data.tail(30)['return_rate'].std() if len(past_data) > 30 else 0,
                }
            else:
                market_stats[date] = {
                    'market_avg_return_7d': 0,
                    'market_volatility_7d': 10,
                    'market_avg_return_30d': 0,
                    'market_volatility_30d': 10,
                }
                
        return market_stats
    
    def _calculate_relative_features_without_identity(self):
        """ê°œì¸ ì •ë³´ ì—†ëŠ” ìƒëŒ€ì  íŠ¹ì§• ê³„ì‚°"""
        # ì „ì²´ ì‹œì¥ ëŒ€ë¹„ ìƒëŒ€ì  ìœ„ì¹˜ (ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©)
        relative_features = []
        
        for idx, row in self.features_df.iterrows():
            episode = self.episodes_df[self.episodes_df['episode_id'] == row['episode_id']].iloc[0]
            buy_date = pd.to_datetime(episode['buy_timestamp']).date()
            
            # í•´ë‹¹ ë‚ ì§œ ì´ì „ 30ì¼ ë°ì´í„°
            past_episodes = self.episodes_df[
                pd.to_datetime(self.episodes_df['buy_timestamp']).dt.date < buy_date
            ].tail(100)
            
            if len(past_episodes) > 10:
                # í˜„ì¬ ê°’ì˜ ìƒëŒ€ì  ìœ„ì¹˜
                relative_features.append({
                    'return_vs_market_avg': row['current_return'] / (past_episodes['return_rate'].mean() + 1e-6),
                    'holding_vs_market_avg': row['holding_days'] / (past_episodes['holding_days'].mean() + 1e-6),
                    'return_percentile_market': (past_episodes['return_rate'] < row['current_return']).mean(),
                    'holding_percentile_market': (past_episodes['holding_days'] < row['holding_days']).mean()
                })
            else:
                relative_features.append({
                    'return_vs_market_avg': 1.0,
                    'holding_vs_market_avg': 1.0,
                    'return_percentile_market': 0.5,
                    'holding_percentile_market': 0.5
                })
                
        return pd.DataFrame(relative_features)
    
    def _calculate_temporal_features(self):
        """ì‹œê°„ ê´€ë ¨ íŠ¹ì§• ê³„ì‚°"""
        temporal_features = []
        
        for _, episode in self.episodes_df.iterrows():
            buy_time = pd.to_datetime(episode['buy_timestamp'])
            sell_time = pd.to_datetime(episode['sell_timestamp'])
            
            temporal_features.append({
                'buy_day_of_week': buy_time.dayofweek,
                'buy_month': buy_time.month,
                'buy_quarter': buy_time.quarter,
                'buy_is_month_start': buy_time.day <= 5,
                'buy_is_month_end': buy_time.day >= 25,
                'sell_day_of_week': sell_time.dayofweek,
                'holding_over_weekend': (sell_time - buy_time).days // 7,
                'holding_weekdays': np.busday_count(buy_time.date(), sell_time.date())
            })
            
        return pd.DataFrame(temporal_features)
    
    def _calculate_technical_style_features(self):
        """ê¸°ìˆ ì  ì§€í‘œ ìŠ¤íƒ€ì¼ íŠ¹ì§•"""
        technical_features = []
        
        for _, row in self.features_df.iterrows():
            # ìˆ˜ìµë¥  êµ¬ê°„í™” (ê¸°ìˆ ì  ë¶„ì„ ìŠ¤íƒ€ì¼)
            return_rate = row['current_return']
            holding_days = row['holding_days']
            
            features = {
                # ìˆ˜ìµë¥  êµ¬ê°„
                'return_zone_negative': 1 if return_rate < 0 else 0,
                'return_zone_0_3': 1 if 0 <= return_rate < 3 else 0,
                'return_zone_3_5': 1 if 3 <= return_rate < 5 else 0,
                'return_zone_5_10': 1 if 5 <= return_rate < 10 else 0,
                'return_zone_10_plus': 1 if return_rate >= 10 else 0,
                
                # ë³´ìœ ê¸°ê°„ êµ¬ê°„
                'holding_zone_short': 1 if holding_days < 7 else 0,
                'holding_zone_medium': 1 if 7 <= holding_days < 30 else 0,
                'holding_zone_long': 1 if 30 <= holding_days < 90 else 0,
                'holding_zone_very_long': 1 if holding_days >= 90 else 0,
                
                # ìˆ˜ìµë¥ /ì¼ íš¨ìœ¨ì„±
                'daily_return_efficiency': return_rate / max(holding_days, 1),
                'is_quick_profit': 1 if return_rate > 5 and holding_days < 7 else 0,
                'is_slow_profit': 1 if return_rate > 5 and holding_days > 30 else 0
            }
            
            technical_features.append(features)
            
        return pd.DataFrame(technical_features)
    
    def _merge_generalizable_features(self, market_features, relative_features, temporal_features, technical_features):
        """ì¼ë°˜í™” ê°€ëŠ¥í•œ íŠ¹ì§•ë“¤ ë³‘í•©"""
        # features_dfì— ì¶”ê°€
        for col in relative_features.columns:
            self.features_df[col] = relative_features[col]
            
        for col in technical_features.columns:
            self.features_df[col] = technical_features[col]
            
        # episodes_dfì˜ ë‚ ì§œë³„ë¡œ market features ë§¤í•‘
        for _, row in self.features_df.iterrows():
            episode = self.episodes_df[self.episodes_df['episode_id'] == row['episode_id']].iloc[0]
            date = pd.to_datetime(episode['buy_timestamp']).date()
            
            if date in market_features:
                for key, value in market_features[date].items():
                    self.features_df.loc[self.features_df['episode_id'] == row['episode_id'], key] = value
                    
    def train_all_models(self):
        """ëª¨ë“  AI ëª¨ë¸ í•™ìŠµ (ê³¼ì í•© ë°©ì§€)"""
        print("\nğŸ¤– ì¼ë°˜í™”ëœ AI ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        # outcome ë³€ìˆ˜ ì¤€ë¹„
        self._prepare_outcome_variables()
        
        # 1. KNN ëª¨ë¸ í•™ìŠµ
        self._train_knn_models()
        
        # 2. ì•™ìƒë¸” ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
        self._train_ensemble_models()
        
        # 3. êµì°¨ ê²€ì¦ìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€
        self._evaluate_with_cross_validation()
        
        print("\nâœ… ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        self._print_model_summary()
        
    def _prepare_outcome_variables(self):
        """outcome ë³€ìˆ˜ ì¤€ë¹„ (ì„ì‹œ)"""
        # episodesì—ì„œ ê°€ì ¸ì˜¤ê¸°
        for _, row in self.features_df.iterrows():
            episode = self.episodes_df[self.episodes_df['episode_id'] == row['episode_id']].iloc[0]
            self.features_df.loc[self.features_df['episode_id'] == row['episode_id'], 'outcome_return_rate'] = episode['return_rate']
            self.features_df.loc[self.features_df['episode_id'] == row['episode_id'], 'outcome_holding_days'] = episode['holding_days']
            self.features_df.loc[self.features_df['episode_id'] == row['episode_id'], 'outcome_profitable'] = 1 if episode['return_rate'] > 0 else 0
            
    def _train_knn_models(self):
        """KNN ëª¨ë¸ í•™ìŠµ"""
        print("\nğŸ“ KNN ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        # 1. ë§¤ìˆ˜ KNN
        buy_features = self.feature_columns['buy']
        if len(buy_features) > 0:
            X_buy = self.situations_df[buy_features].fillna(0).values
            
            # ì°¨ì› ì¶•ì†Œ ê³ ë ¤
            if len(buy_features) > 30:
                from sklearn.decomposition import PCA
                pca = PCA(n_components=20, random_state=42)
                X_buy = pca.fit_transform(X_buy)
                print(f"   - PCA ì ìš©: {len(buy_features)}ì°¨ì› â†’ 20ì°¨ì›")
            
            X_buy_scaled = self.buy_scaler.fit_transform(X_buy)
            self.buy_situation_knn.fit(X_buy_scaled)
            print(f"   âœ… ë§¤ìˆ˜ KNN: {len(X_buy):,}ê°œ ìƒí™© í•™ìŠµ ì™„ë£Œ")
        
        # 2. ë§¤ë„ KNN
        sell_features = [col for col in self.feature_columns['sell'] if not col.startswith('outcome')]
        X_sell = self.features_df[sell_features].fillna(0).values
        X_sell_scaled = self.sell_scaler.fit_transform(X_sell)
        self.sell_situation_knn.fit(X_sell_scaled)
        print(f"   âœ… ë§¤ë„ KNN: {len(X_sell):,}ê°œ ìƒí™© í•™ìŠµ ì™„ë£Œ")
        
    def _train_ensemble_models(self):
        """ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ (ì‹œê°„ìˆœ ë¶„í• )"""
        print("\nğŸ“ˆ ì•™ìƒë¸” ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        # íŠ¹ì§•ê³¼ íƒ€ê²Ÿ ì¤€ë¹„
        feature_cols = [col for col in self.feature_columns['all'] if not col.startswith('outcome')]
        X = self.features_df[feature_cols].fillna(0)
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ë“¤
        y_return = self.features_df['outcome_return_rate']
        y_success = self.features_df['outcome_profitable']
        y_holding = self.features_df['outcome_holding_days']
        
        # í•™ìŠµ/ê²€ì¦ ë¶„í•  (ì‹œê°„ ìˆœì„œ ê³ ë ¤)
        episode_dates = self.episodes_df.set_index('episode_id')['buy_timestamp']
        self.features_df['date'] = self.features_df['episode_id'].map(episode_dates)
        
        # ì‹œê°„ìˆœ ì •ë ¬
        sorted_indices = self.features_df.sort_values('date').index
        split_point = int(len(sorted_indices) * 0.8)
        
        train_idx = sorted_indices[:split_point]
        val_idx = sorted_indices[split_point:]
        
        X_train = X.loc[train_idx]
        X_val = X.loc[val_idx]
        
        # ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.feature_scaler.fit_transform(X_train)
        X_val_scaled = self.feature_scaler.transform(X_val)
        
        # 1. ìˆ˜ìµë¥  ì˜ˆì¸¡ ì•™ìƒë¸”
        print("   - ìˆ˜ìµë¥  ì˜ˆì¸¡ ì•™ìƒë¸” í•™ìŠµ ì¤‘...")
        self.return_ensemble.fit(X_train_scaled, y_return.loc[train_idx])
        
        # 2. ì„±ê³µ í™•ë¥  ì˜ˆì¸¡ ì•™ìƒë¸”
        print("   - ì„±ê³µ í™•ë¥  ì˜ˆì¸¡ ì•™ìƒë¸” í•™ìŠµ ì¤‘...")
        self.success_ensemble.fit(X_train_scaled, y_success.loc[train_idx])
        
        # 3. ë³´ìœ  ê¸°ê°„ ì˜ˆì¸¡
        print("   - ë³´ìœ  ê¸°ê°„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...")
        self.holding_predictor.fit(X_train_scaled, y_holding.loc[train_idx])
        
        # ê²€ì¦ ì„¸íŠ¸ ì„±ëŠ¥
        self._evaluate_on_validation(X_val_scaled, val_idx)
        
    def _evaluate_on_validation(self, X_val, val_idx):
        """ê²€ì¦ ì„¸íŠ¸ ì„±ëŠ¥ í‰ê°€"""
        y_return_val = self.features_df.loc[val_idx, 'outcome_return_rate']
        y_success_val = self.features_df.loc[val_idx, 'outcome_profitable']
        y_holding_val = self.features_df.loc[val_idx, 'outcome_holding_days']
        
        # ì˜ˆì¸¡
        return_pred = self.return_ensemble.predict(X_val)
        success_pred = self.success_ensemble.predict(X_val)
        success_proba = self.success_ensemble.predict_proba(X_val)[:, 1]
        holding_pred = self.holding_predictor.predict(X_val)
        
        # ì„±ëŠ¥ ì§€í‘œ
        self.model_performance = {
            'return_mae': mean_absolute_error(y_return_val, return_pred),
            'return_rmse': np.sqrt(mean_squared_error(y_return_val, return_pred)),
            'success_accuracy': accuracy_score(y_success_val, success_pred),
            'success_precision_recall': precision_recall_fscore_support(
                y_success_val, success_pred, average='binary'
            ),
            'holding_mae': mean_absolute_error(y_holding_val, holding_pred)
        }
        
        print(f"\nğŸ“Š ê²€ì¦ ì„¸íŠ¸ ì„±ëŠ¥:")
        print(f"   - ìˆ˜ìµë¥  MAE: {self.model_performance['return_mae']:.2f}%")
        print(f"   - ìˆ˜ìµë¥  RMSE: {self.model_performance['return_rmse']:.2f}%")
        print(f"   - ì„±ê³µ ì˜ˆì¸¡ ì •í™•ë„: {self.model_performance['success_accuracy']:.2%}")
        print(f"   - ë³´ìœ ê¸°ê°„ MAE: {self.model_performance['holding_mae']:.1f}ì¼")
        
        # ê³¼ì í•© ê²€ì‚¬
        if self.model_performance['success_accuracy'] > 0.85:
            print("\nâš ï¸ ê²½ê³ : ì—¬ì „íˆ ë†’ì€ ì •í™•ë„ - ì¶”ê°€ ê²€ì¦ í•„ìš”")
        else:
            print("\nâœ… ì •ìƒì ì¸ ì„±ëŠ¥ ë²”ìœ„")
            
        # ì¶”ê°€ ì§„ë‹¨
        print(f"\nğŸ“Š ì¶”ê°€ ì§„ë‹¨:")
        print(f"   - ì˜ˆì¸¡ ìˆ˜ìµë¥  ë²”ìœ„: [{return_pred.min():.1f}%, {return_pred.max():.1f}%]")
        print(f"   - ì‹¤ì œ ìˆ˜ìµë¥  ë²”ìœ„: [{y_return_val.min():.1f}%, {y_return_val.max():.1f}%]")
        print(f"   - ì˜ˆì¸¡ í‘œì¤€í¸ì°¨: {np.std(return_pred):.2f}% vs ì‹¤ì œ: {np.std(y_return_val):.2f}%")
        
    def _evaluate_with_cross_validation(self):
        """êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ ì•ˆì •ì„± í‰ê°€"""
        print("\nğŸ”„ êµì°¨ ê²€ì¦ ìˆ˜í–‰ ì¤‘...")
        
        feature_cols = [col for col in self.feature_columns['all'] if not col.startswith('outcome')]
        X = self.features_df[feature_cols].fillna(0)
        y = self.features_df['outcome_profitable']
        
        # XGBoost ë‹¨ì¼ ëª¨ë¸ë¡œ ë¹ ë¥¸ CV
        quick_model = xgb.XGBClassifier(n_estimators=100, random_state=42)
        scores = cross_val_score(quick_model, X, y, cv=3, scoring='accuracy')
        
        print(f"   - 3-Fold CV í‰ê·  ì •í™•ë„: {scores.mean():.2%} (Â±{scores.std():.2%})")
        
    def analyze_sell_situation(self, current_situation):
        """ë§¤ë„ ìƒí™© ë¶„ì„ (ì¼ë°˜í™”ëœ íŒ¨í„´ ê¸°ë°˜)"""
        
        # 1. íŠ¹ì§• ë²¡í„° ìƒì„± (ê°œì¸ ì •ë³´ ì—†ì´)
        sell_features = self._create_sell_feature_vector_generalized(current_situation)
        
        # 2. KNNìœ¼ë¡œ ìœ ì‚¬í•œ ìƒí™© ì°¾ê¸°
        similar_cases = self._find_similar_sell_cases_generalized(sell_features)
        
        # 3. ì•™ìƒë¸”ë¡œ ì˜ˆì¸¡
        predictions = self._predict_sell_outcome_generalized(sell_features)
        
        # 4. íŒ¨í„´ ë¶„ì„
        pattern_analysis = self._analyze_similar_patterns_generalized(similar_cases)
        
        # 5. ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_prediction_confidence(similar_cases, predictions, pattern_analysis)
        
        # 6. ìµœì¢… ë¶„ì„ í†µí•©
        return self._integrate_sell_analysis(
            current_situation, similar_cases, predictions, pattern_analysis, confidence
        )
        
    def _create_sell_feature_vector_generalized(self, situation):
        """ì¼ë°˜í™”ëœ ë§¤ë„ íŠ¹ì§• ë²¡í„° ìƒì„±"""
        features = {
            # ê¸°ë³¸ íŠ¹ì§•
            'current_return': situation['current_return'],
            'holding_days': situation['holding_days'],
            'return_per_day': situation['current_return'] / max(situation['holding_days'], 1),
            
            # ìˆ˜ìµë¥  êµ¬ê°„
            'return_zone_negative': 1 if situation['current_return'] < 0 else 0,
            'return_zone_0_3': 1 if 0 <= situation['current_return'] < 3 else 0,
            'return_zone_3_5': 1 if 3 <= situation['current_return'] < 5 else 0,
            'return_zone_5_10': 1 if 5 <= situation['current_return'] < 10 else 0,
            'return_zone_10_plus': 1 if situation['current_return'] >= 10 else 0,
            
            # ë³´ìœ ê¸°ê°„ êµ¬ê°„
            'holding_zone_short': 1 if situation['holding_days'] < 7 else 0,
            'holding_zone_medium': 1 if 7 <= situation['holding_days'] < 30 else 0,
            'holding_zone_long': 1 if 30 <= situation['holding_days'] < 90 else 0,
            'holding_zone_very_long': 1 if situation['holding_days'] >= 90 else 0,
            
            # íš¨ìœ¨ì„±
            'daily_return_efficiency': situation['current_return'] / max(situation['holding_days'], 1),
            'is_quick_profit': 1 if situation['current_return'] > 5 and situation['holding_days'] < 7 else 0,
            'is_slow_profit': 1 if situation['current_return'] > 5 and situation['holding_days'] > 30 else 0
        }
        
        # ì‹œì¥ ìƒí™© ì¶”ê°€ (ìˆë‹¤ë©´)
        if 'market_volatility' in situation:
            features['market_volatility'] = situation['market_volatility']
            
        return features
    
    def _find_similar_sell_cases_generalized(self, current_features):
        """ì¼ë°˜í™”ëœ ìœ ì‚¬ ë§¤ë„ ìƒí™© ì°¾ê¸°"""
        # íŠ¹ì§• ë²¡í„° ì¤€ë¹„
        sell_cols = [col for col in self.feature_columns['sell'] if not col.startswith('outcome')]
        current_vector = []
        
        for col in sell_cols:
            current_vector.append(current_features.get(col, 0))
            
        current_vector = np.array(current_vector).reshape(1, -1)
        current_scaled = self.sell_scaler.transform(current_vector)
        
        # 30ê°œ ì´ì›ƒ ì°¾ê¸°
        distances, indices = self.sell_situation_knn.kneighbors(current_scaled, n_neighbors=30)
        
        # ìƒì„¸ ì •ë³´ ì¶”ì¶œ
        similar_cases = []
        for dist, idx in zip(distances[0], indices[0]):
            feature_row = self.features_df.iloc[idx]
            episode = self.episodes_df[self.episodes_df['episode_id'] == feature_row['episode_id']].iloc[0]
            
            similar_cases.append({
                'similarity': 1 / (1 + dist),
                'distance': dist,
                'episode': episode,
                'features': feature_row,
                'outcome': {
                    'final_return': episode['return_rate'],
                    'sold_at': feature_row.get('current_return', episode['return_rate']),
                    'holding_days': episode['holding_days']
                }
            })
            
        return similar_cases
    
    def _predict_sell_outcome_generalized(self, current_features):
        """ì¼ë°˜í™”ëœ ë§¤ë„ ê²°ê³¼ ì˜ˆì¸¡"""
        # ì „ì²´ íŠ¹ì§• ë²¡í„° êµ¬ì„±
        feature_cols = [col for col in self.feature_columns['all'] if not col.startswith('outcome')]
        all_features = []
        
        for col in feature_cols:
            if col in current_features:
                all_features.append(current_features[col])
            else:
                # ëˆ„ë½ëœ íŠ¹ì§•ì€ 0 ì‚¬ìš©
                all_features.append(0)
                    
        X = np.array(all_features).reshape(1, -1)
        X_scaled = self.feature_scaler.transform(X)
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        predictions = {
            'expected_final_return': float(self.return_ensemble.predict(X_scaled)[0]),
            'success_probability': float(self.success_ensemble.predict_proba(X_scaled)[0][1]),
            'expected_total_holding': float(self.holding_predictor.predict(X_scaled)[0])
        }
        
        # ì¶”ê°€ ê³„ì‚°
        current_return = current_features['current_return']
        current_holding = current_features['holding_days']
        
        predictions['expected_additional_return'] = predictions['expected_final_return'] - current_return
        predictions['expected_additional_days'] = max(0, predictions['expected_total_holding'] - current_holding)
        
        return predictions
    
    def _analyze_similar_patterns_generalized(self, similar_cases):
        """ì¼ë°˜í™”ëœ íŒ¨í„´ ë¶„ì„"""
        # ìƒìœ„ 10ê°œ ì‚¬ë¡€ë¡œ ë¶„ì„
        top_cases = similar_cases[:10]
        
        # íŒ¨í„´ ë¶„ì„
        patterns = {
            'total_similar': len(top_cases),
            'avg_final_return': np.mean([c['outcome']['final_return'] for c in top_cases]),
            'std_final_return': np.std([c['outcome']['final_return'] for c in top_cases]),
            'positive_ratio': len([c for c in top_cases if c['outcome']['final_return'] > 0]) / len(top_cases),
            'avg_holding_days': np.mean([c['outcome']['holding_days'] for c in top_cases])
        }
        
        # í˜„ì¬ ìˆ˜ìµë¥  êµ¬ê°„ì˜ íŒ¨í„´
        current_return = similar_cases[0]['features'].get('current_return', 0)
        
        # ìœ ì‚¬í•œ ìˆ˜ìµë¥  êµ¬ê°„ ë¶„ì„
        similar_return_cases = [c for c in similar_cases 
                               if abs(c['features'].get('current_return', 0) - current_return) < 2]
        
        if len(similar_return_cases) >= 5:
            patterns['similar_return_pattern'] = {
                'count': len(similar_return_cases),
                'avg_outcome': np.mean([c['outcome']['final_return'] for c in similar_return_cases[:10]]),
                'better_outcome_ratio': len([c for c in similar_return_cases[:10] 
                                           if c['outcome']['final_return'] > current_return]) / 10
            }
            
        return patterns
    
    def _calculate_prediction_confidence(self, similar_cases, predictions, patterns):
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence_factors = []
        
        # 1. ìœ ì‚¬ ì‚¬ë¡€ë“¤ì˜ ì¼ê´€ì„±
        outcomes = [c['outcome']['final_return'] for c in similar_cases[:10]]
        consistency = 1 - (np.std(outcomes) / (abs(np.mean(outcomes)) + 1e-6))
        confidence_factors.append(min(consistency, 1.0) * 0.3)
        
        # 2. ìœ ì‚¬ë„ ì ìˆ˜
        avg_similarity = np.mean([c['similarity'] for c in similar_cases[:5]])
        confidence_factors.append(avg_similarity * 0.3)
        
        # 3. íŒ¨í„´ ê°•ë„
        if patterns['positive_ratio'] > 0.7 or patterns['positive_ratio'] < 0.3:
            confidence_factors.append(0.2)
        else:
            confidence_factors.append(0.1)
            
        # 4. ì˜ˆì¸¡ê°’ì˜ í•©ë¦¬ì„±
        if -100 < predictions['expected_final_return'] < 200:
            confidence_factors.append(0.2)
        else:
            confidence_factors.append(0.05)
            
        # ì¢…í•© ì‹ ë¢°ë„
        total_confidence = sum(confidence_factors)
        
        return {
            'overall': min(total_confidence, 0.9),
            'factors': {
                'consistency': consistency,
                'similarity': avg_similarity,
                'pattern_clarity': confidence_factors[2] / 0.2,
                'prediction_validity': confidence_factors[3] / 0.2
            }
        }
    
    def _integrate_sell_analysis(self, situation, similar_cases, predictions, patterns, confidence):
        """ë§¤ë„ ë¶„ì„ ìµœì¢… í†µí•©"""
        
        # AI ì¶”ì²œ ê²°ì •
        recommendation = self._generate_data_driven_recommendation(
            predictions, patterns, confidence
        )
        
        # ë””ìŠ¤í”Œë ˆì´ìš© í¬ë§·
        display = self._format_sell_display(
            situation, similar_cases[:3], predictions, patterns, confidence, recommendation
        )
        
        return {
            'recommendation': recommendation,
            'predictions': predictions,
            'similar_cases': similar_cases[:5],
            'patterns': patterns,
            'confidence': confidence,
            'display': display,
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def _generate_data_driven_recommendation(self, predictions, patterns, confidence):
        """ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ ìƒì„±"""
        score = 0
        
        # ì˜ˆì¸¡ ê¸°ë°˜ ì ìˆ˜
        if predictions['expected_additional_return'] > 0:
            score += predictions['expected_additional_return'] * 0.1
        else:
            score += predictions['expected_additional_return'] * 0.15
            
        # íŒ¨í„´ ê¸°ë°˜ ì ìˆ˜
        score += (patterns['positive_ratio'] - 0.5) * 2
        
        # ì‹ ë¢°ë„ ë°˜ì˜
        score *= confidence['overall']
        
        # ìµœì¢… ì¶”ì²œ
        if score > 0.3:
            action = 'hold'
            message = f"ê³„ì† ë³´ìœ  ì¶”ì²œ (ì‹ ë¢°ë„ {confidence['overall']*100:.0f}%)"
        elif score < -0.3:
            action = 'sell'
            message = f"ë§¤ë„ ì¶”ì²œ (ì‹ ë¢°ë„ {confidence['overall']*100:.0f}%)"
        else:
            action = 'neutral'
            message = f"ì¤‘ë¦½ (ì‹ ë¢°ë„ {confidence['overall']*100:.0f}%)"
            
        return {
            'action': action,
            'score': score,
            'message': message,
            'confidence': confidence['overall']
        }
    
    def analyze_buy_situation(self, stock_info, market_condition=None):
        """ë§¤ìˆ˜ ìƒí™© ë¶„ì„ (ê°œì¸ ì •ë³´ ì—†ì´)"""
        
        # 1. ë§¤ìˆ˜ íŠ¹ì§• ë²¡í„° ìƒì„±
        buy_features = self._create_buy_feature_vector_generalized(stock_info, market_condition)
        
        # 2. ìœ ì‚¬ ë§¤ìˆ˜ ìƒí™© ê²€ìƒ‰
        similar_buy_cases = self._find_similar_buy_cases_generalized(buy_features)
        
        # 3. ë§¤ìˆ˜ ê²°ê³¼ ì˜ˆì¸¡
        buy_predictions = self._predict_buy_outcome_generalized(buy_features)
        
        # 4. ë¦¬ìŠ¤í¬ íŒ¨í„´ ë¶„ì„
        risk_analysis = self._analyze_buy_risks_generalized(similar_buy_cases, stock_info)
        
        # 5. ìµœì¢… ë¶„ì„ í†µí•©
        return self._integrate_buy_analysis(
            similar_buy_cases, buy_predictions, risk_analysis, stock_info
        )
        
    def _create_buy_feature_vector_generalized(self, stock_info, market_condition):
        """ì¼ë°˜í™”ëœ ë§¤ìˆ˜ íŠ¹ì§• ë²¡í„° ìƒì„±"""
        features = {
            # ê¸°ë³¸ ì‹œì¥ ìƒí™©
            'market_avg_return_7d': market_condition.get('avg_return_7d', 0) if market_condition else 0,
            'market_volatility_7d': market_condition.get('volatility_7d', 10) if market_condition else 10,
            'market_avg_return_30d': market_condition.get('avg_return_30d', 0) if market_condition else 0,
            'market_volatility_30d': market_condition.get('volatility_30d', 10) if market_condition else 10,
            
            # ì‹œê°„ íŠ¹ì§•
            'buy_day_of_week': datetime.now().weekday(),
            'buy_month': datetime.now().month,
            'buy_quarter': (datetime.now().month - 1) // 3 + 1,
            'buy_is_month_start': datetime.now().day <= 5,
            'buy_is_month_end': datetime.now().day >= 25,
        }
        
        # ì£¼ì‹ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if stock_info and 'recent_return' in stock_info:
            features['stock_recent_momentum'] = stock_info['recent_return']
            features['is_rally'] = 1 if stock_info['recent_return'] > 5 else 0
            
        return features
    
    def _find_similar_buy_cases_generalized(self, buy_features):
        """ì¼ë°˜í™”ëœ ìœ ì‚¬ ë§¤ìˆ˜ ìƒí™© ê²€ìƒ‰"""
        # íŠ¹ì§• ë²¡í„° ì¤€ë¹„
        buy_cols = self.feature_columns['buy']
        current_vector = []
        
        for col in buy_cols:
            feature_name = col.replace('feature_', '')
            current_vector.append(buy_features.get(feature_name, 0))
            
        # ë¹ˆ ë²¡í„°ì¸ ê²½ìš° ì²˜ë¦¬
        if len(current_vector) == 0:
            # features_dfì—ì„œ ë¬´ì‘ìœ„ë¡œ ì„ íƒ
            n_samples = min(30, len(self.features_df))
            random_indices = np.random.choice(len(self.features_df), n_samples, replace=False)
            
            similar_cases = []
            for idx in random_indices:
                feature_row = self.features_df.iloc[idx]
                episode = self.episodes_df[self.episodes_df['episode_id'] == feature_row['episode_id']].iloc[0]
                
                similar_cases.append({
                    'similarity': 0.5,  # ê¸°ë³¸ ìœ ì‚¬ë„
                    'outcome': {
                        'return_rate': episode['return_rate'],
                        'holding_days': episode['holding_days'],
                        'profitable': 1 if episode['return_rate'] > 0 else 0
                    }
                })
            return similar_cases
            
        current_vector = np.array(current_vector).reshape(1, -1)
        
        # KNNì´ í•™ìŠµë˜ì§€ ì•Šì€ ê²½ìš° ì²˜ë¦¬
        try:
            current_scaled = self.buy_scaler.transform(current_vector)
            distances, indices = self.buy_situation_knn.kneighbors(current_scaled, n_neighbors=30)
        except:
            # í•™ìŠµë˜ì§€ ì•Šì€ ê²½ìš° ë¬´ì‘ìœ„ ì„ íƒ
            n_samples = min(30, len(self.features_df))
            random_indices = np.random.choice(len(self.features_df), n_samples, replace=False)
            
            similar_cases = []
            for idx in random_indices:
                feature_row = self.features_df.iloc[idx]
                episode = self.episodes_df[self.episodes_df['episode_id'] == feature_row['episode_id']].iloc[0]
                
                similar_cases.append({
                    'similarity': 0.5,
                    'outcome': {
                        'return_rate': episode['return_rate'],
                        'holding_days': episode['holding_days'],
                        'profitable': 1 if episode['return_rate'] > 0 else 0
                    }
                })
            return similar_cases
        
        # ì •ìƒì ì¸ KNN ê²°ê³¼ ì²˜ë¦¬
        similar_cases = []
        for dist, idx in zip(distances[0], indices[0]):
            situation = self.situations_df.iloc[idx]
            episode_id = situation['episode_id']
            
            episode = self.episodes_df[self.episodes_df['episode_id'] == episode_id].iloc[0]
            
            similar_cases.append({
                'similarity': 1 / (1 + dist),
                'situation': situation,
                'outcome': {
                    'return_rate': episode['return_rate'],
                    'holding_days': episode['holding_days'],
                    'profitable': 1 if episode['return_rate'] > 0 else 0
                }
            })
                
        return similar_cases
    
    def _predict_buy_outcome_generalized(self, buy_features):
        """ì¼ë°˜í™”ëœ ë§¤ìˆ˜ ê²°ê³¼ ì˜ˆì¸¡"""
        # ì „ì²´ íŠ¹ì§• ë²¡í„° êµ¬ì„±
        feature_cols = [col for col in self.feature_columns['all'] if not col.startswith('outcome')]
        all_features = []
        
        for col in feature_cols:
            if col in buy_features:
                all_features.append(buy_features[col])
            else:
                all_features.append(0)
                
        X = np.array(all_features).reshape(1, -1)
        X_scaled = self.feature_scaler.transform(X)
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        predictions = {
            'expected_return': float(self.return_ensemble.predict(X_scaled)[0]),
            'success_probability': float(self.success_ensemble.predict_proba(X_scaled)[0][1]),
            'expected_holding_days': float(self.holding_predictor.predict(X_scaled)[0])
        }
        
        # ë¦¬ìŠ¤í¬ ì¡°ì •
        if 'market_volatility_7d' in buy_features:
            volatility = buy_features['market_volatility_7d']
            predictions['risk_adjusted_return'] = predictions['expected_return'] / (1 + volatility/100)
        
        return predictions
    
    def _analyze_buy_risks_generalized(self, similar_cases, stock_info):
        """ì¼ë°˜í™”ëœ ë§¤ìˆ˜ ë¦¬ìŠ¤í¬ ë¶„ì„"""
        risks = {
            'chase_buying': {'detected': False},
            'high_volatility': {'detected': False},
            'poor_timing': {'detected': False}
        }
        
        # 1. ì¶”ê²©ë§¤ìˆ˜ íŒ¨í„´
        if stock_info.get('recent_return', 0) > 8:
            # ê¸‰ë“± í›„ ë§¤ìˆ˜í•œ ìœ ì‚¬ ì‚¬ë¡€ë“¤ì˜ ì„±ê³¼
            rally_cases = [c for c in similar_cases[:20] if c.get('situation', {}).get('feature_is_rally', 0) == 1]
            
            if len(rally_cases) >= 5:
                rally_success_rate = sum(1 for c in rally_cases if c['outcome']['profitable']) / len(rally_cases)
                rally_avg_return = np.mean([c['outcome']['return_rate'] for c in rally_cases])
                
                if rally_success_rate < 0.4:
                    risks['chase_buying'] = {
                        'detected': True,
                        'success_rate': rally_success_rate,
                        'avg_return': rally_avg_return,
                        'sample_size': len(rally_cases)
                    }
        
        # 2. ê³ ë³€ë™ì„± ì‹œì¥
        market_vol = stock_info.get('market_volatility', 10)
        if market_vol > 20:
            risks['high_volatility'] = {
                'detected': True,
                'volatility': market_vol
            }
            
        # 3. íƒ€ì´ë° ë¶„ì„
        current_dow = datetime.now().weekday()
        if current_dow == 0:  # ì›”ìš”ì¼
            monday_cases = [c for c in similar_cases if c.get('situation', {}).get('feature_buy_day_of_week', -1) == 0]
            if len(monday_cases) >= 5:
                monday_success = sum(1 for c in monday_cases[:10] if c['outcome']['profitable']) / min(10, len(monday_cases))
                if monday_success < 0.4:
                    risks['poor_timing'] = {
                        'detected': True,
                        'reason': 'monday_effect',
                        'success_rate': monday_success
                    }
        
        return risks
    
    def _integrate_buy_analysis(self, similar_cases, predictions, risks, stock_info):
        """ë§¤ìˆ˜ ë¶„ì„ ìµœì¢… í†µí•©"""
        
        # ìœ ì‚¬ ì‚¬ë¡€ í†µê³„
        success_cases = [c for c in similar_cases[:10] if c['outcome']['profitable']]
        similar_stats = {
            'success_rate': len(success_cases) / 10,
            'avg_return': np.mean([c['outcome']['return_rate'] for c in similar_cases[:10]]),
            'avg_holding': np.mean([c['outcome']['holding_days'] for c in similar_cases[:10]])
        }
        
        # ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ
        recommendation = self._generate_buy_recommendation(
            predictions, similar_stats, risks
        )
        
        # ë””ìŠ¤í”Œë ˆì´ í¬ë§·
        display = self._format_buy_display(
            stock_info, predictions, similar_stats, risks, recommendation
        )
        
        return {
            'recommendation': recommendation,
            'predictions': predictions,
            'similar_cases': similar_cases[:5],
            'statistics': similar_stats,
            'risks': risks,
            'display': display,
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def _generate_buy_recommendation(self, predictions, similar_stats, risks):
        """ë°ì´í„° ê¸°ë°˜ ë§¤ìˆ˜ ì¶”ì²œ"""
        score = 0
        factors = []
        
        # ì˜ˆì¸¡ ê¸°ë°˜
        score += (predictions['success_probability'] - 0.5) * 2
        score += predictions['expected_return'] * 0.05
        
        # ìœ ì‚¬ ì‚¬ë¡€ ê¸°ë°˜
        score += (similar_stats['success_rate'] - 0.5) * 1.5
        
        # ë¦¬ìŠ¤í¬ ì°¨ê°
        if risks.get('chase_buying', {}).get('detected'):
            score -= 0.5
            factors.append("ì¶”ê²©ë§¤ìˆ˜ ìœ„í—˜")
        if risks.get('high_volatility', {}).get('detected'):
            score -= 0.3
            factors.append("ê³ ë³€ë™ì„± ì‹œì¥")
        if risks.get('poor_timing', {}).get('detected'):
            score -= 0.2
            factors.append("íƒ€ì´ë° ë¶ˆë¦¬")
            
        # ìµœì¢… ì¶”ì²œ
        if score > 0.3:
            action = 'buy'
            message = f"ë§¤ìˆ˜ ì¶”ì²œ (ì ìˆ˜: {score:.2f})"
        elif score < -0.3:
            action = 'wait'
            message = f"ëŒ€ê¸° ì¶”ì²œ (ì ìˆ˜: {score:.2f})"
        else:
            action = 'neutral'
            message = f"ì‹ ì¤‘ ê²€í†  (ì ìˆ˜: {score:.2f})"
            
        return {
            'action': action,
            'score': score,
            'message': message,
            'factors': factors
        }
    
    def _format_sell_display(self, situation, similar_cases, predictions, patterns, confidence, recommendation):
        """ë§¤ë„ í™”ë©´ í¬ë§·"""
        display = f"""ğŸ“Š ë§¤ë„ ë¶„ì„

í˜„ì¬ ìƒí™©: {situation.get('stock_name', 'ì¢…ëª©')} {situation['current_return']:+.1f}% ({situation['holding_days']}ì¼ ë³´ìœ )

ğŸ¤– AI ì˜ˆì¸¡:
- ì˜ˆìƒ ìµœì¢… ìˆ˜ìµë¥ : {predictions['expected_final_return']:.1f}%
- ì¶”ê°€ ìƒìŠ¹ ê°€ëŠ¥ì„±: {predictions['expected_additional_return']:+.1f}%
- ì‹ ë¢°ë„: {confidence['overall']*100:.0f}%

ğŸ“ˆ íŒ¨í„´ ë¶„ì„:
- ìœ ì‚¬ ìƒí™© í‰ê·  ìˆ˜ìµë¥ : {patterns['avg_final_return']:.1f}%
- ì„±ê³µ ë¹„ìœ¨: {patterns['positive_ratio']*100:.0f}%"""
        
        # ìœ ì‚¬ ì‚¬ë¡€ ì¶”ê°€
        display += "\n\nğŸ“š ìœ ì‚¬ ì‚¬ë¡€:"
        for i, case in enumerate(similar_cases, 1):
            display += f"""
[{i}] ìˆ˜ìµë¥ : {case['outcome']['final_return']:+.1f}% ({case['outcome']['holding_days']}ì¼)
    ìœ ì‚¬ë„: {case['similarity']*100:.0f}%"""
        
        display += f"\n\nğŸ’¡ AI ì¶”ì²œ: {recommendation['message']}"
        
        return display
    
    def _format_buy_display(self, stock_info, predictions, stats, risks, recommendation):
        """ë§¤ìˆ˜ í™”ë©´ í¬ë§·"""
        if risks.get('chase_buying', {}).get('detected'):
            display = f"""ğŸ›‘ ë§¤ìˆ˜ ì „ ì ê²€

ğŸ“ˆ í˜„ì¬ ìƒí™©: {stock_info.get('name', 'ì¢…ëª©')} +{stock_info.get('recent_return', 0):.1f}% (ê¸‰ë“± ì¤‘)

ğŸ” AI íŒ¨í„´ ë¶„ì„:
ê³¼ê±° ì¶”ê²©ë§¤ìˆ˜ {risks['chase_buying']['sample_size']}ê±´ ë¶„ì„ ê²°ê³¼:
- ì„±ê³µë¥ : {risks['chase_buying']['success_rate']*100:.0f}%
- í‰ê·  ìˆ˜ìµë¥ : {risks['chase_buying']['avg_return']:.1f}%

âš ï¸ ë°ì´í„°ê°€ ë³´ì—¬ì£¼ëŠ” ë‚®ì€ ì„±ê³µë¥ ì…ë‹ˆë‹¤."""
        else:
            display = f"""ğŸ“Š ë§¤ìˆ˜ ë¶„ì„

ì¢…ëª©: {stock_info.get('name', 'ì¢…ëª©')}

ğŸ¤– AI ì˜ˆì¸¡:
- ì„±ê³µ í™•ë¥ : {predictions['success_probability']*100:.0f}%
- ì˜ˆìƒ ìˆ˜ìµë¥ : {predictions['expected_return']:.1f}%
- ì˜ˆìƒ ë³´ìœ ê¸°ê°„: {predictions['expected_holding_days']:.0f}ì¼

ğŸ“ˆ ìœ ì‚¬ ê±°ë˜ í†µê³„:
- ì„±ê³µë¥ : {stats['success_rate']*100:.0f}%
- í‰ê·  ìˆ˜ìµë¥ : {stats['avg_return']:.1f}%"""
            
        display += f"\n\nğŸ’¡ AI ì¶”ì²œ: {recommendation['message']}"
        
        if recommendation['factors']:
            display += f"\nê³ ë ¤ì‚¬í•­: {', '.join(recommendation['factors'])}"
            
        return display
    
    def _print_model_summary(self):
        """ëª¨ë¸ ìš”ì•½ ì¶œë ¥"""
        print("\nğŸ“‹ ëª¨ë¸ ìš”ì•½:")
        print(f"   - KNN ì´ì›ƒ ìˆ˜: 30")
        print(f"   - ì•™ìƒë¸” ëª¨ë¸: XGBoost + LightGBM + CatBoost")
        print(f"   - íŠ¹ì§• ì°¨ì›: {len(self.feature_columns['all'])}ì°¨ì›")
        print(f"   - í•™ìŠµ ë°ì´í„°: {len(self.features_df):,}ê°œ ì—í”¼ì†Œë“œ")
        print(f"   - ê³¼ì í•© ë°©ì§€: customer_id, isin, ë¯¸ë˜ì •ë³´ ì œê±°")
        
    def save_models(self, path='models/sophisticated_ai_fixed'):
        """ëª¨ë¸ ì €ì¥"""
        import os
        os.makedirs(path, exist_ok=True)
        
        # ëª¨ë“  ëª¨ë¸ ì €ì¥
        models_to_save = {
            'buy_knn': self.buy_situation_knn,
            'sell_knn': self.sell_situation_knn,
            'return_ensemble': self.return_ensemble,
            'success_ensemble': self.success_ensemble,
            'holding_predictor': self.holding_predictor,
            'buy_scaler': self.buy_scaler,
            'sell_scaler': self.sell_scaler,
            'feature_scaler': self.feature_scaler
        }
        
        for name, model in models_to_save.items():
            joblib.dump(model, f'{path}/{name}.pkl')
            
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'trained_at': datetime.now().isoformat(),
            'feature_columns': self.feature_columns,
            'model_performance': self.model_performance,
            'data_stats': {
                'total_episodes': len(self.episodes_df),
                'total_features': len(self.feature_columns['all'])
            },
            'improvements': [
                'customer_id ê¸°ë°˜ íŠ¹ì§• ì œê±°',
                'isin ê¸°ë°˜ íŠ¹ì§• ì œê±°',
                'ë¯¸ë˜ ì •ë³´ ì‚¬ìš© ì œê±°',
                'ì¼ë°˜í™” ê°€ëŠ¥í•œ íŒ¨í„´ë§Œ í•™ìŠµ'
            ]
        }
        
        with open(f'{path}/metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {path}")


# ë©”ì¸ ì‹¤í–‰
def main():
    """ê³¼ì í•© í•´ê²°ëœ AI ì‹œìŠ¤í…œ ì‹¤í–‰"""
    
    # AI ì´ˆê¸°í™”
    ai = SophisticatedTradingAI()
    
    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    DATA_PATH = "/Users/inter4259/Desktop/Programming/hek_credit/generate_data/preprocessed_data_pure"
    
    # ë°ì´í„° ë¡œë“œ
    print("ğŸš€ ê³¼ì í•© í•´ê²°ëœ AI ê±°ë˜ ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œì‘\n")
    ai.load_all_data(
        f'{DATA_PATH}/episodes.csv',
        f'{DATA_PATH}/features.csv',
        f'{DATA_PATH}/situations.csv'
    )
    
    # ëª¨ë¸ í•™ìŠµ
    ai.train_all_models()
    
    # ëª¨ë¸ ì €ì¥
    ai.save_models()
    
    # ë°ëª¨
    print("\n" + "="*60)
    print("ğŸ’¡ AI ê±°ë˜ ì–´ì‹œìŠ¤í„´íŠ¸ ë°ëª¨")
    print("="*60)
    
    # ë§¤ë„ ìƒí™© ë°ëª¨
    print("\n### ì‹œë‚˜ë¦¬ì˜¤ 1: ë§¤ë„ ê²°ì • ###")
    sell_result = ai.analyze_sell_situation({
        'stock_name': 'í…ŒìŠ¤íŠ¸ ì¢…ëª©',
        'current_return': 6.8,
        'holding_days': 8
    })
    print(sell_result['display'])
    
    # ë§¤ìˆ˜ ìƒí™© ë°ëª¨
    print("\n\n### ì‹œë‚˜ë¦¬ì˜¤ 2: ë§¤ìˆ˜ ê²°ì • ###")
    buy_result = ai.analyze_buy_situation(
        stock_info={
            'name': 'í…ŒìŠ¤íŠ¸ ì¢…ëª©',
            'recent_return': 8.5
        },
        market_condition={
            'volatility_7d': 15,
            'avg_return_7d': 2.5
        }
    )
    print(buy_result['display'])


if __name__ == "__main__":
    main()